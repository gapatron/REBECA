{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "\n",
    "import sys\n",
    "sys.path.append('../')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "ename": "ImportError",
     "evalue": "cannot import name 'run_experiments' from 'grid_search' (/home/gabriel/Projects/REBECA/notebooks/../grid_search.py)",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mImportError\u001b[39m                               Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[2]\u001b[39m\u001b[32m, line 6\u001b[39m\n\u001b[32m      4\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mtorch\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mutils\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mdata\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m Subset\n\u001b[32m      5\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mDatasets\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m EmbeddingsDataset\n\u001b[32m----> \u001b[39m\u001b[32m6\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mgrid_search\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m run_experiments\n\u001b[32m      7\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mutils\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m map_embeddings_to_ratings, split_recommender_data\n",
      "\u001b[31mImportError\u001b[39m: cannot import name 'run_experiments' from 'grid_search' (/home/gabriel/Projects/REBECA/notebooks/../grid_search.py)"
     ]
    }
   ],
   "source": [
    "from Datasets import RecommenderUserSampler\n",
    "import pandas as pd\n",
    "import torch\n",
    "from torch.utils.data import Subset\n",
    "from Datasets import EmbeddingsDataset\n",
    "from grid_search import run_experiments\n",
    "from utils import map_embeddings_to_ratings, split_recommender_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "image_features = torch.load(\"../data/flickr/processed/ip-adapters/SDXL/sdxl_image_embeddings.pt\", weights_only=True)\n",
    "ratings_df = pd.read_csv(\"../data/flickr/processed/ratings.csv\")\n",
    "expanded_features = map_embeddings_to_ratings(image_features, ratings_df)\n",
    "device = \"cuda\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train set size: 183692\n",
      "Shared images size: 7489\n",
      "Evaluation set size: 9516\n"
     ]
    }
   ],
   "source": [
    "train_val_df, eval_df, shared_images_df = split_recommender_data(\n",
    "    ratings_df=ratings_df,\n",
    "    eval_spu=10,\n",
    "    seed=42\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Final train set size: 181680\n",
      "Final val set size: 2012\n"
     ]
    }
   ],
   "source": [
    "unique_users = ratings_df[\"worker_id\"].unique()\n",
    "#user_sampler = RecommenderUserSampler(ratings_df=ratings_df, num_users=len(unique_users), samples_per_user=38)\n",
    "# Generae test rating ids\n",
    "val_ratings_sampler = RecommenderUserSampler(ratings_df=train_val_df, num_users=len(unique_users), samples_per_user=10)\n",
    "val_indices = [i for i in val_ratings_sampler]\n",
    "# Convert to set for faster lookup\n",
    "val_indices_set = set(val_indices)\n",
    "# Create mask for training data\n",
    "train_mask = ~train_val_df.index.isin(val_indices_set)\n",
    "\n",
    "val_df = train_val_df[~train_mask]\n",
    "train_df = train_val_df[train_mask]\n",
    "\n",
    "print(f\"Final train set size: {len(train_df)}\")\n",
    "print(f\"Final val set size: {len(val_df)}\")\n",
    "\n",
    "# When creating train_df, keep track of the original indices\n",
    "train_df_final = train_df.reset_index(drop=False).rename(columns={'index': 'train_df_original_index'})\n",
    "val_df_final = val_df.reset_index(drop=False).rename(columns={'index': 'train_df_original_index'})\n",
    "\n",
    "\n",
    "train_val_expanded_features = expanded_features[train_val_df.original_index]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "full_dataset = EmbeddingsDataset(train_val_df, \n",
    "                                 image_embeddings=train_val_expanded_features\n",
    "                                 )\n",
    "# Create the dataset using the original indices\n",
    "train_dataset = Subset(full_dataset, train_df_final['train_df_original_index'].tolist())\n",
    "val_dataset = Subset(full_dataset, val_df_final[\"train_df_original_index\"].tolist())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([183692, 1280])"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_val_expanded_features.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "param_grid = {\n",
    "    'timesteps': [6000],\n",
    "    'layers': [2, 4, 8],\n",
    "    'heads': [8, 16, 32],\n",
    "    'dim_feedforward':[1024],\n",
    "    'num_image_tokens': [1, 4],\n",
    "    'num_user_tokens': [1, 4],\n",
    "    'learning_rate': [1e-4],\n",
    "    #'optimizers': ['adamw', 'sgd'],\n",
    "    'optimizers': ['adamw'],\n",
    "    #'schedulers': ['reduce_on_plateau', 'cosine'],\n",
    "    'schedulers': ['reduce_on_plateau'],\n",
    "    'batch_size': [128],\n",
    "    #'noise_schedule': ['linear', \"squaredcos_cap_v2\"],\n",
    "    'noise_schedule': ['linear'],\n",
    "    'samples_per_user': [30, 50, 80, 110, 140],\n",
    "    'objective':[\"noise-pred\"],\n",
    "    'use_ue': [True, False],\n",
    "}\n",
    "\n",
    "savedir = \"../weights/sdxl_experiments\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Hyperparameter combinations:   0%|          | 0/360 [00:00<?, ?it/s]c:\\Users\\Gabriel\\anaconda3\\envs\\recgensys-env\\lib\\site-packages\\torch\\nn\\modules\\transformer.py:306: UserWarning: enable_nested_tensor is True, but self.use_nested_tensor is False because encoder_layer.norm_first was True\n",
      "  warnings.warn(f\"enable_nested_tensor is True, but self.use_nested_tensor is False because {why_not_sparsity_fast_path}\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running configuration: timesteps=6000, layers=2, heads=8, image_tokens=1, user_tokens=1, learning_rate=0.0001, optimizer=adamw, scheduler=reduce_on_plateau, batch_size=128, noise_schedule=linear, samples_per_user=30, objective=noise-pred, use_ue=True\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Gabriel\\anaconda3\\envs\\recgensys-env\\lib\\site-packages\\torch\\nn\\functional.py:5504: UserWarning: 1Torch was not compiled with flash attention. (Triggered internally at C:\\cb\\pytorch_1000000000000\\work\\aten\\src\\ATen\\native\\transformers\\cuda\\sdp_utils.cpp:455.)\n",
      "  attn_output = scaled_dot_product_attention(q, k, v, attn_mask, dropout_p, is_causal)\n",
      "Hyperparameter combinations:   0%|          | 1/360 [01:37<9:44:34, 97.70s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Early stopping with best val loss: 0.11733414884656668!\n",
      "Running configuration: timesteps=6000, layers=2, heads=8, image_tokens=1, user_tokens=1, learning_rate=0.0001, optimizer=adamw, scheduler=reduce_on_plateau, batch_size=128, noise_schedule=linear, samples_per_user=30, objective=noise-pred, use_ue=False\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Gabriel\\anaconda3\\envs\\recgensys-env\\lib\\site-packages\\torch\\nn\\modules\\transformer.py:306: UserWarning: enable_nested_tensor is True, but self.use_nested_tensor is False because encoder_layer.norm_first was True\n",
      "  warnings.warn(f\"enable_nested_tensor is True, but self.use_nested_tensor is False because {why_not_sparsity_fast_path}\")\n",
      "Hyperparameter combinations:   1%|          | 2/360 [03:04<9:03:07, 91.03s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Early stopping with best val loss: 0.12361452076584101!\n",
      "Running configuration: timesteps=6000, layers=2, heads=8, image_tokens=1, user_tokens=1, learning_rate=0.0001, optimizer=adamw, scheduler=reduce_on_plateau, batch_size=128, noise_schedule=linear, samples_per_user=50, objective=noise-pred, use_ue=True\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Gabriel\\anaconda3\\envs\\recgensys-env\\lib\\site-packages\\torch\\nn\\modules\\transformer.py:306: UserWarning: enable_nested_tensor is True, but self.use_nested_tensor is False because encoder_layer.norm_first was True\n",
      "  warnings.warn(f\"enable_nested_tensor is True, but self.use_nested_tensor is False because {why_not_sparsity_fast_path}\")\n",
      "Hyperparameter combinations:   1%|          | 3/360 [06:07<13:12:22, 133.17s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Early stopping with best val loss: 0.08745722938328981!\n",
      "Running configuration: timesteps=6000, layers=2, heads=8, image_tokens=1, user_tokens=1, learning_rate=0.0001, optimizer=adamw, scheduler=reduce_on_plateau, batch_size=128, noise_schedule=linear, samples_per_user=50, objective=noise-pred, use_ue=False\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Gabriel\\anaconda3\\envs\\recgensys-env\\lib\\site-packages\\torch\\nn\\modules\\transformer.py:306: UserWarning: enable_nested_tensor is True, but self.use_nested_tensor is False because encoder_layer.norm_first was True\n",
      "  warnings.warn(f\"enable_nested_tensor is True, but self.use_nested_tensor is False because {why_not_sparsity_fast_path}\")\n",
      "Hyperparameter combinations:   1%|          | 4/360 [08:42<14:01:45, 141.87s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Early stopping with best val loss: 0.08787929685786366!\n",
      "Running configuration: timesteps=6000, layers=2, heads=8, image_tokens=1, user_tokens=1, learning_rate=0.0001, optimizer=adamw, scheduler=reduce_on_plateau, batch_size=128, noise_schedule=linear, samples_per_user=80, objective=noise-pred, use_ue=True\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Gabriel\\anaconda3\\envs\\recgensys-env\\lib\\site-packages\\torch\\nn\\modules\\transformer.py:306: UserWarning: enable_nested_tensor is True, but self.use_nested_tensor is False because encoder_layer.norm_first was True\n",
      "  warnings.warn(f\"enable_nested_tensor is True, but self.use_nested_tensor is False because {why_not_sparsity_fast_path}\")\n",
      "Hyperparameter combinations:   1%|▏         | 5/360 [11:22<14:38:08, 148.42s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Early stopping with best val loss: 0.08580431225709617!\n",
      "Running configuration: timesteps=6000, layers=2, heads=8, image_tokens=1, user_tokens=1, learning_rate=0.0001, optimizer=adamw, scheduler=reduce_on_plateau, batch_size=128, noise_schedule=linear, samples_per_user=80, objective=noise-pred, use_ue=False\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Gabriel\\anaconda3\\envs\\recgensys-env\\lib\\site-packages\\torch\\nn\\modules\\transformer.py:306: UserWarning: enable_nested_tensor is True, but self.use_nested_tensor is False because encoder_layer.norm_first was True\n",
      "  warnings.warn(f\"enable_nested_tensor is True, but self.use_nested_tensor is False because {why_not_sparsity_fast_path}\")\n",
      "Hyperparameter combinations:   2%|▏         | 6/360 [14:08<15:10:28, 154.32s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Early stopping with best val loss: 0.10389115568250418!\n",
      "Running configuration: timesteps=6000, layers=2, heads=8, image_tokens=1, user_tokens=1, learning_rate=0.0001, optimizer=adamw, scheduler=reduce_on_plateau, batch_size=128, noise_schedule=linear, samples_per_user=110, objective=noise-pred, use_ue=True\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Gabriel\\anaconda3\\envs\\recgensys-env\\lib\\site-packages\\torch\\nn\\modules\\transformer.py:306: UserWarning: enable_nested_tensor is True, but self.use_nested_tensor is False because encoder_layer.norm_first was True\n",
      "  warnings.warn(f\"enable_nested_tensor is True, but self.use_nested_tensor is False because {why_not_sparsity_fast_path}\")\n",
      "Hyperparameter combinations:   2%|▏         | 7/360 [18:04<17:45:46, 181.15s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Early stopping with best val loss: 0.07235537585802376!\n",
      "Running configuration: timesteps=6000, layers=2, heads=8, image_tokens=1, user_tokens=1, learning_rate=0.0001, optimizer=adamw, scheduler=reduce_on_plateau, batch_size=128, noise_schedule=linear, samples_per_user=110, objective=noise-pred, use_ue=False\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Gabriel\\anaconda3\\envs\\recgensys-env\\lib\\site-packages\\torch\\nn\\modules\\transformer.py:306: UserWarning: enable_nested_tensor is True, but self.use_nested_tensor is False because encoder_layer.norm_first was True\n",
      "  warnings.warn(f\"enable_nested_tensor is True, but self.use_nested_tensor is False because {why_not_sparsity_fast_path}\")\n",
      "Hyperparameter combinations:   2%|▏         | 8/360 [21:27<18:22:25, 187.91s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Early stopping with best val loss: 0.07583761913701892!\n",
      "Running configuration: timesteps=6000, layers=2, heads=8, image_tokens=1, user_tokens=1, learning_rate=0.0001, optimizer=adamw, scheduler=reduce_on_plateau, batch_size=128, noise_schedule=linear, samples_per_user=140, objective=noise-pred, use_ue=True\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Gabriel\\anaconda3\\envs\\recgensys-env\\lib\\site-packages\\torch\\nn\\modules\\transformer.py:306: UserWarning: enable_nested_tensor is True, but self.use_nested_tensor is False because encoder_layer.norm_first was True\n",
      "  warnings.warn(f\"enable_nested_tensor is True, but self.use_nested_tensor is False because {why_not_sparsity_fast_path}\")\n",
      "Hyperparameter combinations:   2%|▎         | 9/360 [24:57<19:00:51, 195.02s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Early stopping with best val loss: 0.07840188848786056!\n",
      "Running configuration: timesteps=6000, layers=2, heads=8, image_tokens=1, user_tokens=1, learning_rate=0.0001, optimizer=adamw, scheduler=reduce_on_plateau, batch_size=128, noise_schedule=linear, samples_per_user=140, objective=noise-pred, use_ue=False\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Gabriel\\anaconda3\\envs\\recgensys-env\\lib\\site-packages\\torch\\nn\\modules\\transformer.py:306: UserWarning: enable_nested_tensor is True, but self.use_nested_tensor is False because encoder_layer.norm_first was True\n",
      "  warnings.warn(f\"enable_nested_tensor is True, but self.use_nested_tensor is False because {why_not_sparsity_fast_path}\")\n",
      "Hyperparameter combinations:   3%|▎         | 10/360 [28:43<19:53:22, 204.58s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Early stopping with best val loss: 0.0800076297018677!\n",
      "Running configuration: timesteps=6000, layers=2, heads=8, image_tokens=1, user_tokens=4, learning_rate=0.0001, optimizer=adamw, scheduler=reduce_on_plateau, batch_size=128, noise_schedule=linear, samples_per_user=30, objective=noise-pred, use_ue=True\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Gabriel\\anaconda3\\envs\\recgensys-env\\lib\\site-packages\\torch\\nn\\modules\\transformer.py:306: UserWarning: enable_nested_tensor is True, but self.use_nested_tensor is False because encoder_layer.norm_first was True\n",
      "  warnings.warn(f\"enable_nested_tensor is True, but self.use_nested_tensor is False because {why_not_sparsity_fast_path}\")\n",
      "Hyperparameter combinations:   3%|▎         | 11/360 [30:34<17:02:28, 175.78s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Early stopping with best val loss: 0.12878489820286632!\n",
      "Running configuration: timesteps=6000, layers=2, heads=8, image_tokens=1, user_tokens=4, learning_rate=0.0001, optimizer=adamw, scheduler=reduce_on_plateau, batch_size=128, noise_schedule=linear, samples_per_user=30, objective=noise-pred, use_ue=False\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Gabriel\\anaconda3\\envs\\recgensys-env\\lib\\site-packages\\torch\\nn\\modules\\transformer.py:306: UserWarning: enable_nested_tensor is True, but self.use_nested_tensor is False because encoder_layer.norm_first was True\n",
      "  warnings.warn(f\"enable_nested_tensor is True, but self.use_nested_tensor is False because {why_not_sparsity_fast_path}\")\n",
      "Hyperparameter combinations:   3%|▎         | 12/360 [32:12<14:42:48, 152.21s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Early stopping with best val loss: 0.12358822068199515!\n",
      "Running configuration: timesteps=6000, layers=2, heads=8, image_tokens=1, user_tokens=4, learning_rate=0.0001, optimizer=adamw, scheduler=reduce_on_plateau, batch_size=128, noise_schedule=linear, samples_per_user=50, objective=noise-pred, use_ue=True\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Gabriel\\anaconda3\\envs\\recgensys-env\\lib\\site-packages\\torch\\nn\\modules\\transformer.py:306: UserWarning: enable_nested_tensor is True, but self.use_nested_tensor is False because encoder_layer.norm_first was True\n",
      "  warnings.warn(f\"enable_nested_tensor is True, but self.use_nested_tensor is False because {why_not_sparsity_fast_path}\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Early stopping with best val loss: 0.11743206484243274!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Hyperparameter combinations:   4%|▎         | 13/360 [34:42<14:35:51, 151.45s/it]c:\\Users\\Gabriel\\anaconda3\\envs\\recgensys-env\\lib\\site-packages\\torch\\nn\\modules\\transformer.py:306: UserWarning: enable_nested_tensor is True, but self.use_nested_tensor is False because encoder_layer.norm_first was True\n",
      "  warnings.warn(f\"enable_nested_tensor is True, but self.use_nested_tensor is False because {why_not_sparsity_fast_path}\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running configuration: timesteps=6000, layers=2, heads=8, image_tokens=1, user_tokens=4, learning_rate=0.0001, optimizer=adamw, scheduler=reduce_on_plateau, batch_size=128, noise_schedule=linear, samples_per_user=50, objective=noise-pred, use_ue=False\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Hyperparameter combinations:   4%|▍         | 14/360 [36:36<13:28:59, 140.29s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Early stopping with best val loss: 0.10153397498652339!\n",
      "Running configuration: timesteps=6000, layers=2, heads=8, image_tokens=1, user_tokens=4, learning_rate=0.0001, optimizer=adamw, scheduler=reduce_on_plateau, batch_size=128, noise_schedule=linear, samples_per_user=80, objective=noise-pred, use_ue=True\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Gabriel\\anaconda3\\envs\\recgensys-env\\lib\\site-packages\\torch\\nn\\modules\\transformer.py:306: UserWarning: enable_nested_tensor is True, but self.use_nested_tensor is False because encoder_layer.norm_first was True\n",
      "  warnings.warn(f\"enable_nested_tensor is True, but self.use_nested_tensor is False because {why_not_sparsity_fast_path}\")\n",
      "Hyperparameter combinations:   4%|▍         | 15/360 [39:58<15:13:28, 158.87s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Early stopping with best val loss: 0.10548880975693464!\n",
      "Running configuration: timesteps=6000, layers=2, heads=8, image_tokens=1, user_tokens=4, learning_rate=0.0001, optimizer=adamw, scheduler=reduce_on_plateau, batch_size=128, noise_schedule=linear, samples_per_user=80, objective=noise-pred, use_ue=False\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Gabriel\\anaconda3\\envs\\recgensys-env\\lib\\site-packages\\torch\\nn\\modules\\transformer.py:306: UserWarning: enable_nested_tensor is True, but self.use_nested_tensor is False because encoder_layer.norm_first was True\n",
      "  warnings.warn(f\"enable_nested_tensor is True, but self.use_nested_tensor is False because {why_not_sparsity_fast_path}\")\n",
      "Hyperparameter combinations:   4%|▍         | 16/360 [42:09<14:22:24, 150.42s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Early stopping with best val loss: 0.0847008591517806!\n",
      "Running configuration: timesteps=6000, layers=2, heads=8, image_tokens=1, user_tokens=4, learning_rate=0.0001, optimizer=adamw, scheduler=reduce_on_plateau, batch_size=128, noise_schedule=linear, samples_per_user=110, objective=noise-pred, use_ue=True\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Gabriel\\anaconda3\\envs\\recgensys-env\\lib\\site-packages\\torch\\nn\\modules\\transformer.py:306: UserWarning: enable_nested_tensor is True, but self.use_nested_tensor is False because encoder_layer.norm_first was True\n",
      "  warnings.warn(f\"enable_nested_tensor is True, but self.use_nested_tensor is False because {why_not_sparsity_fast_path}\")\n",
      "Hyperparameter combinations:   5%|▍         | 17/360 [46:10<16:54:49, 177.52s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Early stopping with best val loss: 0.07307655573822558!\n",
      "Running configuration: timesteps=6000, layers=2, heads=8, image_tokens=1, user_tokens=4, learning_rate=0.0001, optimizer=adamw, scheduler=reduce_on_plateau, batch_size=128, noise_schedule=linear, samples_per_user=110, objective=noise-pred, use_ue=False\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Gabriel\\anaconda3\\envs\\recgensys-env\\lib\\site-packages\\torch\\nn\\modules\\transformer.py:306: UserWarning: enable_nested_tensor is True, but self.use_nested_tensor is False because encoder_layer.norm_first was True\n",
      "  warnings.warn(f\"enable_nested_tensor is True, but self.use_nested_tensor is False because {why_not_sparsity_fast_path}\")\n",
      "Hyperparameter combinations:   5%|▌         | 18/360 [48:21<15:32:24, 163.58s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Early stopping with best val loss: 0.09166867705062032!\n",
      "Running configuration: timesteps=6000, layers=2, heads=8, image_tokens=1, user_tokens=4, learning_rate=0.0001, optimizer=adamw, scheduler=reduce_on_plateau, batch_size=128, noise_schedule=linear, samples_per_user=140, objective=noise-pred, use_ue=True\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Gabriel\\anaconda3\\envs\\recgensys-env\\lib\\site-packages\\torch\\nn\\modules\\transformer.py:306: UserWarning: enable_nested_tensor is True, but self.use_nested_tensor is False because encoder_layer.norm_first was True\n",
      "  warnings.warn(f\"enable_nested_tensor is True, but self.use_nested_tensor is False because {why_not_sparsity_fast_path}\")\n",
      "Hyperparameter combinations:   5%|▌         | 19/360 [52:26<17:49:41, 188.22s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Early stopping with best val loss: 0.08150985767133534!\n",
      "Running configuration: timesteps=6000, layers=2, heads=8, image_tokens=1, user_tokens=4, learning_rate=0.0001, optimizer=adamw, scheduler=reduce_on_plateau, batch_size=128, noise_schedule=linear, samples_per_user=140, objective=noise-pred, use_ue=False\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Gabriel\\anaconda3\\envs\\recgensys-env\\lib\\site-packages\\torch\\nn\\modules\\transformer.py:306: UserWarning: enable_nested_tensor is True, but self.use_nested_tensor is False because encoder_layer.norm_first was True\n",
      "  warnings.warn(f\"enable_nested_tensor is True, but self.use_nested_tensor is False because {why_not_sparsity_fast_path}\")\n",
      "Hyperparameter combinations:   6%|▌         | 20/360 [56:08<18:42:49, 198.14s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Early stopping with best val loss: 0.07890545786358416!\n",
      "Running configuration: timesteps=6000, layers=2, heads=8, image_tokens=4, user_tokens=1, learning_rate=0.0001, optimizer=adamw, scheduler=reduce_on_plateau, batch_size=128, noise_schedule=linear, samples_per_user=30, objective=noise-pred, use_ue=True\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Gabriel\\anaconda3\\envs\\recgensys-env\\lib\\site-packages\\torch\\nn\\modules\\transformer.py:306: UserWarning: enable_nested_tensor is True, but self.use_nested_tensor is False because encoder_layer.norm_first was True\n",
      "  warnings.warn(f\"enable_nested_tensor is True, but self.use_nested_tensor is False because {why_not_sparsity_fast_path}\")\n",
      "Hyperparameter combinations:   6%|▌         | 21/360 [56:39<13:56:58, 148.14s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Early stopping with best val loss: 0.15054094465449452!\n",
      "Running configuration: timesteps=6000, layers=2, heads=8, image_tokens=4, user_tokens=1, learning_rate=0.0001, optimizer=adamw, scheduler=reduce_on_plateau, batch_size=128, noise_schedule=linear, samples_per_user=30, objective=noise-pred, use_ue=False\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Gabriel\\anaconda3\\envs\\recgensys-env\\lib\\site-packages\\torch\\nn\\modules\\transformer.py:306: UserWarning: enable_nested_tensor is True, but self.use_nested_tensor is False because encoder_layer.norm_first was True\n",
      "  warnings.warn(f\"enable_nested_tensor is True, but self.use_nested_tensor is False because {why_not_sparsity_fast_path}\")\n",
      "Hyperparameter combinations:   6%|▌         | 22/360 [57:15<10:44:28, 114.40s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Early stopping with best val loss: 0.15324912499636412!\n",
      "Running configuration: timesteps=6000, layers=2, heads=8, image_tokens=4, user_tokens=1, learning_rate=0.0001, optimizer=adamw, scheduler=reduce_on_plateau, batch_size=128, noise_schedule=linear, samples_per_user=50, objective=noise-pred, use_ue=True\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Gabriel\\anaconda3\\envs\\recgensys-env\\lib\\site-packages\\torch\\nn\\modules\\transformer.py:306: UserWarning: enable_nested_tensor is True, but self.use_nested_tensor is False because encoder_layer.norm_first was True\n",
      "  warnings.warn(f\"enable_nested_tensor is True, but self.use_nested_tensor is False because {why_not_sparsity_fast_path}\")\n",
      "Hyperparameter combinations:   6%|▋         | 23/360 [58:24<9:26:56, 100.94s/it] "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Early stopping with best val loss: 0.1295747822150588!\n",
      "Running configuration: timesteps=6000, layers=2, heads=8, image_tokens=4, user_tokens=1, learning_rate=0.0001, optimizer=adamw, scheduler=reduce_on_plateau, batch_size=128, noise_schedule=linear, samples_per_user=50, objective=noise-pred, use_ue=False\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Gabriel\\anaconda3\\envs\\recgensys-env\\lib\\site-packages\\torch\\nn\\modules\\transformer.py:306: UserWarning: enable_nested_tensor is True, but self.use_nested_tensor is False because encoder_layer.norm_first was True\n",
      "  warnings.warn(f\"enable_nested_tensor is True, but self.use_nested_tensor is False because {why_not_sparsity_fast_path}\")\n",
      "Hyperparameter combinations:   7%|▋         | 24/360 [59:35<8:34:49, 91.93s/it] "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Early stopping with best val loss: 0.13791871536523104!\n",
      "Running configuration: timesteps=6000, layers=2, heads=8, image_tokens=4, user_tokens=1, learning_rate=0.0001, optimizer=adamw, scheduler=reduce_on_plateau, batch_size=128, noise_schedule=linear, samples_per_user=80, objective=noise-pred, use_ue=True\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Gabriel\\anaconda3\\envs\\recgensys-env\\lib\\site-packages\\torch\\nn\\modules\\transformer.py:306: UserWarning: enable_nested_tensor is True, but self.use_nested_tensor is False because encoder_layer.norm_first was True\n",
      "  warnings.warn(f\"enable_nested_tensor is True, but self.use_nested_tensor is False because {why_not_sparsity_fast_path}\")\n",
      "Hyperparameter combinations:   7%|▋         | 25/360 [1:01:15<8:46:53, 94.37s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Early stopping with best val loss: 0.1155614610761404!\n",
      "Running configuration: timesteps=6000, layers=2, heads=8, image_tokens=4, user_tokens=1, learning_rate=0.0001, optimizer=adamw, scheduler=reduce_on_plateau, batch_size=128, noise_schedule=linear, samples_per_user=80, objective=noise-pred, use_ue=False\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Gabriel\\anaconda3\\envs\\recgensys-env\\lib\\site-packages\\torch\\nn\\modules\\transformer.py:306: UserWarning: enable_nested_tensor is True, but self.use_nested_tensor is False because encoder_layer.norm_first was True\n",
      "  warnings.warn(f\"enable_nested_tensor is True, but self.use_nested_tensor is False because {why_not_sparsity_fast_path}\")\n",
      "Hyperparameter combinations:   7%|▋         | 26/360 [1:02:13<7:43:53, 83.34s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Early stopping with best val loss: 0.11653161328285933!\n",
      "Running configuration: timesteps=6000, layers=2, heads=8, image_tokens=4, user_tokens=1, learning_rate=0.0001, optimizer=adamw, scheduler=reduce_on_plateau, batch_size=128, noise_schedule=linear, samples_per_user=110, objective=noise-pred, use_ue=True\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Gabriel\\anaconda3\\envs\\recgensys-env\\lib\\site-packages\\torch\\nn\\modules\\transformer.py:306: UserWarning: enable_nested_tensor is True, but self.use_nested_tensor is False because encoder_layer.norm_first was True\n",
      "  warnings.warn(f\"enable_nested_tensor is True, but self.use_nested_tensor is False because {why_not_sparsity_fast_path}\")\n",
      "Hyperparameter combinations:   8%|▊         | 27/360 [1:03:13<7:04:02, 76.40s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Early stopping with best val loss: 0.12409888999536633!\n",
      "Running configuration: timesteps=6000, layers=2, heads=8, image_tokens=4, user_tokens=1, learning_rate=0.0001, optimizer=adamw, scheduler=reduce_on_plateau, batch_size=128, noise_schedule=linear, samples_per_user=110, objective=noise-pred, use_ue=False\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Gabriel\\anaconda3\\envs\\recgensys-env\\lib\\site-packages\\torch\\nn\\modules\\transformer.py:306: UserWarning: enable_nested_tensor is True, but self.use_nested_tensor is False because encoder_layer.norm_first was True\n",
      "  warnings.warn(f\"enable_nested_tensor is True, but self.use_nested_tensor is False because {why_not_sparsity_fast_path}\")\n",
      "Hyperparameter combinations:   8%|▊         | 28/360 [1:04:44<7:27:26, 80.86s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Early stopping with best val loss: 0.10780710587278008!\n",
      "Running configuration: timesteps=6000, layers=2, heads=8, image_tokens=4, user_tokens=1, learning_rate=0.0001, optimizer=adamw, scheduler=reduce_on_plateau, batch_size=128, noise_schedule=linear, samples_per_user=140, objective=noise-pred, use_ue=True\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Gabriel\\anaconda3\\envs\\recgensys-env\\lib\\site-packages\\torch\\nn\\modules\\transformer.py:306: UserWarning: enable_nested_tensor is True, but self.use_nested_tensor is False because encoder_layer.norm_first was True\n",
      "  warnings.warn(f\"enable_nested_tensor is True, but self.use_nested_tensor is False because {why_not_sparsity_fast_path}\")\n",
      "Hyperparameter combinations:   8%|▊         | 29/360 [1:06:22<7:54:20, 85.98s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Early stopping with best val loss: 0.10224636970087886!\n",
      "Running configuration: timesteps=6000, layers=2, heads=8, image_tokens=4, user_tokens=1, learning_rate=0.0001, optimizer=adamw, scheduler=reduce_on_plateau, batch_size=128, noise_schedule=linear, samples_per_user=140, objective=noise-pred, use_ue=False\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Gabriel\\anaconda3\\envs\\recgensys-env\\lib\\site-packages\\torch\\nn\\modules\\transformer.py:306: UserWarning: enable_nested_tensor is True, but self.use_nested_tensor is False because encoder_layer.norm_first was True\n",
      "  warnings.warn(f\"enable_nested_tensor is True, but self.use_nested_tensor is False because {why_not_sparsity_fast_path}\")\n",
      "Hyperparameter combinations:   8%|▊         | 30/360 [1:07:42<7:41:38, 83.93s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Early stopping with best val loss: 0.11629694560542703!\n",
      "Running configuration: timesteps=6000, layers=2, heads=8, image_tokens=4, user_tokens=4, learning_rate=0.0001, optimizer=adamw, scheduler=reduce_on_plateau, batch_size=128, noise_schedule=linear, samples_per_user=30, objective=noise-pred, use_ue=True\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Gabriel\\anaconda3\\envs\\recgensys-env\\lib\\site-packages\\torch\\nn\\modules\\transformer.py:306: UserWarning: enable_nested_tensor is True, but self.use_nested_tensor is False because encoder_layer.norm_first was True\n",
      "  warnings.warn(f\"enable_nested_tensor is True, but self.use_nested_tensor is False because {why_not_sparsity_fast_path}\")\n",
      "Hyperparameter combinations:   9%|▊         | 31/360 [1:08:30<6:41:56, 73.30s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Early stopping with best val loss: 0.1425621504895389!\n",
      "Running configuration: timesteps=6000, layers=2, heads=8, image_tokens=4, user_tokens=4, learning_rate=0.0001, optimizer=adamw, scheduler=reduce_on_plateau, batch_size=128, noise_schedule=linear, samples_per_user=30, objective=noise-pred, use_ue=False\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Gabriel\\anaconda3\\envs\\recgensys-env\\lib\\site-packages\\torch\\nn\\modules\\transformer.py:306: UserWarning: enable_nested_tensor is True, but self.use_nested_tensor is False because encoder_layer.norm_first was True\n",
      "  warnings.warn(f\"enable_nested_tensor is True, but self.use_nested_tensor is False because {why_not_sparsity_fast_path}\")\n",
      "Hyperparameter combinations:   9%|▉         | 32/360 [1:09:11<5:48:23, 63.73s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Early stopping with best val loss: 0.1333731571212411!\n",
      "Running configuration: timesteps=6000, layers=2, heads=8, image_tokens=4, user_tokens=4, learning_rate=0.0001, optimizer=adamw, scheduler=reduce_on_plateau, batch_size=128, noise_schedule=linear, samples_per_user=50, objective=noise-pred, use_ue=True\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Gabriel\\anaconda3\\envs\\recgensys-env\\lib\\site-packages\\torch\\nn\\modules\\transformer.py:306: UserWarning: enable_nested_tensor is True, but self.use_nested_tensor is False because encoder_layer.norm_first was True\n",
      "  warnings.warn(f\"enable_nested_tensor is True, but self.use_nested_tensor is False because {why_not_sparsity_fast_path}\")\n",
      "Hyperparameter combinations:   9%|▉         | 33/360 [1:10:14<5:46:11, 63.52s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Early stopping with best val loss: 0.12668199138715863!\n",
      "Running configuration: timesteps=6000, layers=2, heads=8, image_tokens=4, user_tokens=4, learning_rate=0.0001, optimizer=adamw, scheduler=reduce_on_plateau, batch_size=128, noise_schedule=linear, samples_per_user=50, objective=noise-pred, use_ue=False\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Gabriel\\anaconda3\\envs\\recgensys-env\\lib\\site-packages\\torch\\nn\\modules\\transformer.py:306: UserWarning: enable_nested_tensor is True, but self.use_nested_tensor is False because encoder_layer.norm_first was True\n",
      "  warnings.warn(f\"enable_nested_tensor is True, but self.use_nested_tensor is False because {why_not_sparsity_fast_path}\")\n",
      "Hyperparameter combinations:   9%|▉         | 34/360 [1:11:19<5:46:58, 63.86s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Early stopping with best val loss: 0.12145267659798265!\n",
      "Running configuration: timesteps=6000, layers=2, heads=8, image_tokens=4, user_tokens=4, learning_rate=0.0001, optimizer=adamw, scheduler=reduce_on_plateau, batch_size=128, noise_schedule=linear, samples_per_user=80, objective=noise-pred, use_ue=True\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Gabriel\\anaconda3\\envs\\recgensys-env\\lib\\site-packages\\torch\\nn\\modules\\transformer.py:306: UserWarning: enable_nested_tensor is True, but self.use_nested_tensor is False because encoder_layer.norm_first was True\n",
      "  warnings.warn(f\"enable_nested_tensor is True, but self.use_nested_tensor is False because {why_not_sparsity_fast_path}\")\n",
      "Hyperparameter combinations:  10%|▉         | 35/360 [1:12:56<6:38:47, 73.62s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Early stopping with best val loss: 0.11043010139837861!\n",
      "Running configuration: timesteps=6000, layers=2, heads=8, image_tokens=4, user_tokens=4, learning_rate=0.0001, optimizer=adamw, scheduler=reduce_on_plateau, batch_size=128, noise_schedule=linear, samples_per_user=80, objective=noise-pred, use_ue=False\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Gabriel\\anaconda3\\envs\\recgensys-env\\lib\\site-packages\\torch\\nn\\modules\\transformer.py:306: UserWarning: enable_nested_tensor is True, but self.use_nested_tensor is False because encoder_layer.norm_first was True\n",
      "  warnings.warn(f\"enable_nested_tensor is True, but self.use_nested_tensor is False because {why_not_sparsity_fast_path}\")\n",
      "Hyperparameter combinations:  10%|█         | 36/360 [1:13:50<6:06:33, 67.88s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Early stopping with best val loss: 0.12814523139968514!\n",
      "Running configuration: timesteps=6000, layers=2, heads=8, image_tokens=4, user_tokens=4, learning_rate=0.0001, optimizer=adamw, scheduler=reduce_on_plateau, batch_size=128, noise_schedule=linear, samples_per_user=110, objective=noise-pred, use_ue=True\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Gabriel\\anaconda3\\envs\\recgensys-env\\lib\\site-packages\\torch\\nn\\modules\\transformer.py:306: UserWarning: enable_nested_tensor is True, but self.use_nested_tensor is False because encoder_layer.norm_first was True\n",
      "  warnings.warn(f\"enable_nested_tensor is True, but self.use_nested_tensor is False because {why_not_sparsity_fast_path}\")\n",
      "Hyperparameter combinations:  10%|█         | 37/360 [1:15:24<6:47:27, 75.69s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Early stopping with best val loss: 0.1051749438047409!\n",
      "Running configuration: timesteps=6000, layers=2, heads=8, image_tokens=4, user_tokens=4, learning_rate=0.0001, optimizer=adamw, scheduler=reduce_on_plateau, batch_size=128, noise_schedule=linear, samples_per_user=110, objective=noise-pred, use_ue=False\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Gabriel\\anaconda3\\envs\\recgensys-env\\lib\\site-packages\\torch\\nn\\modules\\transformer.py:306: UserWarning: enable_nested_tensor is True, but self.use_nested_tensor is False because encoder_layer.norm_first was True\n",
      "  warnings.warn(f\"enable_nested_tensor is True, but self.use_nested_tensor is False because {why_not_sparsity_fast_path}\")\n",
      "Hyperparameter combinations:  11%|█         | 38/360 [1:17:21<7:53:01, 88.14s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Early stopping with best val loss: 0.11022591637447476!\n",
      "Running configuration: timesteps=6000, layers=2, heads=8, image_tokens=4, user_tokens=4, learning_rate=0.0001, optimizer=adamw, scheduler=reduce_on_plateau, batch_size=128, noise_schedule=linear, samples_per_user=140, objective=noise-pred, use_ue=True\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Gabriel\\anaconda3\\envs\\recgensys-env\\lib\\site-packages\\torch\\nn\\modules\\transformer.py:306: UserWarning: enable_nested_tensor is True, but self.use_nested_tensor is False because encoder_layer.norm_first was True\n",
      "  warnings.warn(f\"enable_nested_tensor is True, but self.use_nested_tensor is False because {why_not_sparsity_fast_path}\")\n",
      "Hyperparameter combinations:  11%|█         | 39/360 [1:18:47<7:47:26, 87.37s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Early stopping with best val loss: 0.11122276168316603!\n",
      "Running configuration: timesteps=6000, layers=2, heads=8, image_tokens=4, user_tokens=4, learning_rate=0.0001, optimizer=adamw, scheduler=reduce_on_plateau, batch_size=128, noise_schedule=linear, samples_per_user=140, objective=noise-pred, use_ue=False\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Gabriel\\anaconda3\\envs\\recgensys-env\\lib\\site-packages\\torch\\nn\\modules\\transformer.py:306: UserWarning: enable_nested_tensor is True, but self.use_nested_tensor is False because encoder_layer.norm_first was True\n",
      "  warnings.warn(f\"enable_nested_tensor is True, but self.use_nested_tensor is False because {why_not_sparsity_fast_path}\")\n",
      "Hyperparameter combinations:  11%|█         | 40/360 [1:21:01<9:00:58, 101.43s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Early stopping with best val loss: 0.10513601126149297!\n",
      "Running configuration: timesteps=6000, layers=2, heads=16, image_tokens=1, user_tokens=1, learning_rate=0.0001, optimizer=adamw, scheduler=reduce_on_plateau, batch_size=128, noise_schedule=linear, samples_per_user=30, objective=noise-pred, use_ue=True\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Gabriel\\anaconda3\\envs\\recgensys-env\\lib\\site-packages\\torch\\nn\\modules\\transformer.py:306: UserWarning: enable_nested_tensor is True, but self.use_nested_tensor is False because encoder_layer.norm_first was True\n",
      "  warnings.warn(f\"enable_nested_tensor is True, but self.use_nested_tensor is False because {why_not_sparsity_fast_path}\")\n",
      "Hyperparameter combinations:  11%|█▏        | 41/360 [1:22:42<8:58:05, 101.21s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Early stopping with best val loss: 0.12173365941271186!\n",
      "Running configuration: timesteps=6000, layers=2, heads=16, image_tokens=1, user_tokens=1, learning_rate=0.0001, optimizer=adamw, scheduler=reduce_on_plateau, batch_size=128, noise_schedule=linear, samples_per_user=30, objective=noise-pred, use_ue=False\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Gabriel\\anaconda3\\envs\\recgensys-env\\lib\\site-packages\\torch\\nn\\modules\\transformer.py:306: UserWarning: enable_nested_tensor is True, but self.use_nested_tensor is False because encoder_layer.norm_first was True\n",
      "  warnings.warn(f\"enable_nested_tensor is True, but self.use_nested_tensor is False because {why_not_sparsity_fast_path}\")\n",
      "Hyperparameter combinations:  12%|█▏        | 42/360 [1:24:23<8:56:38, 101.25s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Early stopping with best val loss: 0.10586275719106197!\n",
      "Running configuration: timesteps=6000, layers=2, heads=16, image_tokens=1, user_tokens=1, learning_rate=0.0001, optimizer=adamw, scheduler=reduce_on_plateau, batch_size=128, noise_schedule=linear, samples_per_user=50, objective=noise-pred, use_ue=True\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Gabriel\\anaconda3\\envs\\recgensys-env\\lib\\site-packages\\torch\\nn\\modules\\transformer.py:306: UserWarning: enable_nested_tensor is True, but self.use_nested_tensor is False because encoder_layer.norm_first was True\n",
      "  warnings.warn(f\"enable_nested_tensor is True, but self.use_nested_tensor is False because {why_not_sparsity_fast_path}\")\n",
      "Hyperparameter combinations:  12%|█▏        | 43/360 [1:26:12<9:06:40, 103.47s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Early stopping with best val loss: 0.11246055830270052!\n",
      "Running configuration: timesteps=6000, layers=2, heads=16, image_tokens=1, user_tokens=1, learning_rate=0.0001, optimizer=adamw, scheduler=reduce_on_plateau, batch_size=128, noise_schedule=linear, samples_per_user=50, objective=noise-pred, use_ue=False\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Gabriel\\anaconda3\\envs\\recgensys-env\\lib\\site-packages\\torch\\nn\\modules\\transformer.py:306: UserWarning: enable_nested_tensor is True, but self.use_nested_tensor is False because encoder_layer.norm_first was True\n",
      "  warnings.warn(f\"enable_nested_tensor is True, but self.use_nested_tensor is False because {why_not_sparsity_fast_path}\")\n",
      "Hyperparameter combinations:  12%|█▏        | 44/360 [1:28:15<9:35:46, 109.32s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Early stopping with best val loss: 0.1004754682071507!\n",
      "Running configuration: timesteps=6000, layers=2, heads=16, image_tokens=1, user_tokens=1, learning_rate=0.0001, optimizer=adamw, scheduler=reduce_on_plateau, batch_size=128, noise_schedule=linear, samples_per_user=80, objective=noise-pred, use_ue=True\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Gabriel\\anaconda3\\envs\\recgensys-env\\lib\\site-packages\\torch\\nn\\modules\\transformer.py:306: UserWarning: enable_nested_tensor is True, but self.use_nested_tensor is False because encoder_layer.norm_first was True\n",
      "  warnings.warn(f\"enable_nested_tensor is True, but self.use_nested_tensor is False because {why_not_sparsity_fast_path}\")\n",
      "Hyperparameter combinations:  12%|█▎        | 45/360 [1:31:42<12:08:45, 138.81s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Early stopping with best val loss: 0.07155639468692243!\n",
      "Running configuration: timesteps=6000, layers=2, heads=16, image_tokens=1, user_tokens=1, learning_rate=0.0001, optimizer=adamw, scheduler=reduce_on_plateau, batch_size=128, noise_schedule=linear, samples_per_user=80, objective=noise-pred, use_ue=False\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Gabriel\\anaconda3\\envs\\recgensys-env\\lib\\site-packages\\torch\\nn\\modules\\transformer.py:306: UserWarning: enable_nested_tensor is True, but self.use_nested_tensor is False because encoder_layer.norm_first was True\n",
      "  warnings.warn(f\"enable_nested_tensor is True, but self.use_nested_tensor is False because {why_not_sparsity_fast_path}\")\n",
      "Hyperparameter combinations:  13%|█▎        | 46/360 [1:34:08<12:17:22, 140.90s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Early stopping with best val loss: 0.08470006054267287!\n",
      "Running configuration: timesteps=6000, layers=2, heads=16, image_tokens=1, user_tokens=1, learning_rate=0.0001, optimizer=adamw, scheduler=reduce_on_plateau, batch_size=128, noise_schedule=linear, samples_per_user=110, objective=noise-pred, use_ue=True\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Gabriel\\anaconda3\\envs\\recgensys-env\\lib\\site-packages\\torch\\nn\\modules\\transformer.py:306: UserWarning: enable_nested_tensor is True, but self.use_nested_tensor is False because encoder_layer.norm_first was True\n",
      "  warnings.warn(f\"enable_nested_tensor is True, but self.use_nested_tensor is False because {why_not_sparsity_fast_path}\")\n",
      "Hyperparameter combinations:  13%|█▎        | 47/360 [1:38:36<15:34:27, 179.13s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Early stopping with best val loss: 0.07570055755786598!\n",
      "Running configuration: timesteps=6000, layers=2, heads=16, image_tokens=1, user_tokens=1, learning_rate=0.0001, optimizer=adamw, scheduler=reduce_on_plateau, batch_size=128, noise_schedule=linear, samples_per_user=110, objective=noise-pred, use_ue=False\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Gabriel\\anaconda3\\envs\\recgensys-env\\lib\\site-packages\\torch\\nn\\modules\\transformer.py:306: UserWarning: enable_nested_tensor is True, but self.use_nested_tensor is False because encoder_layer.norm_first was True\n",
      "  warnings.warn(f\"enable_nested_tensor is True, but self.use_nested_tensor is False because {why_not_sparsity_fast_path}\")\n",
      "Hyperparameter combinations:  13%|█▎        | 48/360 [1:42:35<17:04:32, 197.03s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Early stopping with best val loss: 0.08211723226122558!\n",
      "Running configuration: timesteps=6000, layers=2, heads=16, image_tokens=1, user_tokens=1, learning_rate=0.0001, optimizer=adamw, scheduler=reduce_on_plateau, batch_size=128, noise_schedule=linear, samples_per_user=140, objective=noise-pred, use_ue=True\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Gabriel\\anaconda3\\envs\\recgensys-env\\lib\\site-packages\\torch\\nn\\modules\\transformer.py:306: UserWarning: enable_nested_tensor is True, but self.use_nested_tensor is False because encoder_layer.norm_first was True\n",
      "  warnings.warn(f\"enable_nested_tensor is True, but self.use_nested_tensor is False because {why_not_sparsity_fast_path}\")\n",
      "Hyperparameter combinations:  14%|█▎        | 49/360 [1:46:16<17:37:55, 204.10s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Early stopping with best val loss: 0.07698993547819555!\n",
      "Running configuration: timesteps=6000, layers=2, heads=16, image_tokens=1, user_tokens=1, learning_rate=0.0001, optimizer=adamw, scheduler=reduce_on_plateau, batch_size=128, noise_schedule=linear, samples_per_user=140, objective=noise-pred, use_ue=False\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Gabriel\\anaconda3\\envs\\recgensys-env\\lib\\site-packages\\torch\\nn\\modules\\transformer.py:306: UserWarning: enable_nested_tensor is True, but self.use_nested_tensor is False because encoder_layer.norm_first was True\n",
      "  warnings.warn(f\"enable_nested_tensor is True, but self.use_nested_tensor is False because {why_not_sparsity_fast_path}\")\n",
      "Hyperparameter combinations:  14%|█▍        | 50/360 [1:50:32<18:55:52, 219.85s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Early stopping with best val loss: 0.07051753369159997!\n",
      "Running configuration: timesteps=6000, layers=2, heads=16, image_tokens=1, user_tokens=4, learning_rate=0.0001, optimizer=adamw, scheduler=reduce_on_plateau, batch_size=128, noise_schedule=linear, samples_per_user=30, objective=noise-pred, use_ue=True\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Gabriel\\anaconda3\\envs\\recgensys-env\\lib\\site-packages\\torch\\nn\\modules\\transformer.py:306: UserWarning: enable_nested_tensor is True, but self.use_nested_tensor is False because encoder_layer.norm_first was True\n",
      "  warnings.warn(f\"enable_nested_tensor is True, but self.use_nested_tensor is False because {why_not_sparsity_fast_path}\")\n",
      "Hyperparameter combinations:  14%|█▍        | 51/360 [1:52:18<15:55:19, 185.50s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Early stopping with best val loss: 0.13368544355034828!\n",
      "Running configuration: timesteps=6000, layers=2, heads=16, image_tokens=1, user_tokens=4, learning_rate=0.0001, optimizer=adamw, scheduler=reduce_on_plateau, batch_size=128, noise_schedule=linear, samples_per_user=30, objective=noise-pred, use_ue=False\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Gabriel\\anaconda3\\envs\\recgensys-env\\lib\\site-packages\\torch\\nn\\modules\\transformer.py:306: UserWarning: enable_nested_tensor is True, but self.use_nested_tensor is False because encoder_layer.norm_first was True\n",
      "  warnings.warn(f\"enable_nested_tensor is True, but self.use_nested_tensor is False because {why_not_sparsity_fast_path}\")\n",
      "Hyperparameter combinations:  14%|█▍        | 52/360 [1:53:44<13:20:09, 155.87s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Early stopping with best val loss: 0.12455751607194543!\n",
      "Running configuration: timesteps=6000, layers=2, heads=16, image_tokens=1, user_tokens=4, learning_rate=0.0001, optimizer=adamw, scheduler=reduce_on_plateau, batch_size=128, noise_schedule=linear, samples_per_user=50, objective=noise-pred, use_ue=True\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Gabriel\\anaconda3\\envs\\recgensys-env\\lib\\site-packages\\torch\\nn\\modules\\transformer.py:306: UserWarning: enable_nested_tensor is True, but self.use_nested_tensor is False because encoder_layer.norm_first was True\n",
      "  warnings.warn(f\"enable_nested_tensor is True, but self.use_nested_tensor is False because {why_not_sparsity_fast_path}\")\n",
      "Hyperparameter combinations:  15%|█▍        | 53/360 [1:56:24<13:23:05, 156.96s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Early stopping with best val loss: 0.11756619112566113!\n",
      "Running configuration: timesteps=6000, layers=2, heads=16, image_tokens=1, user_tokens=4, learning_rate=0.0001, optimizer=adamw, scheduler=reduce_on_plateau, batch_size=128, noise_schedule=linear, samples_per_user=50, objective=noise-pred, use_ue=False\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Gabriel\\anaconda3\\envs\\recgensys-env\\lib\\site-packages\\torch\\nn\\modules\\transformer.py:306: UserWarning: enable_nested_tensor is True, but self.use_nested_tensor is False because encoder_layer.norm_first was True\n",
      "  warnings.warn(f\"enable_nested_tensor is True, but self.use_nested_tensor is False because {why_not_sparsity_fast_path}\")\n",
      "Hyperparameter combinations:  15%|█▌        | 54/360 [1:58:27<12:28:45, 146.81s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Early stopping with best val loss: 0.09501655446365476!\n",
      "Running configuration: timesteps=6000, layers=2, heads=16, image_tokens=1, user_tokens=4, learning_rate=0.0001, optimizer=adamw, scheduler=reduce_on_plateau, batch_size=128, noise_schedule=linear, samples_per_user=80, objective=noise-pred, use_ue=True\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Gabriel\\anaconda3\\envs\\recgensys-env\\lib\\site-packages\\torch\\nn\\modules\\transformer.py:306: UserWarning: enable_nested_tensor is True, but self.use_nested_tensor is False because encoder_layer.norm_first was True\n",
      "  warnings.warn(f\"enable_nested_tensor is True, but self.use_nested_tensor is False because {why_not_sparsity_fast_path}\")\n",
      "Hyperparameter combinations:  15%|█▌        | 55/360 [2:02:16<14:31:47, 171.50s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Early stopping with best val loss: 0.07824590243399143!\n",
      "Running configuration: timesteps=6000, layers=2, heads=16, image_tokens=1, user_tokens=4, learning_rate=0.0001, optimizer=adamw, scheduler=reduce_on_plateau, batch_size=128, noise_schedule=linear, samples_per_user=80, objective=noise-pred, use_ue=False\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Gabriel\\anaconda3\\envs\\recgensys-env\\lib\\site-packages\\torch\\nn\\modules\\transformer.py:306: UserWarning: enable_nested_tensor is True, but self.use_nested_tensor is False because encoder_layer.norm_first was True\n",
      "  warnings.warn(f\"enable_nested_tensor is True, but self.use_nested_tensor is False because {why_not_sparsity_fast_path}\")\n",
      "Hyperparameter combinations:  16%|█▌        | 56/360 [2:05:09<14:30:18, 171.77s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Early stopping with best val loss: 0.07595997769385576!\n",
      "Running configuration: timesteps=6000, layers=2, heads=16, image_tokens=1, user_tokens=4, learning_rate=0.0001, optimizer=adamw, scheduler=reduce_on_plateau, batch_size=128, noise_schedule=linear, samples_per_user=110, objective=noise-pred, use_ue=True\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Gabriel\\anaconda3\\envs\\recgensys-env\\lib\\site-packages\\torch\\nn\\modules\\transformer.py:306: UserWarning: enable_nested_tensor is True, but self.use_nested_tensor is False because encoder_layer.norm_first was True\n",
      "  warnings.warn(f\"enable_nested_tensor is True, but self.use_nested_tensor is False because {why_not_sparsity_fast_path}\")\n",
      "Hyperparameter combinations:  16%|█▌        | 57/360 [2:09:23<16:32:27, 196.53s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Early stopping with best val loss: 0.0830795718356967!\n",
      "Running configuration: timesteps=6000, layers=2, heads=16, image_tokens=1, user_tokens=4, learning_rate=0.0001, optimizer=adamw, scheduler=reduce_on_plateau, batch_size=128, noise_schedule=linear, samples_per_user=110, objective=noise-pred, use_ue=False\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Gabriel\\anaconda3\\envs\\recgensys-env\\lib\\site-packages\\torch\\nn\\modules\\transformer.py:306: UserWarning: enable_nested_tensor is True, but self.use_nested_tensor is False because encoder_layer.norm_first was True\n",
      "  warnings.warn(f\"enable_nested_tensor is True, but self.use_nested_tensor is False because {why_not_sparsity_fast_path}\")\n",
      "Hyperparameter combinations:  16%|█▌        | 58/360 [2:11:44<15:05:22, 179.88s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Early stopping with best val loss: 0.08450309536419809!\n",
      "Running configuration: timesteps=6000, layers=2, heads=16, image_tokens=1, user_tokens=4, learning_rate=0.0001, optimizer=adamw, scheduler=reduce_on_plateau, batch_size=128, noise_schedule=linear, samples_per_user=140, objective=noise-pred, use_ue=True\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Gabriel\\anaconda3\\envs\\recgensys-env\\lib\\site-packages\\torch\\nn\\modules\\transformer.py:306: UserWarning: enable_nested_tensor is True, but self.use_nested_tensor is False because encoder_layer.norm_first was True\n",
      "  warnings.warn(f\"enable_nested_tensor is True, but self.use_nested_tensor is False because {why_not_sparsity_fast_path}\")\n",
      "Hyperparameter combinations:  16%|█▋        | 59/360 [2:16:39<17:56:24, 214.57s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Early stopping with best val loss: 0.06941840914078057!\n",
      "Running configuration: timesteps=6000, layers=2, heads=16, image_tokens=1, user_tokens=4, learning_rate=0.0001, optimizer=adamw, scheduler=reduce_on_plateau, batch_size=128, noise_schedule=linear, samples_per_user=140, objective=noise-pred, use_ue=False\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Gabriel\\anaconda3\\envs\\recgensys-env\\lib\\site-packages\\torch\\nn\\modules\\transformer.py:306: UserWarning: enable_nested_tensor is True, but self.use_nested_tensor is False because encoder_layer.norm_first was True\n",
      "  warnings.warn(f\"enable_nested_tensor is True, but self.use_nested_tensor is False because {why_not_sparsity_fast_path}\")\n",
      "Hyperparameter combinations:  17%|█▋        | 60/360 [2:20:37<18:26:43, 221.34s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Early stopping with best val loss: 0.07033053156919777!\n",
      "Running configuration: timesteps=6000, layers=2, heads=16, image_tokens=4, user_tokens=1, learning_rate=0.0001, optimizer=adamw, scheduler=reduce_on_plateau, batch_size=128, noise_schedule=linear, samples_per_user=30, objective=noise-pred, use_ue=True\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Gabriel\\anaconda3\\envs\\recgensys-env\\lib\\site-packages\\torch\\nn\\modules\\transformer.py:306: UserWarning: enable_nested_tensor is True, but self.use_nested_tensor is False because encoder_layer.norm_first was True\n",
      "  warnings.warn(f\"enable_nested_tensor is True, but self.use_nested_tensor is False because {why_not_sparsity_fast_path}\")\n",
      "Hyperparameter combinations:  17%|█▋        | 61/360 [2:21:39<14:25:05, 173.60s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Early stopping with best val loss: 0.12196246767416596!\n",
      "Running configuration: timesteps=6000, layers=2, heads=16, image_tokens=4, user_tokens=1, learning_rate=0.0001, optimizer=adamw, scheduler=reduce_on_plateau, batch_size=128, noise_schedule=linear, samples_per_user=30, objective=noise-pred, use_ue=False\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Gabriel\\anaconda3\\envs\\recgensys-env\\lib\\site-packages\\torch\\nn\\modules\\transformer.py:306: UserWarning: enable_nested_tensor is True, but self.use_nested_tensor is False because encoder_layer.norm_first was True\n",
      "  warnings.warn(f\"enable_nested_tensor is True, but self.use_nested_tensor is False because {why_not_sparsity_fast_path}\")\n",
      "Hyperparameter combinations:  17%|█▋        | 62/360 [2:22:06<10:44:47, 129.82s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Early stopping with best val loss: 0.17062988504767418!\n",
      "Running configuration: timesteps=6000, layers=2, heads=16, image_tokens=4, user_tokens=1, learning_rate=0.0001, optimizer=adamw, scheduler=reduce_on_plateau, batch_size=128, noise_schedule=linear, samples_per_user=50, objective=noise-pred, use_ue=True\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Gabriel\\anaconda3\\envs\\recgensys-env\\lib\\site-packages\\torch\\nn\\modules\\transformer.py:306: UserWarning: enable_nested_tensor is True, but self.use_nested_tensor is False because encoder_layer.norm_first was True\n",
      "  warnings.warn(f\"enable_nested_tensor is True, but self.use_nested_tensor is False because {why_not_sparsity_fast_path}\")\n",
      "Hyperparameter combinations:  18%|█▊        | 63/360 [2:23:06<8:58:04, 108.70s/it] "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Early stopping with best val loss: 0.13719685096293688!\n",
      "Running configuration: timesteps=6000, layers=2, heads=16, image_tokens=4, user_tokens=1, learning_rate=0.0001, optimizer=adamw, scheduler=reduce_on_plateau, batch_size=128, noise_schedule=linear, samples_per_user=50, objective=noise-pred, use_ue=False\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Gabriel\\anaconda3\\envs\\recgensys-env\\lib\\site-packages\\torch\\nn\\modules\\transformer.py:306: UserWarning: enable_nested_tensor is True, but self.use_nested_tensor is False because encoder_layer.norm_first was True\n",
      "  warnings.warn(f\"enable_nested_tensor is True, but self.use_nested_tensor is False because {why_not_sparsity_fast_path}\")\n",
      "Hyperparameter combinations:  18%|█▊        | 64/360 [2:24:13<7:54:36, 96.20s/it] "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Early stopping with best val loss: 0.12623150600120425!\n",
      "Running configuration: timesteps=6000, layers=2, heads=16, image_tokens=4, user_tokens=1, learning_rate=0.0001, optimizer=adamw, scheduler=reduce_on_plateau, batch_size=128, noise_schedule=linear, samples_per_user=80, objective=noise-pred, use_ue=True\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Gabriel\\anaconda3\\envs\\recgensys-env\\lib\\site-packages\\torch\\nn\\modules\\transformer.py:306: UserWarning: enable_nested_tensor is True, but self.use_nested_tensor is False because encoder_layer.norm_first was True\n",
      "  warnings.warn(f\"enable_nested_tensor is True, but self.use_nested_tensor is False because {why_not_sparsity_fast_path}\")\n",
      "Hyperparameter combinations:  18%|█▊        | 65/360 [2:25:41<7:40:31, 93.67s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Early stopping with best val loss: 0.10383597947657108!\n",
      "Running configuration: timesteps=6000, layers=2, heads=16, image_tokens=4, user_tokens=1, learning_rate=0.0001, optimizer=adamw, scheduler=reduce_on_plateau, batch_size=128, noise_schedule=linear, samples_per_user=80, objective=noise-pred, use_ue=False\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Gabriel\\anaconda3\\envs\\recgensys-env\\lib\\site-packages\\torch\\nn\\modules\\transformer.py:306: UserWarning: enable_nested_tensor is True, but self.use_nested_tensor is False because encoder_layer.norm_first was True\n",
      "  warnings.warn(f\"enable_nested_tensor is True, but self.use_nested_tensor is False because {why_not_sparsity_fast_path}\")\n",
      "Hyperparameter combinations:  18%|█▊        | 66/360 [2:26:46<6:57:55, 85.29s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Early stopping with best val loss: 0.10992499953135848!\n",
      "Running configuration: timesteps=6000, layers=2, heads=16, image_tokens=4, user_tokens=1, learning_rate=0.0001, optimizer=adamw, scheduler=reduce_on_plateau, batch_size=128, noise_schedule=linear, samples_per_user=110, objective=noise-pred, use_ue=True\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Gabriel\\anaconda3\\envs\\recgensys-env\\lib\\site-packages\\torch\\nn\\modules\\transformer.py:306: UserWarning: enable_nested_tensor is True, but self.use_nested_tensor is False because encoder_layer.norm_first was True\n",
      "  warnings.warn(f\"enable_nested_tensor is True, but self.use_nested_tensor is False because {why_not_sparsity_fast_path}\")\n",
      "Hyperparameter combinations:  19%|█▊        | 67/360 [2:28:54<7:58:51, 98.06s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Early stopping with best val loss: 0.09927482157945633!\n",
      "Running configuration: timesteps=6000, layers=2, heads=16, image_tokens=4, user_tokens=1, learning_rate=0.0001, optimizer=adamw, scheduler=reduce_on_plateau, batch_size=128, noise_schedule=linear, samples_per_user=110, objective=noise-pred, use_ue=False\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Gabriel\\anaconda3\\envs\\recgensys-env\\lib\\site-packages\\torch\\nn\\modules\\transformer.py:306: UserWarning: enable_nested_tensor is True, but self.use_nested_tensor is False because encoder_layer.norm_first was True\n",
      "  warnings.warn(f\"enable_nested_tensor is True, but self.use_nested_tensor is False because {why_not_sparsity_fast_path}\")\n",
      "Hyperparameter combinations:  19%|█▉        | 68/360 [2:30:56<8:32:04, 105.22s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Early stopping with best val loss: 0.10175180435180664!\n",
      "Running configuration: timesteps=6000, layers=2, heads=16, image_tokens=4, user_tokens=1, learning_rate=0.0001, optimizer=adamw, scheduler=reduce_on_plateau, batch_size=128, noise_schedule=linear, samples_per_user=140, objective=noise-pred, use_ue=True\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Gabriel\\anaconda3\\envs\\recgensys-env\\lib\\site-packages\\torch\\nn\\modules\\transformer.py:306: UserWarning: enable_nested_tensor is True, but self.use_nested_tensor is False because encoder_layer.norm_first was True\n",
      "  warnings.warn(f\"enable_nested_tensor is True, but self.use_nested_tensor is False because {why_not_sparsity_fast_path}\")\n",
      "Hyperparameter combinations:  19%|█▉        | 69/360 [2:33:19<9:24:32, 116.40s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Early stopping with best val loss: 0.0966133838519454!\n",
      "Running configuration: timesteps=6000, layers=2, heads=16, image_tokens=4, user_tokens=1, learning_rate=0.0001, optimizer=adamw, scheduler=reduce_on_plateau, batch_size=128, noise_schedule=linear, samples_per_user=140, objective=noise-pred, use_ue=False\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Gabriel\\anaconda3\\envs\\recgensys-env\\lib\\site-packages\\torch\\nn\\modules\\transformer.py:306: UserWarning: enable_nested_tensor is True, but self.use_nested_tensor is False because encoder_layer.norm_first was True\n",
      "  warnings.warn(f\"enable_nested_tensor is True, but self.use_nested_tensor is False because {why_not_sparsity_fast_path}\")\n",
      "Hyperparameter combinations:  19%|█▉        | 70/360 [2:35:11<9:16:46, 115.20s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Early stopping with best val loss: 0.10439794603735209!\n",
      "Running configuration: timesteps=6000, layers=2, heads=16, image_tokens=4, user_tokens=4, learning_rate=0.0001, optimizer=adamw, scheduler=reduce_on_plateau, batch_size=128, noise_schedule=linear, samples_per_user=30, objective=noise-pred, use_ue=True\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Gabriel\\anaconda3\\envs\\recgensys-env\\lib\\site-packages\\torch\\nn\\modules\\transformer.py:306: UserWarning: enable_nested_tensor is True, but self.use_nested_tensor is False because encoder_layer.norm_first was True\n",
      "  warnings.warn(f\"enable_nested_tensor is True, but self.use_nested_tensor is False because {why_not_sparsity_fast_path}\")\n",
      "Hyperparameter combinations:  20%|█▉        | 71/360 [2:35:45<7:17:26, 90.82s/it] "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Early stopping with best val loss: 0.16199848474934697!\n",
      "Running configuration: timesteps=6000, layers=2, heads=16, image_tokens=4, user_tokens=4, learning_rate=0.0001, optimizer=adamw, scheduler=reduce_on_plateau, batch_size=128, noise_schedule=linear, samples_per_user=30, objective=noise-pred, use_ue=False\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Gabriel\\anaconda3\\envs\\recgensys-env\\lib\\site-packages\\torch\\nn\\modules\\transformer.py:306: UserWarning: enable_nested_tensor is True, but self.use_nested_tensor is False because encoder_layer.norm_first was True\n",
      "  warnings.warn(f\"enable_nested_tensor is True, but self.use_nested_tensor is False because {why_not_sparsity_fast_path}\")\n",
      "Hyperparameter combinations:  20%|██        | 72/360 [2:36:27<6:06:12, 76.29s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Early stopping with best val loss: 0.15435996651649475!\n",
      "Running configuration: timesteps=6000, layers=2, heads=16, image_tokens=4, user_tokens=4, learning_rate=0.0001, optimizer=adamw, scheduler=reduce_on_plateau, batch_size=128, noise_schedule=linear, samples_per_user=50, objective=noise-pred, use_ue=True\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Gabriel\\anaconda3\\envs\\recgensys-env\\lib\\site-packages\\torch\\nn\\modules\\transformer.py:306: UserWarning: enable_nested_tensor is True, but self.use_nested_tensor is False because encoder_layer.norm_first was True\n",
      "  warnings.warn(f\"enable_nested_tensor is True, but self.use_nested_tensor is False because {why_not_sparsity_fast_path}\")\n",
      "Hyperparameter combinations:  20%|██        | 73/360 [2:37:46<6:08:11, 76.97s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Early stopping with best val loss: 0.11476746527478099!\n",
      "Running configuration: timesteps=6000, layers=2, heads=16, image_tokens=4, user_tokens=4, learning_rate=0.0001, optimizer=adamw, scheduler=reduce_on_plateau, batch_size=128, noise_schedule=linear, samples_per_user=50, objective=noise-pred, use_ue=False\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Gabriel\\anaconda3\\envs\\recgensys-env\\lib\\site-packages\\torch\\nn\\modules\\transformer.py:306: UserWarning: enable_nested_tensor is True, but self.use_nested_tensor is False because encoder_layer.norm_first was True\n",
      "  warnings.warn(f\"enable_nested_tensor is True, but self.use_nested_tensor is False because {why_not_sparsity_fast_path}\")\n",
      "Hyperparameter combinations:  21%|██        | 74/360 [2:38:51<5:50:35, 73.55s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Early stopping with best val loss: 0.11545922700315714!\n",
      "Running configuration: timesteps=6000, layers=2, heads=16, image_tokens=4, user_tokens=4, learning_rate=0.0001, optimizer=adamw, scheduler=reduce_on_plateau, batch_size=128, noise_schedule=linear, samples_per_user=80, objective=noise-pred, use_ue=True\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Gabriel\\anaconda3\\envs\\recgensys-env\\lib\\site-packages\\torch\\nn\\modules\\transformer.py:306: UserWarning: enable_nested_tensor is True, but self.use_nested_tensor is False because encoder_layer.norm_first was True\n",
      "  warnings.warn(f\"enable_nested_tensor is True, but self.use_nested_tensor is False because {why_not_sparsity_fast_path}\")\n",
      "Hyperparameter combinations:  21%|██        | 75/360 [2:40:11<5:57:38, 75.29s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Early stopping with best val loss: 0.12503379909321666!\n",
      "Running configuration: timesteps=6000, layers=2, heads=16, image_tokens=4, user_tokens=4, learning_rate=0.0001, optimizer=adamw, scheduler=reduce_on_plateau, batch_size=128, noise_schedule=linear, samples_per_user=80, objective=noise-pred, use_ue=False\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Gabriel\\anaconda3\\envs\\recgensys-env\\lib\\site-packages\\torch\\nn\\modules\\transformer.py:306: UserWarning: enable_nested_tensor is True, but self.use_nested_tensor is False because encoder_layer.norm_first was True\n",
      "  warnings.warn(f\"enable_nested_tensor is True, but self.use_nested_tensor is False because {why_not_sparsity_fast_path}\")\n",
      "Hyperparameter combinations:  21%|██        | 76/360 [2:41:19<5:45:42, 73.04s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Early stopping with best val loss: 0.11245875479653478!\n",
      "Running configuration: timesteps=6000, layers=2, heads=16, image_tokens=4, user_tokens=4, learning_rate=0.0001, optimizer=adamw, scheduler=reduce_on_plateau, batch_size=128, noise_schedule=linear, samples_per_user=110, objective=noise-pred, use_ue=True\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Gabriel\\anaconda3\\envs\\recgensys-env\\lib\\site-packages\\torch\\nn\\modules\\transformer.py:306: UserWarning: enable_nested_tensor is True, but self.use_nested_tensor is False because encoder_layer.norm_first was True\n",
      "  warnings.warn(f\"enable_nested_tensor is True, but self.use_nested_tensor is False because {why_not_sparsity_fast_path}\")\n",
      "Hyperparameter combinations:  21%|██▏       | 77/360 [2:43:24<6:57:54, 88.60s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Early stopping with best val loss: 0.10016538575291634!\n",
      "Running configuration: timesteps=6000, layers=2, heads=16, image_tokens=4, user_tokens=4, learning_rate=0.0001, optimizer=adamw, scheduler=reduce_on_plateau, batch_size=128, noise_schedule=linear, samples_per_user=110, objective=noise-pred, use_ue=False\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Gabriel\\anaconda3\\envs\\recgensys-env\\lib\\site-packages\\torch\\nn\\modules\\transformer.py:306: UserWarning: enable_nested_tensor is True, but self.use_nested_tensor is False because encoder_layer.norm_first was True\n",
      "  warnings.warn(f\"enable_nested_tensor is True, but self.use_nested_tensor is False because {why_not_sparsity_fast_path}\")\n",
      "Hyperparameter combinations:  22%|██▏       | 78/360 [2:44:56<7:02:19, 89.86s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Early stopping with best val loss: 0.11721170647069812!\n",
      "Running configuration: timesteps=6000, layers=2, heads=16, image_tokens=4, user_tokens=4, learning_rate=0.0001, optimizer=adamw, scheduler=reduce_on_plateau, batch_size=128, noise_schedule=linear, samples_per_user=140, objective=noise-pred, use_ue=True\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Gabriel\\anaconda3\\envs\\recgensys-env\\lib\\site-packages\\torch\\nn\\modules\\transformer.py:306: UserWarning: enable_nested_tensor is True, but self.use_nested_tensor is False because encoder_layer.norm_first was True\n",
      "  warnings.warn(f\"enable_nested_tensor is True, but self.use_nested_tensor is False because {why_not_sparsity_fast_path}\")\n",
      "Hyperparameter combinations:  22%|██▏       | 79/360 [2:46:58<7:45:55, 99.49s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Early stopping with best val loss: 0.1017738045193255!\n",
      "Running configuration: timesteps=6000, layers=2, heads=16, image_tokens=4, user_tokens=4, learning_rate=0.0001, optimizer=adamw, scheduler=reduce_on_plateau, batch_size=128, noise_schedule=linear, samples_per_user=140, objective=noise-pred, use_ue=False\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Gabriel\\anaconda3\\envs\\recgensys-env\\lib\\site-packages\\torch\\nn\\modules\\transformer.py:306: UserWarning: enable_nested_tensor is True, but self.use_nested_tensor is False because encoder_layer.norm_first was True\n",
      "  warnings.warn(f\"enable_nested_tensor is True, but self.use_nested_tensor is False because {why_not_sparsity_fast_path}\")\n",
      "Hyperparameter combinations:  22%|██▏       | 80/360 [2:48:33<7:37:13, 97.98s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Early stopping with best val loss: 0.10364495730027556!\n",
      "Running configuration: timesteps=6000, layers=2, heads=32, image_tokens=1, user_tokens=1, learning_rate=0.0001, optimizer=adamw, scheduler=reduce_on_plateau, batch_size=128, noise_schedule=linear, samples_per_user=30, objective=noise-pred, use_ue=True\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Gabriel\\anaconda3\\envs\\recgensys-env\\lib\\site-packages\\torch\\nn\\modules\\transformer.py:306: UserWarning: enable_nested_tensor is True, but self.use_nested_tensor is False because encoder_layer.norm_first was True\n",
      "  warnings.warn(f\"enable_nested_tensor is True, but self.use_nested_tensor is False because {why_not_sparsity_fast_path}\")\n",
      "Hyperparameter combinations:  22%|██▎       | 81/360 [2:50:21<7:49:35, 100.99s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Early stopping with best val loss: 0.13118382124230266!\n",
      "Running configuration: timesteps=6000, layers=2, heads=32, image_tokens=1, user_tokens=1, learning_rate=0.0001, optimizer=adamw, scheduler=reduce_on_plateau, batch_size=128, noise_schedule=linear, samples_per_user=30, objective=noise-pred, use_ue=False\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Gabriel\\anaconda3\\envs\\recgensys-env\\lib\\site-packages\\torch\\nn\\modules\\transformer.py:306: UserWarning: enable_nested_tensor is True, but self.use_nested_tensor is False because encoder_layer.norm_first was True\n",
      "  warnings.warn(f\"enable_nested_tensor is True, but self.use_nested_tensor is False because {why_not_sparsity_fast_path}\")\n",
      "Hyperparameter combinations:  23%|██▎       | 82/360 [2:52:11<8:01:18, 103.88s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Early stopping with best val loss: 0.1213586856611073!\n",
      "Running configuration: timesteps=6000, layers=2, heads=32, image_tokens=1, user_tokens=1, learning_rate=0.0001, optimizer=adamw, scheduler=reduce_on_plateau, batch_size=128, noise_schedule=linear, samples_per_user=50, objective=noise-pred, use_ue=True\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Gabriel\\anaconda3\\envs\\recgensys-env\\lib\\site-packages\\torch\\nn\\modules\\transformer.py:306: UserWarning: enable_nested_tensor is True, but self.use_nested_tensor is False because encoder_layer.norm_first was True\n",
      "  warnings.warn(f\"enable_nested_tensor is True, but self.use_nested_tensor is False because {why_not_sparsity_fast_path}\")\n",
      "Hyperparameter combinations:  23%|██▎       | 83/360 [2:54:07<8:15:54, 107.42s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Early stopping with best val loss: 0.11073385365307331!\n",
      "Running configuration: timesteps=6000, layers=2, heads=32, image_tokens=1, user_tokens=1, learning_rate=0.0001, optimizer=adamw, scheduler=reduce_on_plateau, batch_size=128, noise_schedule=linear, samples_per_user=50, objective=noise-pred, use_ue=False\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Gabriel\\anaconda3\\envs\\recgensys-env\\lib\\site-packages\\torch\\nn\\modules\\transformer.py:306: UserWarning: enable_nested_tensor is True, but self.use_nested_tensor is False because encoder_layer.norm_first was True\n",
      "  warnings.warn(f\"enable_nested_tensor is True, but self.use_nested_tensor is False because {why_not_sparsity_fast_path}\")\n",
      "Hyperparameter combinations:  23%|██▎       | 84/360 [2:55:52<8:11:19, 106.81s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Early stopping with best val loss: 0.11519768508151174!\n",
      "Running configuration: timesteps=6000, layers=2, heads=32, image_tokens=1, user_tokens=1, learning_rate=0.0001, optimizer=adamw, scheduler=reduce_on_plateau, batch_size=128, noise_schedule=linear, samples_per_user=80, objective=noise-pred, use_ue=True\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Gabriel\\anaconda3\\envs\\recgensys-env\\lib\\site-packages\\torch\\nn\\modules\\transformer.py:306: UserWarning: enable_nested_tensor is True, but self.use_nested_tensor is False because encoder_layer.norm_first was True\n",
      "  warnings.warn(f\"enable_nested_tensor is True, but self.use_nested_tensor is False because {why_not_sparsity_fast_path}\")\n",
      "Hyperparameter combinations:  24%|██▎       | 85/360 [2:59:37<10:51:25, 142.13s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Early stopping with best val loss: 0.08983076876029372!\n",
      "Running configuration: timesteps=6000, layers=2, heads=32, image_tokens=1, user_tokens=1, learning_rate=0.0001, optimizer=adamw, scheduler=reduce_on_plateau, batch_size=128, noise_schedule=linear, samples_per_user=80, objective=noise-pred, use_ue=False\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Gabriel\\anaconda3\\envs\\recgensys-env\\lib\\site-packages\\torch\\nn\\modules\\transformer.py:306: UserWarning: enable_nested_tensor is True, but self.use_nested_tensor is False because encoder_layer.norm_first was True\n",
      "  warnings.warn(f\"enable_nested_tensor is True, but self.use_nested_tensor is False because {why_not_sparsity_fast_path}\")\n",
      "Hyperparameter combinations:  24%|██▍       | 86/360 [3:03:51<13:21:58, 175.62s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Early stopping with best val loss: 0.0666983318515122!\n",
      "Running configuration: timesteps=6000, layers=2, heads=32, image_tokens=1, user_tokens=1, learning_rate=0.0001, optimizer=adamw, scheduler=reduce_on_plateau, batch_size=128, noise_schedule=linear, samples_per_user=110, objective=noise-pred, use_ue=True\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Gabriel\\anaconda3\\envs\\recgensys-env\\lib\\site-packages\\torch\\nn\\modules\\transformer.py:306: UserWarning: enable_nested_tensor is True, but self.use_nested_tensor is False because encoder_layer.norm_first was True\n",
      "  warnings.warn(f\"enable_nested_tensor is True, but self.use_nested_tensor is False because {why_not_sparsity_fast_path}\")\n",
      "Hyperparameter combinations:  24%|██▍       | 87/360 [3:07:47<14:41:47, 193.80s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Early stopping with best val loss: 0.07966776518151164!\n",
      "Running configuration: timesteps=6000, layers=2, heads=32, image_tokens=1, user_tokens=1, learning_rate=0.0001, optimizer=adamw, scheduler=reduce_on_plateau, batch_size=128, noise_schedule=linear, samples_per_user=110, objective=noise-pred, use_ue=False\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Gabriel\\anaconda3\\envs\\recgensys-env\\lib\\site-packages\\torch\\nn\\modules\\transformer.py:306: UserWarning: enable_nested_tensor is True, but self.use_nested_tensor is False because encoder_layer.norm_first was True\n",
      "  warnings.warn(f\"enable_nested_tensor is True, but self.use_nested_tensor is False because {why_not_sparsity_fast_path}\")\n",
      "Hyperparameter combinations:  24%|██▍       | 88/360 [3:10:49<14:22:47, 190.32s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Early stopping with best val loss: 0.07581994263455272!\n",
      "Running configuration: timesteps=6000, layers=2, heads=32, image_tokens=1, user_tokens=1, learning_rate=0.0001, optimizer=adamw, scheduler=reduce_on_plateau, batch_size=128, noise_schedule=linear, samples_per_user=140, objective=noise-pred, use_ue=True\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Gabriel\\anaconda3\\envs\\recgensys-env\\lib\\site-packages\\torch\\nn\\modules\\transformer.py:306: UserWarning: enable_nested_tensor is True, but self.use_nested_tensor is False because encoder_layer.norm_first was True\n",
      "  warnings.warn(f\"enable_nested_tensor is True, but self.use_nested_tensor is False because {why_not_sparsity_fast_path}\")\n",
      "Hyperparameter combinations:  25%|██▍       | 89/360 [3:14:33<15:05:32, 200.49s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Early stopping with best val loss: 0.07023864099755883!\n",
      "Running configuration: timesteps=6000, layers=2, heads=32, image_tokens=1, user_tokens=1, learning_rate=0.0001, optimizer=adamw, scheduler=reduce_on_plateau, batch_size=128, noise_schedule=linear, samples_per_user=140, objective=noise-pred, use_ue=False\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Gabriel\\anaconda3\\envs\\recgensys-env\\lib\\site-packages\\torch\\nn\\modules\\transformer.py:306: UserWarning: enable_nested_tensor is True, but self.use_nested_tensor is False because encoder_layer.norm_first was True\n",
      "  warnings.warn(f\"enable_nested_tensor is True, but self.use_nested_tensor is False because {why_not_sparsity_fast_path}\")\n",
      "Hyperparameter combinations:  25%|██▌       | 90/360 [3:18:38<16:01:37, 213.69s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Early stopping with best val loss: 0.07244739914312959!\n",
      "Running configuration: timesteps=6000, layers=2, heads=32, image_tokens=1, user_tokens=4, learning_rate=0.0001, optimizer=adamw, scheduler=reduce_on_plateau, batch_size=128, noise_schedule=linear, samples_per_user=30, objective=noise-pred, use_ue=True\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Gabriel\\anaconda3\\envs\\recgensys-env\\lib\\site-packages\\torch\\nn\\modules\\transformer.py:306: UserWarning: enable_nested_tensor is True, but self.use_nested_tensor is False because encoder_layer.norm_first was True\n",
      "  warnings.warn(f\"enable_nested_tensor is True, but self.use_nested_tensor is False because {why_not_sparsity_fast_path}\")\n",
      "Hyperparameter combinations:  25%|██▌       | 91/360 [3:20:52<14:11:01, 189.82s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Early stopping with best val loss: 0.1330657615326345!\n",
      "Running configuration: timesteps=6000, layers=2, heads=32, image_tokens=1, user_tokens=4, learning_rate=0.0001, optimizer=adamw, scheduler=reduce_on_plateau, batch_size=128, noise_schedule=linear, samples_per_user=30, objective=noise-pred, use_ue=False\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Gabriel\\anaconda3\\envs\\recgensys-env\\lib\\site-packages\\torch\\nn\\modules\\transformer.py:306: UserWarning: enable_nested_tensor is True, but self.use_nested_tensor is False because encoder_layer.norm_first was True\n",
      "  warnings.warn(f\"enable_nested_tensor is True, but self.use_nested_tensor is False because {why_not_sparsity_fast_path}\")\n",
      "Hyperparameter combinations:  26%|██▌       | 92/360 [3:22:45<12:24:25, 166.66s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Early stopping with best val loss: 0.11394743388518691!\n",
      "Running configuration: timesteps=6000, layers=2, heads=32, image_tokens=1, user_tokens=4, learning_rate=0.0001, optimizer=adamw, scheduler=reduce_on_plateau, batch_size=128, noise_schedule=linear, samples_per_user=50, objective=noise-pred, use_ue=True\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Gabriel\\anaconda3\\envs\\recgensys-env\\lib\\site-packages\\torch\\nn\\modules\\transformer.py:306: UserWarning: enable_nested_tensor is True, but self.use_nested_tensor is False because encoder_layer.norm_first was True\n",
      "  warnings.warn(f\"enable_nested_tensor is True, but self.use_nested_tensor is False because {why_not_sparsity_fast_path}\")\n",
      "Hyperparameter combinations:  26%|██▌       | 93/360 [3:25:03<11:44:29, 158.31s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Early stopping with best val loss: 0.11867405008524656!\n",
      "Running configuration: timesteps=6000, layers=2, heads=32, image_tokens=1, user_tokens=4, learning_rate=0.0001, optimizer=adamw, scheduler=reduce_on_plateau, batch_size=128, noise_schedule=linear, samples_per_user=50, objective=noise-pred, use_ue=False\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Gabriel\\anaconda3\\envs\\recgensys-env\\lib\\site-packages\\torch\\nn\\modules\\transformer.py:306: UserWarning: enable_nested_tensor is True, but self.use_nested_tensor is False because encoder_layer.norm_first was True\n",
      "  warnings.warn(f\"enable_nested_tensor is True, but self.use_nested_tensor is False because {why_not_sparsity_fast_path}\")\n",
      "Hyperparameter combinations:  26%|██▌       | 94/360 [3:27:09<10:58:16, 148.48s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Early stopping with best val loss: 0.10048781707882881!\n",
      "Running configuration: timesteps=6000, layers=2, heads=32, image_tokens=1, user_tokens=4, learning_rate=0.0001, optimizer=adamw, scheduler=reduce_on_plateau, batch_size=128, noise_schedule=linear, samples_per_user=80, objective=noise-pred, use_ue=True\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Gabriel\\anaconda3\\envs\\recgensys-env\\lib\\site-packages\\torch\\nn\\modules\\transformer.py:306: UserWarning: enable_nested_tensor is True, but self.use_nested_tensor is False because encoder_layer.norm_first was True\n",
      "  warnings.warn(f\"enable_nested_tensor is True, but self.use_nested_tensor is False because {why_not_sparsity_fast_path}\")\n",
      "Hyperparameter combinations:  26%|██▋       | 95/360 [3:30:09<11:37:54, 158.02s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Early stopping with best val loss: 0.11031890194863081!\n",
      "Running configuration: timesteps=6000, layers=2, heads=32, image_tokens=1, user_tokens=4, learning_rate=0.0001, optimizer=adamw, scheduler=reduce_on_plateau, batch_size=128, noise_schedule=linear, samples_per_user=80, objective=noise-pred, use_ue=False\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Gabriel\\anaconda3\\envs\\recgensys-env\\lib\\site-packages\\torch\\nn\\modules\\transformer.py:306: UserWarning: enable_nested_tensor is True, but self.use_nested_tensor is False because encoder_layer.norm_first was True\n",
      "  warnings.warn(f\"enable_nested_tensor is True, but self.use_nested_tensor is False because {why_not_sparsity_fast_path}\")\n",
      "Hyperparameter combinations:  27%|██▋       | 96/360 [3:33:11<12:06:09, 165.03s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Early stopping with best val loss: 0.07705842470750213!\n",
      "Running configuration: timesteps=6000, layers=2, heads=32, image_tokens=1, user_tokens=4, learning_rate=0.0001, optimizer=adamw, scheduler=reduce_on_plateau, batch_size=128, noise_schedule=linear, samples_per_user=110, objective=noise-pred, use_ue=True\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Gabriel\\anaconda3\\envs\\recgensys-env\\lib\\site-packages\\torch\\nn\\modules\\transformer.py:306: UserWarning: enable_nested_tensor is True, but self.use_nested_tensor is False because encoder_layer.norm_first was True\n",
      "  warnings.warn(f\"enable_nested_tensor is True, but self.use_nested_tensor is False because {why_not_sparsity_fast_path}\")\n",
      "Hyperparameter combinations:  27%|██▋       | 97/360 [3:37:09<13:39:25, 186.94s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Early stopping with best val loss: 0.09011484403163195!\n",
      "Running configuration: timesteps=6000, layers=2, heads=32, image_tokens=1, user_tokens=4, learning_rate=0.0001, optimizer=adamw, scheduler=reduce_on_plateau, batch_size=128, noise_schedule=linear, samples_per_user=110, objective=noise-pred, use_ue=False\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Gabriel\\anaconda3\\envs\\recgensys-env\\lib\\site-packages\\torch\\nn\\modules\\transformer.py:306: UserWarning: enable_nested_tensor is True, but self.use_nested_tensor is False because encoder_layer.norm_first was True\n",
      "  warnings.warn(f\"enable_nested_tensor is True, but self.use_nested_tensor is False because {why_not_sparsity_fast_path}\")\n",
      "Hyperparameter combinations:  27%|██▋       | 98/360 [3:40:12<13:31:57, 185.94s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Early stopping with best val loss: 0.07609208975918591!\n",
      "Running configuration: timesteps=6000, layers=2, heads=32, image_tokens=1, user_tokens=4, learning_rate=0.0001, optimizer=adamw, scheduler=reduce_on_plateau, batch_size=128, noise_schedule=linear, samples_per_user=140, objective=noise-pred, use_ue=True\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Gabriel\\anaconda3\\envs\\recgensys-env\\lib\\site-packages\\torch\\nn\\modules\\transformer.py:306: UserWarning: enable_nested_tensor is True, but self.use_nested_tensor is False because encoder_layer.norm_first was True\n",
      "  warnings.warn(f\"enable_nested_tensor is True, but self.use_nested_tensor is False because {why_not_sparsity_fast_path}\")\n",
      "Hyperparameter combinations:  28%|██▊       | 99/360 [3:44:36<15:09:47, 209.15s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Early stopping with best val loss: 0.07785779819823802!\n",
      "Running configuration: timesteps=6000, layers=2, heads=32, image_tokens=1, user_tokens=4, learning_rate=0.0001, optimizer=adamw, scheduler=reduce_on_plateau, batch_size=128, noise_schedule=linear, samples_per_user=140, objective=noise-pred, use_ue=False\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Gabriel\\anaconda3\\envs\\recgensys-env\\lib\\site-packages\\torch\\nn\\modules\\transformer.py:306: UserWarning: enable_nested_tensor is True, but self.use_nested_tensor is False because encoder_layer.norm_first was True\n",
      "  warnings.warn(f\"enable_nested_tensor is True, but self.use_nested_tensor is False because {why_not_sparsity_fast_path}\")\n",
      "Hyperparameter combinations:  28%|██▊       | 100/360 [3:48:23<15:29:43, 214.55s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Early stopping with best val loss: 0.06964702950790524!\n",
      "Running configuration: timesteps=6000, layers=2, heads=32, image_tokens=4, user_tokens=1, learning_rate=0.0001, optimizer=adamw, scheduler=reduce_on_plateau, batch_size=128, noise_schedule=linear, samples_per_user=30, objective=noise-pred, use_ue=True\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Gabriel\\anaconda3\\envs\\recgensys-env\\lib\\site-packages\\torch\\nn\\modules\\transformer.py:306: UserWarning: enable_nested_tensor is True, but self.use_nested_tensor is False because encoder_layer.norm_first was True\n",
      "  warnings.warn(f\"enable_nested_tensor is True, but self.use_nested_tensor is False because {why_not_sparsity_fast_path}\")\n",
      "Hyperparameter combinations:  28%|██▊       | 101/360 [3:49:10<11:49:35, 164.38s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Early stopping with best val loss: 0.17196394223719835!\n",
      "Running configuration: timesteps=6000, layers=2, heads=32, image_tokens=4, user_tokens=1, learning_rate=0.0001, optimizer=adamw, scheduler=reduce_on_plateau, batch_size=128, noise_schedule=linear, samples_per_user=30, objective=noise-pred, use_ue=False\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Gabriel\\anaconda3\\envs\\recgensys-env\\lib\\site-packages\\torch\\nn\\modules\\transformer.py:306: UserWarning: enable_nested_tensor is True, but self.use_nested_tensor is False because encoder_layer.norm_first was True\n",
      "  warnings.warn(f\"enable_nested_tensor is True, but self.use_nested_tensor is False because {why_not_sparsity_fast_path}\")\n",
      "Hyperparameter combinations:  28%|██▊       | 102/360 [3:49:52<9:09:00, 127.67s/it] "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Early stopping with best val loss: 0.16513312235474586!\n",
      "Running configuration: timesteps=6000, layers=2, heads=32, image_tokens=4, user_tokens=1, learning_rate=0.0001, optimizer=adamw, scheduler=reduce_on_plateau, batch_size=128, noise_schedule=linear, samples_per_user=50, objective=noise-pred, use_ue=True\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Gabriel\\anaconda3\\envs\\recgensys-env\\lib\\site-packages\\torch\\nn\\modules\\transformer.py:306: UserWarning: enable_nested_tensor is True, but self.use_nested_tensor is False because encoder_layer.norm_first was True\n",
      "  warnings.warn(f\"enable_nested_tensor is True, but self.use_nested_tensor is False because {why_not_sparsity_fast_path}\")\n",
      "Hyperparameter combinations:  29%|██▊       | 103/360 [3:50:58<7:47:32, 109.15s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Early stopping with best val loss: 0.1319132656790316!\n",
      "Running configuration: timesteps=6000, layers=2, heads=32, image_tokens=4, user_tokens=1, learning_rate=0.0001, optimizer=adamw, scheduler=reduce_on_plateau, batch_size=128, noise_schedule=linear, samples_per_user=50, objective=noise-pred, use_ue=False\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Gabriel\\anaconda3\\envs\\recgensys-env\\lib\\site-packages\\torch\\nn\\modules\\transformer.py:306: UserWarning: enable_nested_tensor is True, but self.use_nested_tensor is False because encoder_layer.norm_first was True\n",
      "  warnings.warn(f\"enable_nested_tensor is True, but self.use_nested_tensor is False because {why_not_sparsity_fast_path}\")\n",
      "Hyperparameter combinations:  29%|██▉       | 104/360 [3:51:39<6:18:48, 88.78s/it] "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Early stopping with best val loss: 0.14206070266664028!\n",
      "Running configuration: timesteps=6000, layers=2, heads=32, image_tokens=4, user_tokens=1, learning_rate=0.0001, optimizer=adamw, scheduler=reduce_on_plateau, batch_size=128, noise_schedule=linear, samples_per_user=80, objective=noise-pred, use_ue=True\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Gabriel\\anaconda3\\envs\\recgensys-env\\lib\\site-packages\\torch\\nn\\modules\\transformer.py:306: UserWarning: enable_nested_tensor is True, but self.use_nested_tensor is False because encoder_layer.norm_first was True\n",
      "  warnings.warn(f\"enable_nested_tensor is True, but self.use_nested_tensor is False because {why_not_sparsity_fast_path}\")\n",
      "Hyperparameter combinations:  29%|██▉       | 105/360 [3:53:18<6:30:18, 91.84s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Early stopping with best val loss: 0.10318779828958213!\n",
      "Running configuration: timesteps=6000, layers=2, heads=32, image_tokens=4, user_tokens=1, learning_rate=0.0001, optimizer=adamw, scheduler=reduce_on_plateau, batch_size=128, noise_schedule=linear, samples_per_user=80, objective=noise-pred, use_ue=False\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Gabriel\\anaconda3\\envs\\recgensys-env\\lib\\site-packages\\torch\\nn\\modules\\transformer.py:306: UserWarning: enable_nested_tensor is True, but self.use_nested_tensor is False because encoder_layer.norm_first was True\n",
      "  warnings.warn(f\"enable_nested_tensor is True, but self.use_nested_tensor is False because {why_not_sparsity_fast_path}\")\n",
      "Hyperparameter combinations:  29%|██▉       | 106/360 [3:55:17<7:02:38, 99.84s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Early stopping with best val loss: 0.12568891793489456!\n",
      "Running configuration: timesteps=6000, layers=2, heads=32, image_tokens=4, user_tokens=1, learning_rate=0.0001, optimizer=adamw, scheduler=reduce_on_plateau, batch_size=128, noise_schedule=linear, samples_per_user=110, objective=noise-pred, use_ue=True\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Gabriel\\anaconda3\\envs\\recgensys-env\\lib\\site-packages\\torch\\nn\\modules\\transformer.py:306: UserWarning: enable_nested_tensor is True, but self.use_nested_tensor is False because encoder_layer.norm_first was True\n",
      "  warnings.warn(f\"enable_nested_tensor is True, but self.use_nested_tensor is False because {why_not_sparsity_fast_path}\")\n",
      "Hyperparameter combinations:  30%|██▉       | 107/360 [3:57:13<7:21:20, 104.67s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Early stopping with best val loss: 0.10567644005641341!\n",
      "Running configuration: timesteps=6000, layers=2, heads=32, image_tokens=4, user_tokens=1, learning_rate=0.0001, optimizer=adamw, scheduler=reduce_on_plateau, batch_size=128, noise_schedule=linear, samples_per_user=110, objective=noise-pred, use_ue=False\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Gabriel\\anaconda3\\envs\\recgensys-env\\lib\\site-packages\\torch\\nn\\modules\\transformer.py:306: UserWarning: enable_nested_tensor is True, but self.use_nested_tensor is False because encoder_layer.norm_first was True\n",
      "  warnings.warn(f\"enable_nested_tensor is True, but self.use_nested_tensor is False because {why_not_sparsity_fast_path}\")\n",
      "Hyperparameter combinations:  30%|███       | 108/360 [3:58:37<6:54:11, 98.62s/it] "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Early stopping with best val loss: 0.12457483448088169!\n",
      "Running configuration: timesteps=6000, layers=2, heads=32, image_tokens=4, user_tokens=1, learning_rate=0.0001, optimizer=adamw, scheduler=reduce_on_plateau, batch_size=128, noise_schedule=linear, samples_per_user=140, objective=noise-pred, use_ue=True\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Gabriel\\anaconda3\\envs\\recgensys-env\\lib\\site-packages\\torch\\nn\\modules\\transformer.py:306: UserWarning: enable_nested_tensor is True, but self.use_nested_tensor is False because encoder_layer.norm_first was True\n",
      "  warnings.warn(f\"enable_nested_tensor is True, but self.use_nested_tensor is False because {why_not_sparsity_fast_path}\")\n",
      "Hyperparameter combinations:  30%|███       | 109/360 [4:01:00<7:48:29, 111.99s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Early stopping with best val loss: 0.10495502967387438!\n",
      "Running configuration: timesteps=6000, layers=2, heads=32, image_tokens=4, user_tokens=1, learning_rate=0.0001, optimizer=adamw, scheduler=reduce_on_plateau, batch_size=128, noise_schedule=linear, samples_per_user=140, objective=noise-pred, use_ue=False\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Gabriel\\anaconda3\\envs\\recgensys-env\\lib\\site-packages\\torch\\nn\\modules\\transformer.py:306: UserWarning: enable_nested_tensor is True, but self.use_nested_tensor is False because encoder_layer.norm_first was True\n",
      "  warnings.warn(f\"enable_nested_tensor is True, but self.use_nested_tensor is False because {why_not_sparsity_fast_path}\")\n",
      "Hyperparameter combinations:  31%|███       | 110/360 [4:02:29<7:17:10, 104.92s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Early stopping with best val loss: 0.10685995407402515!\n",
      "Running configuration: timesteps=6000, layers=2, heads=32, image_tokens=4, user_tokens=4, learning_rate=0.0001, optimizer=adamw, scheduler=reduce_on_plateau, batch_size=128, noise_schedule=linear, samples_per_user=30, objective=noise-pred, use_ue=True\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Gabriel\\anaconda3\\envs\\recgensys-env\\lib\\site-packages\\torch\\nn\\modules\\transformer.py:306: UserWarning: enable_nested_tensor is True, but self.use_nested_tensor is False because encoder_layer.norm_first was True\n",
      "  warnings.warn(f\"enable_nested_tensor is True, but self.use_nested_tensor is False because {why_not_sparsity_fast_path}\")\n",
      "Hyperparameter combinations:  31%|███       | 111/360 [4:03:13<5:59:45, 86.69s/it] "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Early stopping with best val loss: 0.15640584006905556!\n",
      "Running configuration: timesteps=6000, layers=2, heads=32, image_tokens=4, user_tokens=4, learning_rate=0.0001, optimizer=adamw, scheduler=reduce_on_plateau, batch_size=128, noise_schedule=linear, samples_per_user=30, objective=noise-pred, use_ue=False\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Gabriel\\anaconda3\\envs\\recgensys-env\\lib\\site-packages\\torch\\nn\\modules\\transformer.py:306: UserWarning: enable_nested_tensor is True, but self.use_nested_tensor is False because encoder_layer.norm_first was True\n",
      "  warnings.warn(f\"enable_nested_tensor is True, but self.use_nested_tensor is False because {why_not_sparsity_fast_path}\")\n",
      "Hyperparameter combinations:  31%|███       | 112/360 [4:03:49<4:56:02, 71.62s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Early stopping with best val loss: 0.1550602624192834!\n",
      "Running configuration: timesteps=6000, layers=2, heads=32, image_tokens=4, user_tokens=4, learning_rate=0.0001, optimizer=adamw, scheduler=reduce_on_plateau, batch_size=128, noise_schedule=linear, samples_per_user=50, objective=noise-pred, use_ue=True\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Gabriel\\anaconda3\\envs\\recgensys-env\\lib\\site-packages\\torch\\nn\\modules\\transformer.py:306: UserWarning: enable_nested_tensor is True, but self.use_nested_tensor is False because encoder_layer.norm_first was True\n",
      "  warnings.warn(f\"enable_nested_tensor is True, but self.use_nested_tensor is False because {why_not_sparsity_fast_path}\")\n",
      "Hyperparameter combinations:  31%|███▏      | 113/360 [4:05:08<5:02:52, 73.57s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Early stopping with best val loss: 0.14047096716240048!\n",
      "Running configuration: timesteps=6000, layers=2, heads=32, image_tokens=4, user_tokens=4, learning_rate=0.0001, optimizer=adamw, scheduler=reduce_on_plateau, batch_size=128, noise_schedule=linear, samples_per_user=50, objective=noise-pred, use_ue=False\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Gabriel\\anaconda3\\envs\\recgensys-env\\lib\\site-packages\\torch\\nn\\modules\\transformer.py:306: UserWarning: enable_nested_tensor is True, but self.use_nested_tensor is False because encoder_layer.norm_first was True\n",
      "  warnings.warn(f\"enable_nested_tensor is True, but self.use_nested_tensor is False because {why_not_sparsity_fast_path}\")\n",
      "Hyperparameter combinations:  32%|███▏      | 114/360 [4:06:02<4:37:59, 67.80s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Early stopping with best val loss: 0.13080997951328754!\n",
      "Running configuration: timesteps=6000, layers=2, heads=32, image_tokens=4, user_tokens=4, learning_rate=0.0001, optimizer=adamw, scheduler=reduce_on_plateau, batch_size=128, noise_schedule=linear, samples_per_user=80, objective=noise-pred, use_ue=True\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Gabriel\\anaconda3\\envs\\recgensys-env\\lib\\site-packages\\torch\\nn\\modules\\transformer.py:306: UserWarning: enable_nested_tensor is True, but self.use_nested_tensor is False because encoder_layer.norm_first was True\n",
      "  warnings.warn(f\"enable_nested_tensor is True, but self.use_nested_tensor is False because {why_not_sparsity_fast_path}\")\n",
      "Hyperparameter combinations:  32%|███▏      | 115/360 [4:07:31<5:02:58, 74.20s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Early stopping with best val loss: 0.10989915253594518!\n",
      "Running configuration: timesteps=6000, layers=2, heads=32, image_tokens=4, user_tokens=4, learning_rate=0.0001, optimizer=adamw, scheduler=reduce_on_plateau, batch_size=128, noise_schedule=linear, samples_per_user=80, objective=noise-pred, use_ue=False\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Gabriel\\anaconda3\\envs\\recgensys-env\\lib\\site-packages\\torch\\nn\\modules\\transformer.py:306: UserWarning: enable_nested_tensor is True, but self.use_nested_tensor is False because encoder_layer.norm_first was True\n",
      "  warnings.warn(f\"enable_nested_tensor is True, but self.use_nested_tensor is False because {why_not_sparsity_fast_path}\")\n",
      "Hyperparameter combinations:  32%|███▏      | 116/360 [4:09:36<6:03:16, 89.33s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Early stopping with best val loss: 0.1114061838015914!\n",
      "Running configuration: timesteps=6000, layers=2, heads=32, image_tokens=4, user_tokens=4, learning_rate=0.0001, optimizer=adamw, scheduler=reduce_on_plateau, batch_size=128, noise_schedule=linear, samples_per_user=110, objective=noise-pred, use_ue=True\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Gabriel\\anaconda3\\envs\\recgensys-env\\lib\\site-packages\\torch\\nn\\modules\\transformer.py:306: UserWarning: enable_nested_tensor is True, but self.use_nested_tensor is False because encoder_layer.norm_first was True\n",
      "  warnings.warn(f\"enable_nested_tensor is True, but self.use_nested_tensor is False because {why_not_sparsity_fast_path}\")\n",
      "Hyperparameter combinations:  32%|███▎      | 117/360 [4:11:43<6:47:32, 100.63s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Early stopping with best val loss: 0.10228525195270777!\n",
      "Running configuration: timesteps=6000, layers=2, heads=32, image_tokens=4, user_tokens=4, learning_rate=0.0001, optimizer=adamw, scheduler=reduce_on_plateau, batch_size=128, noise_schedule=linear, samples_per_user=110, objective=noise-pred, use_ue=False\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Gabriel\\anaconda3\\envs\\recgensys-env\\lib\\site-packages\\torch\\nn\\modules\\transformer.py:306: UserWarning: enable_nested_tensor is True, but self.use_nested_tensor is False because encoder_layer.norm_first was True\n",
      "  warnings.warn(f\"enable_nested_tensor is True, but self.use_nested_tensor is False because {why_not_sparsity_fast_path}\")\n",
      "Hyperparameter combinations:  33%|███▎      | 118/360 [4:13:56<7:25:50, 110.54s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Early stopping with best val loss: 0.10905757127329707!\n",
      "Running configuration: timesteps=6000, layers=2, heads=32, image_tokens=4, user_tokens=4, learning_rate=0.0001, optimizer=adamw, scheduler=reduce_on_plateau, batch_size=128, noise_schedule=linear, samples_per_user=140, objective=noise-pred, use_ue=True\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Gabriel\\anaconda3\\envs\\recgensys-env\\lib\\site-packages\\torch\\nn\\modules\\transformer.py:306: UserWarning: enable_nested_tensor is True, but self.use_nested_tensor is False because encoder_layer.norm_first was True\n",
      "  warnings.warn(f\"enable_nested_tensor is True, but self.use_nested_tensor is False because {why_not_sparsity_fast_path}\")\n",
      "Hyperparameter combinations:  33%|███▎      | 119/360 [4:16:01<7:41:28, 114.89s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Early stopping with best val loss: 0.10036001075059175!\n",
      "Running configuration: timesteps=6000, layers=2, heads=32, image_tokens=4, user_tokens=4, learning_rate=0.0001, optimizer=adamw, scheduler=reduce_on_plateau, batch_size=128, noise_schedule=linear, samples_per_user=140, objective=noise-pred, use_ue=False\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Gabriel\\anaconda3\\envs\\recgensys-env\\lib\\site-packages\\torch\\nn\\modules\\transformer.py:306: UserWarning: enable_nested_tensor is True, but self.use_nested_tensor is False because encoder_layer.norm_first was True\n",
      "  warnings.warn(f\"enable_nested_tensor is True, but self.use_nested_tensor is False because {why_not_sparsity_fast_path}\")\n",
      "Hyperparameter combinations:  33%|███▎      | 120/360 [4:18:21<8:08:50, 122.21s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Early stopping with best val loss: 0.09856185643002391!\n",
      "Running configuration: timesteps=6000, layers=4, heads=8, image_tokens=1, user_tokens=1, learning_rate=0.0001, optimizer=adamw, scheduler=reduce_on_plateau, batch_size=128, noise_schedule=linear, samples_per_user=30, objective=noise-pred, use_ue=True\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Gabriel\\anaconda3\\envs\\recgensys-env\\lib\\site-packages\\torch\\nn\\modules\\transformer.py:306: UserWarning: enable_nested_tensor is True, but self.use_nested_tensor is False because encoder_layer.norm_first was True\n",
      "  warnings.warn(f\"enable_nested_tensor is True, but self.use_nested_tensor is False because {why_not_sparsity_fast_path}\")\n",
      "Hyperparameter combinations:  34%|███▎      | 121/360 [4:21:37<9:35:11, 144.40s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Early stopping with best val loss: 0.1001339415088296!\n",
      "Running configuration: timesteps=6000, layers=4, heads=8, image_tokens=1, user_tokens=1, learning_rate=0.0001, optimizer=adamw, scheduler=reduce_on_plateau, batch_size=128, noise_schedule=linear, samples_per_user=30, objective=noise-pred, use_ue=False\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Gabriel\\anaconda3\\envs\\recgensys-env\\lib\\site-packages\\torch\\nn\\modules\\transformer.py:306: UserWarning: enable_nested_tensor is True, but self.use_nested_tensor is False because encoder_layer.norm_first was True\n",
      "  warnings.warn(f\"enable_nested_tensor is True, but self.use_nested_tensor is False because {why_not_sparsity_fast_path}\")\n",
      "Hyperparameter combinations:  34%|███▍      | 122/360 [4:23:54<9:24:39, 142.35s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Early stopping with best val loss: 0.1083555119112134!\n",
      "Running configuration: timesteps=6000, layers=4, heads=8, image_tokens=1, user_tokens=1, learning_rate=0.0001, optimizer=adamw, scheduler=reduce_on_plateau, batch_size=128, noise_schedule=linear, samples_per_user=50, objective=noise-pred, use_ue=True\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Gabriel\\anaconda3\\envs\\recgensys-env\\lib\\site-packages\\torch\\nn\\modules\\transformer.py:306: UserWarning: enable_nested_tensor is True, but self.use_nested_tensor is False because encoder_layer.norm_first was True\n",
      "  warnings.warn(f\"enable_nested_tensor is True, but self.use_nested_tensor is False because {why_not_sparsity_fast_path}\")\n",
      "Hyperparameter combinations:  34%|███▍      | 123/360 [4:27:50<11:12:15, 170.19s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Early stopping with best val loss: 0.08791447593830526!\n",
      "Running configuration: timesteps=6000, layers=4, heads=8, image_tokens=1, user_tokens=1, learning_rate=0.0001, optimizer=adamw, scheduler=reduce_on_plateau, batch_size=128, noise_schedule=linear, samples_per_user=50, objective=noise-pred, use_ue=False\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Gabriel\\anaconda3\\envs\\recgensys-env\\lib\\site-packages\\torch\\nn\\modules\\transformer.py:306: UserWarning: enable_nested_tensor is True, but self.use_nested_tensor is False because encoder_layer.norm_first was True\n",
      "  warnings.warn(f\"enable_nested_tensor is True, but self.use_nested_tensor is False because {why_not_sparsity_fast_path}\")\n",
      "Hyperparameter combinations:  34%|███▍      | 124/360 [4:30:31<10:58:53, 167.52s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Early stopping with best val loss: 0.09658256312832236!\n",
      "Running configuration: timesteps=6000, layers=4, heads=8, image_tokens=1, user_tokens=1, learning_rate=0.0001, optimizer=adamw, scheduler=reduce_on_plateau, batch_size=128, noise_schedule=linear, samples_per_user=80, objective=noise-pred, use_ue=True\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Gabriel\\anaconda3\\envs\\recgensys-env\\lib\\site-packages\\torch\\nn\\modules\\transformer.py:306: UserWarning: enable_nested_tensor is True, but self.use_nested_tensor is False because encoder_layer.norm_first was True\n",
      "  warnings.warn(f\"enable_nested_tensor is True, but self.use_nested_tensor is False because {why_not_sparsity_fast_path}\")\n",
      "Hyperparameter combinations:  35%|███▍      | 125/360 [4:34:40<12:31:33, 191.89s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Early stopping with best val loss: 0.08248699363321066!\n",
      "Running configuration: timesteps=6000, layers=4, heads=8, image_tokens=1, user_tokens=1, learning_rate=0.0001, optimizer=adamw, scheduler=reduce_on_plateau, batch_size=128, noise_schedule=linear, samples_per_user=80, objective=noise-pred, use_ue=False\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Gabriel\\anaconda3\\envs\\recgensys-env\\lib\\site-packages\\torch\\nn\\modules\\transformer.py:306: UserWarning: enable_nested_tensor is True, but self.use_nested_tensor is False because encoder_layer.norm_first was True\n",
      "  warnings.warn(f\"enable_nested_tensor is True, but self.use_nested_tensor is False because {why_not_sparsity_fast_path}\")\n",
      "Hyperparameter combinations:  35%|███▌      | 126/360 [4:39:51<14:47:50, 227.65s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Early stopping with best val loss: 0.07648544595576823!\n",
      "Running configuration: timesteps=6000, layers=4, heads=8, image_tokens=1, user_tokens=1, learning_rate=0.0001, optimizer=adamw, scheduler=reduce_on_plateau, batch_size=128, noise_schedule=linear, samples_per_user=110, objective=noise-pred, use_ue=True\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Gabriel\\anaconda3\\envs\\recgensys-env\\lib\\site-packages\\torch\\nn\\modules\\transformer.py:306: UserWarning: enable_nested_tensor is True, but self.use_nested_tensor is False because encoder_layer.norm_first was True\n",
      "  warnings.warn(f\"enable_nested_tensor is True, but self.use_nested_tensor is False because {why_not_sparsity_fast_path}\")\n",
      "Hyperparameter combinations:  35%|███▌      | 127/360 [4:49:26<21:29:34, 332.08s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Early stopping with best val loss: 0.06562053179368377!\n",
      "Running configuration: timesteps=6000, layers=4, heads=8, image_tokens=1, user_tokens=1, learning_rate=0.0001, optimizer=adamw, scheduler=reduce_on_plateau, batch_size=128, noise_schedule=linear, samples_per_user=110, objective=noise-pred, use_ue=False\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Gabriel\\anaconda3\\envs\\recgensys-env\\lib\\site-packages\\torch\\nn\\modules\\transformer.py:306: UserWarning: enable_nested_tensor is True, but self.use_nested_tensor is False because encoder_layer.norm_first was True\n",
      "  warnings.warn(f\"enable_nested_tensor is True, but self.use_nested_tensor is False because {why_not_sparsity_fast_path}\")\n",
      "Hyperparameter combinations:  36%|███▌      | 128/360 [4:55:03<21:29:14, 333.42s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Early stopping with best val loss: 0.07744250632822514!\n",
      "Running configuration: timesteps=6000, layers=4, heads=8, image_tokens=1, user_tokens=1, learning_rate=0.0001, optimizer=adamw, scheduler=reduce_on_plateau, batch_size=128, noise_schedule=linear, samples_per_user=140, objective=noise-pred, use_ue=True\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Gabriel\\anaconda3\\envs\\recgensys-env\\lib\\site-packages\\torch\\nn\\modules\\transformer.py:306: UserWarning: enable_nested_tensor is True, but self.use_nested_tensor is False because encoder_layer.norm_first was True\n",
      "  warnings.warn(f\"enable_nested_tensor is True, but self.use_nested_tensor is False because {why_not_sparsity_fast_path}\")\n",
      "Hyperparameter combinations:  36%|███▌      | 129/360 [5:00:08<20:51:11, 324.98s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Early stopping with best val loss: 0.0755647774785757!\n",
      "Running configuration: timesteps=6000, layers=4, heads=8, image_tokens=1, user_tokens=1, learning_rate=0.0001, optimizer=adamw, scheduler=reduce_on_plateau, batch_size=128, noise_schedule=linear, samples_per_user=140, objective=noise-pred, use_ue=False\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Gabriel\\anaconda3\\envs\\recgensys-env\\lib\\site-packages\\torch\\nn\\modules\\transformer.py:306: UserWarning: enable_nested_tensor is True, but self.use_nested_tensor is False because encoder_layer.norm_first was True\n",
      "  warnings.warn(f\"enable_nested_tensor is True, but self.use_nested_tensor is False because {why_not_sparsity_fast_path}\")\n",
      "Hyperparameter combinations:  36%|███▌      | 130/360 [5:07:12<22:39:37, 354.68s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Early stopping with best val loss: 0.07183254836127162!\n",
      "Running configuration: timesteps=6000, layers=4, heads=8, image_tokens=1, user_tokens=4, learning_rate=0.0001, optimizer=adamw, scheduler=reduce_on_plateau, batch_size=128, noise_schedule=linear, samples_per_user=30, objective=noise-pred, use_ue=True\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Gabriel\\anaconda3\\envs\\recgensys-env\\lib\\site-packages\\torch\\nn\\modules\\transformer.py:306: UserWarning: enable_nested_tensor is True, but self.use_nested_tensor is False because encoder_layer.norm_first was True\n",
      "  warnings.warn(f\"enable_nested_tensor is True, but self.use_nested_tensor is False because {why_not_sparsity_fast_path}\")\n",
      "Hyperparameter combinations:  36%|███▋      | 131/360 [5:11:13<20:23:27, 320.56s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Early stopping with best val loss: 0.09607105399481952!\n",
      "Running configuration: timesteps=6000, layers=4, heads=8, image_tokens=1, user_tokens=4, learning_rate=0.0001, optimizer=adamw, scheduler=reduce_on_plateau, batch_size=128, noise_schedule=linear, samples_per_user=30, objective=noise-pred, use_ue=False\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Gabriel\\anaconda3\\envs\\recgensys-env\\lib\\site-packages\\torch\\nn\\modules\\transformer.py:306: UserWarning: enable_nested_tensor is True, but self.use_nested_tensor is False because encoder_layer.norm_first was True\n",
      "  warnings.warn(f\"enable_nested_tensor is True, but self.use_nested_tensor is False because {why_not_sparsity_fast_path}\")\n",
      "Hyperparameter combinations:  37%|███▋      | 132/360 [5:13:10<16:25:33, 259.36s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Early stopping with best val loss: 0.11976212682202458!\n",
      "Running configuration: timesteps=6000, layers=4, heads=8, image_tokens=1, user_tokens=4, learning_rate=0.0001, optimizer=adamw, scheduler=reduce_on_plateau, batch_size=128, noise_schedule=linear, samples_per_user=50, objective=noise-pred, use_ue=True\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Gabriel\\anaconda3\\envs\\recgensys-env\\lib\\site-packages\\torch\\nn\\modules\\transformer.py:306: UserWarning: enable_nested_tensor is True, but self.use_nested_tensor is False because encoder_layer.norm_first was True\n",
      "  warnings.warn(f\"enable_nested_tensor is True, but self.use_nested_tensor is False because {why_not_sparsity_fast_path}\")\n",
      "Hyperparameter combinations:  37%|███▋      | 133/360 [5:17:17<16:07:25, 255.71s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Early stopping with best val loss: 0.08544384711422026!\n",
      "Running configuration: timesteps=6000, layers=4, heads=8, image_tokens=1, user_tokens=4, learning_rate=0.0001, optimizer=adamw, scheduler=reduce_on_plateau, batch_size=128, noise_schedule=linear, samples_per_user=50, objective=noise-pred, use_ue=False\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Gabriel\\anaconda3\\envs\\recgensys-env\\lib\\site-packages\\torch\\nn\\modules\\transformer.py:306: UserWarning: enable_nested_tensor is True, but self.use_nested_tensor is False because encoder_layer.norm_first was True\n",
      "  warnings.warn(f\"enable_nested_tensor is True, but self.use_nested_tensor is False because {why_not_sparsity_fast_path}\")\n",
      "Hyperparameter combinations:  37%|███▋      | 134/360 [5:20:36<14:58:41, 238.59s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Early stopping with best val loss: 0.10075735114514828!\n",
      "Running configuration: timesteps=6000, layers=4, heads=8, image_tokens=1, user_tokens=4, learning_rate=0.0001, optimizer=adamw, scheduler=reduce_on_plateau, batch_size=128, noise_schedule=linear, samples_per_user=80, objective=noise-pred, use_ue=True\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Gabriel\\anaconda3\\envs\\recgensys-env\\lib\\site-packages\\torch\\nn\\modules\\transformer.py:306: UserWarning: enable_nested_tensor is True, but self.use_nested_tensor is False because encoder_layer.norm_first was True\n",
      "  warnings.warn(f\"enable_nested_tensor is True, but self.use_nested_tensor is False because {why_not_sparsity_fast_path}\")\n",
      "Hyperparameter combinations:  38%|███▊      | 135/360 [5:25:59<16:29:41, 263.92s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Early stopping with best val loss: 0.07986512361094356!\n",
      "Running configuration: timesteps=6000, layers=4, heads=8, image_tokens=1, user_tokens=4, learning_rate=0.0001, optimizer=adamw, scheduler=reduce_on_plateau, batch_size=128, noise_schedule=linear, samples_per_user=80, objective=noise-pred, use_ue=False\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Gabriel\\anaconda3\\envs\\recgensys-env\\lib\\site-packages\\torch\\nn\\modules\\transformer.py:306: UserWarning: enable_nested_tensor is True, but self.use_nested_tensor is False because encoder_layer.norm_first was True\n",
      "  warnings.warn(f\"enable_nested_tensor is True, but self.use_nested_tensor is False because {why_not_sparsity_fast_path}\")\n",
      "Hyperparameter combinations:  38%|███▊      | 136/360 [5:29:45<15:43:44, 252.79s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Early stopping with best val loss: 0.0814199149608612!\n",
      "Running configuration: timesteps=6000, layers=4, heads=8, image_tokens=1, user_tokens=4, learning_rate=0.0001, optimizer=adamw, scheduler=reduce_on_plateau, batch_size=128, noise_schedule=linear, samples_per_user=110, objective=noise-pred, use_ue=True\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Gabriel\\anaconda3\\envs\\recgensys-env\\lib\\site-packages\\torch\\nn\\modules\\transformer.py:306: UserWarning: enable_nested_tensor is True, but self.use_nested_tensor is False because encoder_layer.norm_first was True\n",
      "  warnings.warn(f\"enable_nested_tensor is True, but self.use_nested_tensor is False because {why_not_sparsity_fast_path}\")\n",
      "Hyperparameter combinations:  38%|███▊      | 137/360 [5:37:21<19:26:02, 313.73s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Early stopping with best val loss: 0.07790521043352783!\n",
      "Running configuration: timesteps=6000, layers=4, heads=8, image_tokens=1, user_tokens=4, learning_rate=0.0001, optimizer=adamw, scheduler=reduce_on_plateau, batch_size=128, noise_schedule=linear, samples_per_user=110, objective=noise-pred, use_ue=False\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Gabriel\\anaconda3\\envs\\recgensys-env\\lib\\site-packages\\torch\\nn\\modules\\transformer.py:306: UserWarning: enable_nested_tensor is True, but self.use_nested_tensor is False because encoder_layer.norm_first was True\n",
      "  warnings.warn(f\"enable_nested_tensor is True, but self.use_nested_tensor is False because {why_not_sparsity_fast_path}\")\n",
      "Hyperparameter combinations:  38%|███▊      | 138/360 [5:42:27<19:11:37, 311.25s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Early stopping with best val loss: 0.0812495811842382!\n",
      "Running configuration: timesteps=6000, layers=4, heads=8, image_tokens=1, user_tokens=4, learning_rate=0.0001, optimizer=adamw, scheduler=reduce_on_plateau, batch_size=128, noise_schedule=linear, samples_per_user=140, objective=noise-pred, use_ue=True\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Gabriel\\anaconda3\\envs\\recgensys-env\\lib\\site-packages\\torch\\nn\\modules\\transformer.py:306: UserWarning: enable_nested_tensor is True, but self.use_nested_tensor is False because encoder_layer.norm_first was True\n",
      "  warnings.warn(f\"enable_nested_tensor is True, but self.use_nested_tensor is False because {why_not_sparsity_fast_path}\")\n",
      "Hyperparameter combinations:  39%|███▊      | 139/360 [5:50:05<21:49:09, 355.43s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Early stopping with best val loss: 0.07109885243698955!\n",
      "Running configuration: timesteps=6000, layers=4, heads=8, image_tokens=1, user_tokens=4, learning_rate=0.0001, optimizer=adamw, scheduler=reduce_on_plateau, batch_size=128, noise_schedule=linear, samples_per_user=140, objective=noise-pred, use_ue=False\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Gabriel\\anaconda3\\envs\\recgensys-env\\lib\\site-packages\\torch\\nn\\modules\\transformer.py:306: UserWarning: enable_nested_tensor is True, but self.use_nested_tensor is False because encoder_layer.norm_first was True\n",
      "  warnings.warn(f\"enable_nested_tensor is True, but self.use_nested_tensor is False because {why_not_sparsity_fast_path}\")\n",
      "Hyperparameter combinations:  39%|███▉      | 140/360 [5:56:25<22:10:18, 362.81s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Early stopping with best val loss: 0.07241794373840094!\n",
      "Running configuration: timesteps=6000, layers=4, heads=8, image_tokens=4, user_tokens=1, learning_rate=0.0001, optimizer=adamw, scheduler=reduce_on_plateau, batch_size=128, noise_schedule=linear, samples_per_user=30, objective=noise-pred, use_ue=True\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Gabriel\\anaconda3\\envs\\recgensys-env\\lib\\site-packages\\torch\\nn\\modules\\transformer.py:306: UserWarning: enable_nested_tensor is True, but self.use_nested_tensor is False because encoder_layer.norm_first was True\n",
      "  warnings.warn(f\"enable_nested_tensor is True, but self.use_nested_tensor is False because {why_not_sparsity_fast_path}\")\n",
      "Hyperparameter combinations:  39%|███▉      | 141/360 [5:57:41<16:50:08, 276.75s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Early stopping with best val loss: 0.1372044482268393!\n",
      "Running configuration: timesteps=6000, layers=4, heads=8, image_tokens=4, user_tokens=1, learning_rate=0.0001, optimizer=adamw, scheduler=reduce_on_plateau, batch_size=128, noise_schedule=linear, samples_per_user=30, objective=noise-pred, use_ue=False\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Gabriel\\anaconda3\\envs\\recgensys-env\\lib\\site-packages\\torch\\nn\\modules\\transformer.py:306: UserWarning: enable_nested_tensor is True, but self.use_nested_tensor is False because encoder_layer.norm_first was True\n",
      "  warnings.warn(f\"enable_nested_tensor is True, but self.use_nested_tensor is False because {why_not_sparsity_fast_path}\")\n",
      "Hyperparameter combinations:  39%|███▉      | 142/360 [5:59:00<13:09:49, 217.38s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Early stopping with best val loss: 0.13444213941693306!\n",
      "Running configuration: timesteps=6000, layers=4, heads=8, image_tokens=4, user_tokens=1, learning_rate=0.0001, optimizer=adamw, scheduler=reduce_on_plateau, batch_size=128, noise_schedule=linear, samples_per_user=50, objective=noise-pred, use_ue=True\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Gabriel\\anaconda3\\envs\\recgensys-env\\lib\\site-packages\\torch\\nn\\modules\\transformer.py:306: UserWarning: enable_nested_tensor is True, but self.use_nested_tensor is False because encoder_layer.norm_first was True\n",
      "  warnings.warn(f\"enable_nested_tensor is True, but self.use_nested_tensor is False because {why_not_sparsity_fast_path}\")\n",
      "Hyperparameter combinations:  40%|███▉      | 143/360 [6:00:48<11:07:13, 184.49s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Early stopping with best val loss: 0.11017127800732851!\n",
      "Running configuration: timesteps=6000, layers=4, heads=8, image_tokens=4, user_tokens=1, learning_rate=0.0001, optimizer=adamw, scheduler=reduce_on_plateau, batch_size=128, noise_schedule=linear, samples_per_user=50, objective=noise-pred, use_ue=False\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Gabriel\\anaconda3\\envs\\recgensys-env\\lib\\site-packages\\torch\\nn\\modules\\transformer.py:306: UserWarning: enable_nested_tensor is True, but self.use_nested_tensor is False because encoder_layer.norm_first was True\n",
      "  warnings.warn(f\"enable_nested_tensor is True, but self.use_nested_tensor is False because {why_not_sparsity_fast_path}\")\n",
      "Hyperparameter combinations:  40%|████      | 144/360 [6:01:56<8:58:25, 149.56s/it] "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Early stopping with best val loss: 0.1303620133548975!\n",
      "Running configuration: timesteps=6000, layers=4, heads=8, image_tokens=4, user_tokens=1, learning_rate=0.0001, optimizer=adamw, scheduler=reduce_on_plateau, batch_size=128, noise_schedule=linear, samples_per_user=80, objective=noise-pred, use_ue=True\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Gabriel\\anaconda3\\envs\\recgensys-env\\lib\\site-packages\\torch\\nn\\modules\\transformer.py:306: UserWarning: enable_nested_tensor is True, but self.use_nested_tensor is False because encoder_layer.norm_first was True\n",
      "  warnings.warn(f\"enable_nested_tensor is True, but self.use_nested_tensor is False because {why_not_sparsity_fast_path}\")\n",
      "Hyperparameter combinations:  40%|████      | 145/360 [6:04:45<9:16:59, 155.44s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Early stopping with best val loss: 0.09822395024821162!\n",
      "Running configuration: timesteps=6000, layers=4, heads=8, image_tokens=4, user_tokens=1, learning_rate=0.0001, optimizer=adamw, scheduler=reduce_on_plateau, batch_size=128, noise_schedule=linear, samples_per_user=80, objective=noise-pred, use_ue=False\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Gabriel\\anaconda3\\envs\\recgensys-env\\lib\\site-packages\\torch\\nn\\modules\\transformer.py:306: UserWarning: enable_nested_tensor is True, but self.use_nested_tensor is False because encoder_layer.norm_first was True\n",
      "  warnings.warn(f\"enable_nested_tensor is True, but self.use_nested_tensor is False because {why_not_sparsity_fast_path}\")\n",
      "Hyperparameter combinations:  41%|████      | 146/360 [6:06:57<8:49:34, 148.48s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Early stopping with best val loss: 0.1138996914960444!\n",
      "Running configuration: timesteps=6000, layers=4, heads=8, image_tokens=4, user_tokens=1, learning_rate=0.0001, optimizer=adamw, scheduler=reduce_on_plateau, batch_size=128, noise_schedule=linear, samples_per_user=110, objective=noise-pred, use_ue=True\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Gabriel\\anaconda3\\envs\\recgensys-env\\lib\\site-packages\\torch\\nn\\modules\\transformer.py:306: UserWarning: enable_nested_tensor is True, but self.use_nested_tensor is False because encoder_layer.norm_first was True\n",
      "  warnings.warn(f\"enable_nested_tensor is True, but self.use_nested_tensor is False because {why_not_sparsity_fast_path}\")\n",
      "Hyperparameter combinations:  41%|████      | 147/360 [6:08:37<7:54:58, 133.80s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Early stopping with best val loss: 0.1110486350953579!\n",
      "Running configuration: timesteps=6000, layers=4, heads=8, image_tokens=4, user_tokens=1, learning_rate=0.0001, optimizer=adamw, scheduler=reduce_on_plateau, batch_size=128, noise_schedule=linear, samples_per_user=110, objective=noise-pred, use_ue=False\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Gabriel\\anaconda3\\envs\\recgensys-env\\lib\\site-packages\\torch\\nn\\modules\\transformer.py:306: UserWarning: enable_nested_tensor is True, but self.use_nested_tensor is False because encoder_layer.norm_first was True\n",
      "  warnings.warn(f\"enable_nested_tensor is True, but self.use_nested_tensor is False because {why_not_sparsity_fast_path}\")\n",
      "Hyperparameter combinations:  41%|████      | 148/360 [6:11:05<8:08:12, 138.17s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Early stopping with best val loss: 0.10129296220839024!\n",
      "Running configuration: timesteps=6000, layers=4, heads=8, image_tokens=4, user_tokens=1, learning_rate=0.0001, optimizer=adamw, scheduler=reduce_on_plateau, batch_size=128, noise_schedule=linear, samples_per_user=140, objective=noise-pred, use_ue=True\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Gabriel\\anaconda3\\envs\\recgensys-env\\lib\\site-packages\\torch\\nn\\modules\\transformer.py:306: UserWarning: enable_nested_tensor is True, but self.use_nested_tensor is False because encoder_layer.norm_first was True\n",
      "  warnings.warn(f\"enable_nested_tensor is True, but self.use_nested_tensor is False because {why_not_sparsity_fast_path}\")\n",
      "Hyperparameter combinations:  41%|████▏     | 149/360 [6:14:59<9:46:16, 166.72s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Early stopping with best val loss: 0.09593468438833952!\n",
      "Running configuration: timesteps=6000, layers=4, heads=8, image_tokens=4, user_tokens=1, learning_rate=0.0001, optimizer=adamw, scheduler=reduce_on_plateau, batch_size=128, noise_schedule=linear, samples_per_user=140, objective=noise-pred, use_ue=False\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Gabriel\\anaconda3\\envs\\recgensys-env\\lib\\site-packages\\torch\\nn\\modules\\transformer.py:306: UserWarning: enable_nested_tensor is True, but self.use_nested_tensor is False because encoder_layer.norm_first was True\n",
      "  warnings.warn(f\"enable_nested_tensor is True, but self.use_nested_tensor is False because {why_not_sparsity_fast_path}\")\n",
      "Hyperparameter combinations:  42%|████▏     | 150/360 [6:18:01<10:00:09, 171.47s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Early stopping with best val loss: 0.09615327673964202!\n",
      "Running configuration: timesteps=6000, layers=4, heads=8, image_tokens=4, user_tokens=4, learning_rate=0.0001, optimizer=adamw, scheduler=reduce_on_plateau, batch_size=128, noise_schedule=linear, samples_per_user=30, objective=noise-pred, use_ue=True\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Gabriel\\anaconda3\\envs\\recgensys-env\\lib\\site-packages\\torch\\nn\\modules\\transformer.py:306: UserWarning: enable_nested_tensor is True, but self.use_nested_tensor is False because encoder_layer.norm_first was True\n",
      "  warnings.warn(f\"enable_nested_tensor is True, but self.use_nested_tensor is False because {why_not_sparsity_fast_path}\")\n",
      "Hyperparameter combinations:  42%|████▏     | 151/360 [6:19:07<8:06:55, 139.79s/it] "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Early stopping with best val loss: 0.135303377173841!\n",
      "Running configuration: timesteps=6000, layers=4, heads=8, image_tokens=4, user_tokens=4, learning_rate=0.0001, optimizer=adamw, scheduler=reduce_on_plateau, batch_size=128, noise_schedule=linear, samples_per_user=30, objective=noise-pred, use_ue=False\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Gabriel\\anaconda3\\envs\\recgensys-env\\lib\\site-packages\\torch\\nn\\modules\\transformer.py:306: UserWarning: enable_nested_tensor is True, but self.use_nested_tensor is False because encoder_layer.norm_first was True\n",
      "  warnings.warn(f\"enable_nested_tensor is True, but self.use_nested_tensor is False because {why_not_sparsity_fast_path}\")\n",
      "Hyperparameter combinations:  42%|████▏     | 152/360 [6:20:00<6:34:40, 113.85s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Early stopping with best val loss: 0.1474095662124455!\n",
      "Running configuration: timesteps=6000, layers=4, heads=8, image_tokens=4, user_tokens=4, learning_rate=0.0001, optimizer=adamw, scheduler=reduce_on_plateau, batch_size=128, noise_schedule=linear, samples_per_user=50, objective=noise-pred, use_ue=True\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Gabriel\\anaconda3\\envs\\recgensys-env\\lib\\site-packages\\torch\\nn\\modules\\transformer.py:306: UserWarning: enable_nested_tensor is True, but self.use_nested_tensor is False because encoder_layer.norm_first was True\n",
      "  warnings.warn(f\"enable_nested_tensor is True, but self.use_nested_tensor is False because {why_not_sparsity_fast_path}\")\n",
      "Hyperparameter combinations:  42%|████▎     | 153/360 [6:22:24<7:04:00, 122.90s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Early stopping with best val loss: 0.10276222787797451!\n",
      "Running configuration: timesteps=6000, layers=4, heads=8, image_tokens=4, user_tokens=4, learning_rate=0.0001, optimizer=adamw, scheduler=reduce_on_plateau, batch_size=128, noise_schedule=linear, samples_per_user=50, objective=noise-pred, use_ue=False\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Gabriel\\anaconda3\\envs\\recgensys-env\\lib\\site-packages\\torch\\nn\\modules\\transformer.py:306: UserWarning: enable_nested_tensor is True, but self.use_nested_tensor is False because encoder_layer.norm_first was True\n",
      "  warnings.warn(f\"enable_nested_tensor is True, but self.use_nested_tensor is False because {why_not_sparsity_fast_path}\")\n",
      "Hyperparameter combinations:  43%|████▎     | 154/360 [6:24:01<6:34:55, 115.03s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Early stopping with best val loss: 0.11835955921560526!\n",
      "Running configuration: timesteps=6000, layers=4, heads=8, image_tokens=4, user_tokens=4, learning_rate=0.0001, optimizer=adamw, scheduler=reduce_on_plateau, batch_size=128, noise_schedule=linear, samples_per_user=80, objective=noise-pred, use_ue=True\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Gabriel\\anaconda3\\envs\\recgensys-env\\lib\\site-packages\\torch\\nn\\modules\\transformer.py:306: UserWarning: enable_nested_tensor is True, but self.use_nested_tensor is False because encoder_layer.norm_first was True\n",
      "  warnings.warn(f\"enable_nested_tensor is True, but self.use_nested_tensor is False because {why_not_sparsity_fast_path}\")\n",
      "Hyperparameter combinations:  43%|████▎     | 155/360 [6:26:09<6:46:41, 119.03s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Early stopping with best val loss: 0.0969688631594181!\n",
      "Running configuration: timesteps=6000, layers=4, heads=8, image_tokens=4, user_tokens=4, learning_rate=0.0001, optimizer=adamw, scheduler=reduce_on_plateau, batch_size=128, noise_schedule=linear, samples_per_user=80, objective=noise-pred, use_ue=False\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Gabriel\\anaconda3\\envs\\recgensys-env\\lib\\site-packages\\torch\\nn\\modules\\transformer.py:306: UserWarning: enable_nested_tensor is True, but self.use_nested_tensor is False because encoder_layer.norm_first was True\n",
      "  warnings.warn(f\"enable_nested_tensor is True, but self.use_nested_tensor is False because {why_not_sparsity_fast_path}\")\n",
      "Hyperparameter combinations:  43%|████▎     | 156/360 [6:28:20<6:56:19, 122.45s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Early stopping with best val loss: 0.11255081463605165!\n",
      "Running configuration: timesteps=6000, layers=4, heads=8, image_tokens=4, user_tokens=4, learning_rate=0.0001, optimizer=adamw, scheduler=reduce_on_plateau, batch_size=128, noise_schedule=linear, samples_per_user=110, objective=noise-pred, use_ue=True\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Gabriel\\anaconda3\\envs\\recgensys-env\\lib\\site-packages\\torch\\nn\\modules\\transformer.py:306: UserWarning: enable_nested_tensor is True, but self.use_nested_tensor is False because encoder_layer.norm_first was True\n",
      "  warnings.warn(f\"enable_nested_tensor is True, but self.use_nested_tensor is False because {why_not_sparsity_fast_path}\")\n",
      "Hyperparameter combinations:  44%|████▎     | 157/360 [6:31:56<8:29:53, 150.71s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Early stopping with best val loss: 0.09269667509943247!\n",
      "Running configuration: timesteps=6000, layers=4, heads=8, image_tokens=4, user_tokens=4, learning_rate=0.0001, optimizer=adamw, scheduler=reduce_on_plateau, batch_size=128, noise_schedule=linear, samples_per_user=110, objective=noise-pred, use_ue=False\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Gabriel\\anaconda3\\envs\\recgensys-env\\lib\\site-packages\\torch\\nn\\modules\\transformer.py:306: UserWarning: enable_nested_tensor is True, but self.use_nested_tensor is False because encoder_layer.norm_first was True\n",
      "  warnings.warn(f\"enable_nested_tensor is True, but self.use_nested_tensor is False because {why_not_sparsity_fast_path}\")\n",
      "Hyperparameter combinations:  44%|████▍     | 158/360 [6:34:26<8:26:17, 150.38s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Early stopping with best val loss: 0.09545436315238476!\n",
      "Running configuration: timesteps=6000, layers=4, heads=8, image_tokens=4, user_tokens=4, learning_rate=0.0001, optimizer=adamw, scheduler=reduce_on_plateau, batch_size=128, noise_schedule=linear, samples_per_user=140, objective=noise-pred, use_ue=True\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Gabriel\\anaconda3\\envs\\recgensys-env\\lib\\site-packages\\torch\\nn\\modules\\transformer.py:306: UserWarning: enable_nested_tensor is True, but self.use_nested_tensor is False because encoder_layer.norm_first was True\n",
      "  warnings.warn(f\"enable_nested_tensor is True, but self.use_nested_tensor is False because {why_not_sparsity_fast_path}\")\n",
      "Hyperparameter combinations:  44%|████▍     | 159/360 [6:37:26<8:53:27, 159.24s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Early stopping with best val loss: 0.10490289516746998!\n",
      "Running configuration: timesteps=6000, layers=4, heads=8, image_tokens=4, user_tokens=4, learning_rate=0.0001, optimizer=adamw, scheduler=reduce_on_plateau, batch_size=128, noise_schedule=linear, samples_per_user=140, objective=noise-pred, use_ue=False\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Gabriel\\anaconda3\\envs\\recgensys-env\\lib\\site-packages\\torch\\nn\\modules\\transformer.py:306: UserWarning: enable_nested_tensor is True, but self.use_nested_tensor is False because encoder_layer.norm_first was True\n",
      "  warnings.warn(f\"enable_nested_tensor is True, but self.use_nested_tensor is False because {why_not_sparsity_fast_path}\")\n",
      "Hyperparameter combinations:  44%|████▍     | 160/360 [6:40:59<9:44:44, 175.42s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Early stopping with best val loss: 0.09499600832350552!\n",
      "Running configuration: timesteps=6000, layers=4, heads=16, image_tokens=1, user_tokens=1, learning_rate=0.0001, optimizer=adamw, scheduler=reduce_on_plateau, batch_size=128, noise_schedule=linear, samples_per_user=30, objective=noise-pred, use_ue=True\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Gabriel\\anaconda3\\envs\\recgensys-env\\lib\\site-packages\\torch\\nn\\modules\\transformer.py:306: UserWarning: enable_nested_tensor is True, but self.use_nested_tensor is False because encoder_layer.norm_first was True\n",
      "  warnings.warn(f\"enable_nested_tensor is True, but self.use_nested_tensor is False because {why_not_sparsity_fast_path}\")\n",
      "Hyperparameter combinations:  45%|████▍     | 161/360 [6:43:43<9:30:28, 172.00s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Early stopping with best val loss: 0.11116965860128403!\n",
      "Running configuration: timesteps=6000, layers=4, heads=16, image_tokens=1, user_tokens=1, learning_rate=0.0001, optimizer=adamw, scheduler=reduce_on_plateau, batch_size=128, noise_schedule=linear, samples_per_user=30, objective=noise-pred, use_ue=False\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Gabriel\\anaconda3\\envs\\recgensys-env\\lib\\site-packages\\torch\\nn\\modules\\transformer.py:306: UserWarning: enable_nested_tensor is True, but self.use_nested_tensor is False because encoder_layer.norm_first was True\n",
      "  warnings.warn(f\"enable_nested_tensor is True, but self.use_nested_tensor is False because {why_not_sparsity_fast_path}\")\n",
      "Hyperparameter combinations:  45%|████▌     | 162/360 [6:46:56<9:48:16, 178.27s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Early stopping with best val loss: 0.08747826120816171!\n",
      "Running configuration: timesteps=6000, layers=4, heads=16, image_tokens=1, user_tokens=1, learning_rate=0.0001, optimizer=adamw, scheduler=reduce_on_plateau, batch_size=128, noise_schedule=linear, samples_per_user=50, objective=noise-pred, use_ue=True\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Gabriel\\anaconda3\\envs\\recgensys-env\\lib\\site-packages\\torch\\nn\\modules\\transformer.py:306: UserWarning: enable_nested_tensor is True, but self.use_nested_tensor is False because encoder_layer.norm_first was True\n",
      "  warnings.warn(f\"enable_nested_tensor is True, but self.use_nested_tensor is False because {why_not_sparsity_fast_path}\")\n",
      "Hyperparameter combinations:  45%|████▌     | 163/360 [6:50:36<10:25:54, 190.63s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Early stopping with best val loss: 0.1036366275511682!\n",
      "Running configuration: timesteps=6000, layers=4, heads=16, image_tokens=1, user_tokens=1, learning_rate=0.0001, optimizer=adamw, scheduler=reduce_on_plateau, batch_size=128, noise_schedule=linear, samples_per_user=50, objective=noise-pred, use_ue=False\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Gabriel\\anaconda3\\envs\\recgensys-env\\lib\\site-packages\\torch\\nn\\modules\\transformer.py:306: UserWarning: enable_nested_tensor is True, but self.use_nested_tensor is False because encoder_layer.norm_first was True\n",
      "  warnings.warn(f\"enable_nested_tensor is True, but self.use_nested_tensor is False because {why_not_sparsity_fast_path}\")\n",
      "Hyperparameter combinations:  46%|████▌     | 164/360 [6:53:42<10:19:07, 189.53s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Early stopping with best val loss: 0.08731794869527221!\n",
      "Running configuration: timesteps=6000, layers=4, heads=16, image_tokens=1, user_tokens=1, learning_rate=0.0001, optimizer=adamw, scheduler=reduce_on_plateau, batch_size=128, noise_schedule=linear, samples_per_user=80, objective=noise-pred, use_ue=True\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Gabriel\\anaconda3\\envs\\recgensys-env\\lib\\site-packages\\torch\\nn\\modules\\transformer.py:306: UserWarning: enable_nested_tensor is True, but self.use_nested_tensor is False because encoder_layer.norm_first was True\n",
      "  warnings.warn(f\"enable_nested_tensor is True, but self.use_nested_tensor is False because {why_not_sparsity_fast_path}\")\n",
      "Hyperparameter combinations:  46%|████▌     | 165/360 [6:57:46<11:08:38, 205.74s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Early stopping with best val loss: 0.094319524243474!\n",
      "Running configuration: timesteps=6000, layers=4, heads=16, image_tokens=1, user_tokens=1, learning_rate=0.0001, optimizer=adamw, scheduler=reduce_on_plateau, batch_size=128, noise_schedule=linear, samples_per_user=80, objective=noise-pred, use_ue=False\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Gabriel\\anaconda3\\envs\\recgensys-env\\lib\\site-packages\\torch\\nn\\modules\\transformer.py:306: UserWarning: enable_nested_tensor is True, but self.use_nested_tensor is False because encoder_layer.norm_first was True\n",
      "  warnings.warn(f\"enable_nested_tensor is True, but self.use_nested_tensor is False because {why_not_sparsity_fast_path}\")\n",
      "Hyperparameter combinations:  46%|████▌     | 166/360 [7:03:49<13:37:54, 252.96s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Early stopping with best val loss: 0.07163364253938198!\n",
      "Running configuration: timesteps=6000, layers=4, heads=16, image_tokens=1, user_tokens=1, learning_rate=0.0001, optimizer=adamw, scheduler=reduce_on_plateau, batch_size=128, noise_schedule=linear, samples_per_user=110, objective=noise-pred, use_ue=True\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Gabriel\\anaconda3\\envs\\recgensys-env\\lib\\site-packages\\torch\\nn\\modules\\transformer.py:306: UserWarning: enable_nested_tensor is True, but self.use_nested_tensor is False because encoder_layer.norm_first was True\n",
      "  warnings.warn(f\"enable_nested_tensor is True, but self.use_nested_tensor is False because {why_not_sparsity_fast_path}\")\n",
      "Hyperparameter combinations:  46%|████▋     | 167/360 [7:09:14<14:42:34, 274.38s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Early stopping with best val loss: 0.07390216644853354!\n",
      "Running configuration: timesteps=6000, layers=4, heads=16, image_tokens=1, user_tokens=1, learning_rate=0.0001, optimizer=adamw, scheduler=reduce_on_plateau, batch_size=128, noise_schedule=linear, samples_per_user=110, objective=noise-pred, use_ue=False\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Gabriel\\anaconda3\\envs\\recgensys-env\\lib\\site-packages\\torch\\nn\\modules\\transformer.py:306: UserWarning: enable_nested_tensor is True, but self.use_nested_tensor is False because encoder_layer.norm_first was True\n",
      "  warnings.warn(f\"enable_nested_tensor is True, but self.use_nested_tensor is False because {why_not_sparsity_fast_path}\")\n",
      "Hyperparameter combinations:  47%|████▋     | 168/360 [7:13:16<14:07:26, 264.83s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Early stopping with best val loss: 0.07838222431018949!\n",
      "Running configuration: timesteps=6000, layers=4, heads=16, image_tokens=1, user_tokens=1, learning_rate=0.0001, optimizer=adamw, scheduler=reduce_on_plateau, batch_size=128, noise_schedule=linear, samples_per_user=140, objective=noise-pred, use_ue=True\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Gabriel\\anaconda3\\envs\\recgensys-env\\lib\\site-packages\\torch\\nn\\modules\\transformer.py:306: UserWarning: enable_nested_tensor is True, but self.use_nested_tensor is False because encoder_layer.norm_first was True\n",
      "  warnings.warn(f\"enable_nested_tensor is True, but self.use_nested_tensor is False because {why_not_sparsity_fast_path}\")\n",
      "Hyperparameter combinations:  47%|████▋     | 169/360 [7:21:00<17:12:57, 324.49s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Early stopping with best val loss: 0.0734913672786206!\n",
      "Running configuration: timesteps=6000, layers=4, heads=16, image_tokens=1, user_tokens=1, learning_rate=0.0001, optimizer=adamw, scheduler=reduce_on_plateau, batch_size=128, noise_schedule=linear, samples_per_user=140, objective=noise-pred, use_ue=False\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Gabriel\\anaconda3\\envs\\recgensys-env\\lib\\site-packages\\torch\\nn\\modules\\transformer.py:306: UserWarning: enable_nested_tensor is True, but self.use_nested_tensor is False because encoder_layer.norm_first was True\n",
      "  warnings.warn(f\"enable_nested_tensor is True, but self.use_nested_tensor is False because {why_not_sparsity_fast_path}\")\n",
      "Hyperparameter combinations:  47%|████▋     | 170/360 [7:27:36<18:15:20, 345.90s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Early stopping with best val loss: 0.07658628188073635!\n",
      "Running configuration: timesteps=6000, layers=4, heads=16, image_tokens=1, user_tokens=4, learning_rate=0.0001, optimizer=adamw, scheduler=reduce_on_plateau, batch_size=128, noise_schedule=linear, samples_per_user=30, objective=noise-pred, use_ue=True\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Gabriel\\anaconda3\\envs\\recgensys-env\\lib\\site-packages\\torch\\nn\\modules\\transformer.py:306: UserWarning: enable_nested_tensor is True, but self.use_nested_tensor is False because encoder_layer.norm_first was True\n",
      "  warnings.warn(f\"enable_nested_tensor is True, but self.use_nested_tensor is False because {why_not_sparsity_fast_path}\")\n",
      "Hyperparameter combinations:  48%|████▊     | 171/360 [7:31:11<16:06:34, 306.85s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Early stopping with best val loss: 0.09579367213882506!\n",
      "Running configuration: timesteps=6000, layers=4, heads=16, image_tokens=1, user_tokens=4, learning_rate=0.0001, optimizer=adamw, scheduler=reduce_on_plateau, batch_size=128, noise_schedule=linear, samples_per_user=30, objective=noise-pred, use_ue=False\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Gabriel\\anaconda3\\envs\\recgensys-env\\lib\\site-packages\\torch\\nn\\modules\\transformer.py:306: UserWarning: enable_nested_tensor is True, but self.use_nested_tensor is False because encoder_layer.norm_first was True\n",
      "  warnings.warn(f\"enable_nested_tensor is True, but self.use_nested_tensor is False because {why_not_sparsity_fast_path}\")\n",
      "Hyperparameter combinations:  48%|████▊     | 172/360 [7:34:09<13:59:56, 268.07s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Early stopping with best val loss: 0.10166831873357296!\n",
      "Running configuration: timesteps=6000, layers=4, heads=16, image_tokens=1, user_tokens=4, learning_rate=0.0001, optimizer=adamw, scheduler=reduce_on_plateau, batch_size=128, noise_schedule=linear, samples_per_user=50, objective=noise-pred, use_ue=True\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Gabriel\\anaconda3\\envs\\recgensys-env\\lib\\site-packages\\torch\\nn\\modules\\transformer.py:306: UserWarning: enable_nested_tensor is True, but self.use_nested_tensor is False because encoder_layer.norm_first was True\n",
      "  warnings.warn(f\"enable_nested_tensor is True, but self.use_nested_tensor is False because {why_not_sparsity_fast_path}\")\n",
      "Hyperparameter combinations:  48%|████▊     | 173/360 [7:39:38<14:52:38, 286.41s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Early stopping with best val loss: 0.0859475047327578!\n",
      "Running configuration: timesteps=6000, layers=4, heads=16, image_tokens=1, user_tokens=4, learning_rate=0.0001, optimizer=adamw, scheduler=reduce_on_plateau, batch_size=128, noise_schedule=linear, samples_per_user=50, objective=noise-pred, use_ue=False\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Gabriel\\anaconda3\\envs\\recgensys-env\\lib\\site-packages\\torch\\nn\\modules\\transformer.py:306: UserWarning: enable_nested_tensor is True, but self.use_nested_tensor is False because encoder_layer.norm_first was True\n",
      "  warnings.warn(f\"enable_nested_tensor is True, but self.use_nested_tensor is False because {why_not_sparsity_fast_path}\")\n",
      "Hyperparameter combinations:  48%|████▊     | 174/360 [7:43:22<13:50:01, 267.75s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Early stopping with best val loss: 0.09043230349197984!\n",
      "Running configuration: timesteps=6000, layers=4, heads=16, image_tokens=1, user_tokens=4, learning_rate=0.0001, optimizer=adamw, scheduler=reduce_on_plateau, batch_size=128, noise_schedule=linear, samples_per_user=80, objective=noise-pred, use_ue=True\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Gabriel\\anaconda3\\envs\\recgensys-env\\lib\\site-packages\\torch\\nn\\modules\\transformer.py:306: UserWarning: enable_nested_tensor is True, but self.use_nested_tensor is False because encoder_layer.norm_first was True\n",
      "  warnings.warn(f\"enable_nested_tensor is True, but self.use_nested_tensor is False because {why_not_sparsity_fast_path}\")\n",
      "Hyperparameter combinations:  49%|████▊     | 175/360 [7:49:26<15:14:04, 296.46s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Early stopping with best val loss: 0.08114427421241999!\n",
      "Running configuration: timesteps=6000, layers=4, heads=16, image_tokens=1, user_tokens=4, learning_rate=0.0001, optimizer=adamw, scheduler=reduce_on_plateau, batch_size=128, noise_schedule=linear, samples_per_user=80, objective=noise-pred, use_ue=False\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Gabriel\\anaconda3\\envs\\recgensys-env\\lib\\site-packages\\torch\\nn\\modules\\transformer.py:306: UserWarning: enable_nested_tensor is True, but self.use_nested_tensor is False because encoder_layer.norm_first was True\n",
      "  warnings.warn(f\"enable_nested_tensor is True, but self.use_nested_tensor is False because {why_not_sparsity_fast_path}\")\n",
      "Hyperparameter combinations:  49%|████▉     | 176/360 [7:53:10<14:02:40, 274.79s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Early stopping with best val loss: 0.08638627687469125!\n",
      "Running configuration: timesteps=6000, layers=4, heads=16, image_tokens=1, user_tokens=4, learning_rate=0.0001, optimizer=adamw, scheduler=reduce_on_plateau, batch_size=128, noise_schedule=linear, samples_per_user=110, objective=noise-pred, use_ue=True\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Gabriel\\anaconda3\\envs\\recgensys-env\\lib\\site-packages\\torch\\nn\\modules\\transformer.py:306: UserWarning: enable_nested_tensor is True, but self.use_nested_tensor is False because encoder_layer.norm_first was True\n",
      "  warnings.warn(f\"enable_nested_tensor is True, but self.use_nested_tensor is False because {why_not_sparsity_fast_path}\")\n",
      "Hyperparameter combinations:  49%|████▉     | 177/360 [8:01:06<17:02:02, 335.09s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Early stopping with best val loss: 0.07495526620186865!\n",
      "Running configuration: timesteps=6000, layers=4, heads=16, image_tokens=1, user_tokens=4, learning_rate=0.0001, optimizer=adamw, scheduler=reduce_on_plateau, batch_size=128, noise_schedule=linear, samples_per_user=110, objective=noise-pred, use_ue=False\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Gabriel\\anaconda3\\envs\\recgensys-env\\lib\\site-packages\\torch\\nn\\modules\\transformer.py:306: UserWarning: enable_nested_tensor is True, but self.use_nested_tensor is False because encoder_layer.norm_first was True\n",
      "  warnings.warn(f\"enable_nested_tensor is True, but self.use_nested_tensor is False because {why_not_sparsity_fast_path}\")\n",
      "Hyperparameter combinations:  49%|████▉     | 178/360 [8:06:39<16:54:47, 334.55s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Early stopping with best val loss: 0.07299035973846912!\n",
      "Running configuration: timesteps=6000, layers=4, heads=16, image_tokens=1, user_tokens=4, learning_rate=0.0001, optimizer=adamw, scheduler=reduce_on_plateau, batch_size=128, noise_schedule=linear, samples_per_user=140, objective=noise-pred, use_ue=True\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Gabriel\\anaconda3\\envs\\recgensys-env\\lib\\site-packages\\torch\\nn\\modules\\transformer.py:306: UserWarning: enable_nested_tensor is True, but self.use_nested_tensor is False because encoder_layer.norm_first was True\n",
      "  warnings.warn(f\"enable_nested_tensor is True, but self.use_nested_tensor is False because {why_not_sparsity_fast_path}\")\n",
      "Hyperparameter combinations:  50%|████▉     | 179/360 [8:15:10<19:29:03, 387.53s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Early stopping with best val loss: 0.06904501700773835!\n",
      "Running configuration: timesteps=6000, layers=4, heads=16, image_tokens=1, user_tokens=4, learning_rate=0.0001, optimizer=adamw, scheduler=reduce_on_plateau, batch_size=128, noise_schedule=linear, samples_per_user=140, objective=noise-pred, use_ue=False\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Gabriel\\anaconda3\\envs\\recgensys-env\\lib\\site-packages\\torch\\nn\\modules\\transformer.py:306: UserWarning: enable_nested_tensor is True, but self.use_nested_tensor is False because encoder_layer.norm_first was True\n",
      "  warnings.warn(f\"enable_nested_tensor is True, but self.use_nested_tensor is False because {why_not_sparsity_fast_path}\")\n",
      "Hyperparameter combinations:  50%|█████     | 180/360 [8:22:02<19:44:26, 394.82s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Early stopping with best val loss: 0.0713946798350662!\n",
      "Running configuration: timesteps=6000, layers=4, heads=16, image_tokens=4, user_tokens=1, learning_rate=0.0001, optimizer=adamw, scheduler=reduce_on_plateau, batch_size=128, noise_schedule=linear, samples_per_user=30, objective=noise-pred, use_ue=True\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Gabriel\\anaconda3\\envs\\recgensys-env\\lib\\site-packages\\torch\\nn\\modules\\transformer.py:306: UserWarning: enable_nested_tensor is True, but self.use_nested_tensor is False because encoder_layer.norm_first was True\n",
      "  warnings.warn(f\"enable_nested_tensor is True, but self.use_nested_tensor is False because {why_not_sparsity_fast_path}\")\n",
      "Hyperparameter combinations:  50%|█████     | 181/360 [8:23:12<14:47:12, 297.39s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Early stopping with best val loss: 0.1487311515957117!\n",
      "Running configuration: timesteps=6000, layers=4, heads=16, image_tokens=4, user_tokens=1, learning_rate=0.0001, optimizer=adamw, scheduler=reduce_on_plateau, batch_size=128, noise_schedule=linear, samples_per_user=30, objective=noise-pred, use_ue=False\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Gabriel\\anaconda3\\envs\\recgensys-env\\lib\\site-packages\\torch\\nn\\modules\\transformer.py:306: UserWarning: enable_nested_tensor is True, but self.use_nested_tensor is False because encoder_layer.norm_first was True\n",
      "  warnings.warn(f\"enable_nested_tensor is True, but self.use_nested_tensor is False because {why_not_sparsity_fast_path}\")\n",
      "Hyperparameter combinations:  51%|█████     | 182/360 [8:24:34<11:30:50, 232.87s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Early stopping with best val loss: 0.15543195325881243!\n",
      "Running configuration: timesteps=6000, layers=4, heads=16, image_tokens=4, user_tokens=1, learning_rate=0.0001, optimizer=adamw, scheduler=reduce_on_plateau, batch_size=128, noise_schedule=linear, samples_per_user=50, objective=noise-pred, use_ue=True\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Gabriel\\anaconda3\\envs\\recgensys-env\\lib\\site-packages\\torch\\nn\\modules\\transformer.py:306: UserWarning: enable_nested_tensor is True, but self.use_nested_tensor is False because encoder_layer.norm_first was True\n",
      "  warnings.warn(f\"enable_nested_tensor is True, but self.use_nested_tensor is False because {why_not_sparsity_fast_path}\")\n",
      "Hyperparameter combinations:  51%|█████     | 183/360 [8:26:30<9:43:26, 197.78s/it] "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Early stopping with best val loss: 0.11578604811802506!\n",
      "Running configuration: timesteps=6000, layers=4, heads=16, image_tokens=4, user_tokens=1, learning_rate=0.0001, optimizer=adamw, scheduler=reduce_on_plateau, batch_size=128, noise_schedule=linear, samples_per_user=50, objective=noise-pred, use_ue=False\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Gabriel\\anaconda3\\envs\\recgensys-env\\lib\\site-packages\\torch\\nn\\modules\\transformer.py:306: UserWarning: enable_nested_tensor is True, but self.use_nested_tensor is False because encoder_layer.norm_first was True\n",
      "  warnings.warn(f\"enable_nested_tensor is True, but self.use_nested_tensor is False because {why_not_sparsity_fast_path}\")\n",
      "Hyperparameter combinations:  51%|█████     | 184/360 [8:28:26<8:27:42, 173.08s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Early stopping with best val loss: 0.10694226762279868!\n",
      "Running configuration: timesteps=6000, layers=4, heads=16, image_tokens=4, user_tokens=1, learning_rate=0.0001, optimizer=adamw, scheduler=reduce_on_plateau, batch_size=128, noise_schedule=linear, samples_per_user=80, objective=noise-pred, use_ue=True\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Gabriel\\anaconda3\\envs\\recgensys-env\\lib\\site-packages\\torch\\nn\\modules\\transformer.py:306: UserWarning: enable_nested_tensor is True, but self.use_nested_tensor is False because encoder_layer.norm_first was True\n",
      "  warnings.warn(f\"enable_nested_tensor is True, but self.use_nested_tensor is False because {why_not_sparsity_fast_path}\")\n",
      "Hyperparameter combinations:  51%|█████▏    | 185/360 [8:31:16<8:21:54, 172.08s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Early stopping with best val loss: 0.10116142896004021!\n",
      "Running configuration: timesteps=6000, layers=4, heads=16, image_tokens=4, user_tokens=1, learning_rate=0.0001, optimizer=adamw, scheduler=reduce_on_plateau, batch_size=128, noise_schedule=linear, samples_per_user=80, objective=noise-pred, use_ue=False\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Gabriel\\anaconda3\\envs\\recgensys-env\\lib\\site-packages\\torch\\nn\\modules\\transformer.py:306: UserWarning: enable_nested_tensor is True, but self.use_nested_tensor is False because encoder_layer.norm_first was True\n",
      "  warnings.warn(f\"enable_nested_tensor is True, but self.use_nested_tensor is False because {why_not_sparsity_fast_path}\")\n",
      "Hyperparameter combinations:  52%|█████▏    | 186/360 [8:33:12<7:30:44, 155.43s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Early stopping with best val loss: 0.10356988618150353!\n",
      "Running configuration: timesteps=6000, layers=4, heads=16, image_tokens=4, user_tokens=1, learning_rate=0.0001, optimizer=adamw, scheduler=reduce_on_plateau, batch_size=128, noise_schedule=linear, samples_per_user=110, objective=noise-pred, use_ue=True\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Gabriel\\anaconda3\\envs\\recgensys-env\\lib\\site-packages\\torch\\nn\\modules\\transformer.py:306: UserWarning: enable_nested_tensor is True, but self.use_nested_tensor is False because encoder_layer.norm_first was True\n",
      "  warnings.warn(f\"enable_nested_tensor is True, but self.use_nested_tensor is False because {why_not_sparsity_fast_path}\")\n",
      "Hyperparameter combinations:  52%|█████▏    | 187/360 [8:35:43<7:24:28, 154.16s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Early stopping with best val loss: 0.10027645714581013!\n",
      "Running configuration: timesteps=6000, layers=4, heads=16, image_tokens=4, user_tokens=1, learning_rate=0.0001, optimizer=adamw, scheduler=reduce_on_plateau, batch_size=128, noise_schedule=linear, samples_per_user=110, objective=noise-pred, use_ue=False\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Gabriel\\anaconda3\\envs\\recgensys-env\\lib\\site-packages\\torch\\nn\\modules\\transformer.py:306: UserWarning: enable_nested_tensor is True, but self.use_nested_tensor is False because encoder_layer.norm_first was True\n",
      "  warnings.warn(f\"enable_nested_tensor is True, but self.use_nested_tensor is False because {why_not_sparsity_fast_path}\")\n",
      "Hyperparameter combinations:  52%|█████▏    | 188/360 [8:39:18<8:13:47, 172.25s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Early stopping with best val loss: 0.09078763634897768!\n",
      "Running configuration: timesteps=6000, layers=4, heads=16, image_tokens=4, user_tokens=1, learning_rate=0.0001, optimizer=adamw, scheduler=reduce_on_plateau, batch_size=128, noise_schedule=linear, samples_per_user=140, objective=noise-pred, use_ue=True\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Gabriel\\anaconda3\\envs\\recgensys-env\\lib\\site-packages\\torch\\nn\\modules\\transformer.py:306: UserWarning: enable_nested_tensor is True, but self.use_nested_tensor is False because encoder_layer.norm_first was True\n",
      "  warnings.warn(f\"enable_nested_tensor is True, but self.use_nested_tensor is False because {why_not_sparsity_fast_path}\")\n",
      "Hyperparameter combinations:  52%|█████▎    | 189/360 [8:42:40<8:36:54, 181.37s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Early stopping with best val loss: 0.10077979229390621!\n",
      "Running configuration: timesteps=6000, layers=4, heads=16, image_tokens=4, user_tokens=1, learning_rate=0.0001, optimizer=adamw, scheduler=reduce_on_plateau, batch_size=128, noise_schedule=linear, samples_per_user=140, objective=noise-pred, use_ue=False\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Gabriel\\anaconda3\\envs\\recgensys-env\\lib\\site-packages\\torch\\nn\\modules\\transformer.py:306: UserWarning: enable_nested_tensor is True, but self.use_nested_tensor is False because encoder_layer.norm_first was True\n",
      "  warnings.warn(f\"enable_nested_tensor is True, but self.use_nested_tensor is False because {why_not_sparsity_fast_path}\")\n",
      "Hyperparameter combinations:  53%|█████▎    | 190/360 [8:45:34<8:27:18, 179.05s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Early stopping with best val loss: 0.1061050184071064!\n",
      "Running configuration: timesteps=6000, layers=4, heads=16, image_tokens=4, user_tokens=4, learning_rate=0.0001, optimizer=adamw, scheduler=reduce_on_plateau, batch_size=128, noise_schedule=linear, samples_per_user=30, objective=noise-pred, use_ue=True\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Gabriel\\anaconda3\\envs\\recgensys-env\\lib\\site-packages\\torch\\nn\\modules\\transformer.py:306: UserWarning: enable_nested_tensor is True, but self.use_nested_tensor is False because encoder_layer.norm_first was True\n",
      "  warnings.warn(f\"enable_nested_tensor is True, but self.use_nested_tensor is False because {why_not_sparsity_fast_path}\")\n",
      "Hyperparameter combinations:  53%|█████▎    | 191/360 [8:46:23<6:34:34, 140.09s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Early stopping with best val loss: 0.15977889439091086!\n",
      "Running configuration: timesteps=6000, layers=4, heads=16, image_tokens=4, user_tokens=4, learning_rate=0.0001, optimizer=adamw, scheduler=reduce_on_plateau, batch_size=128, noise_schedule=linear, samples_per_user=30, objective=noise-pred, use_ue=False\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Gabriel\\anaconda3\\envs\\recgensys-env\\lib\\site-packages\\torch\\nn\\modules\\transformer.py:306: UserWarning: enable_nested_tensor is True, but self.use_nested_tensor is False because encoder_layer.norm_first was True\n",
      "  warnings.warn(f\"enable_nested_tensor is True, but self.use_nested_tensor is False because {why_not_sparsity_fast_path}\")\n",
      "Hyperparameter combinations:  53%|█████▎    | 192/360 [8:47:35<5:35:09, 119.70s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Early stopping with best val loss: 0.14553027274087071!\n",
      "Running configuration: timesteps=6000, layers=4, heads=16, image_tokens=4, user_tokens=4, learning_rate=0.0001, optimizer=adamw, scheduler=reduce_on_plateau, batch_size=128, noise_schedule=linear, samples_per_user=50, objective=noise-pred, use_ue=True\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Gabriel\\anaconda3\\envs\\recgensys-env\\lib\\site-packages\\torch\\nn\\modules\\transformer.py:306: UserWarning: enable_nested_tensor is True, but self.use_nested_tensor is False because encoder_layer.norm_first was True\n",
      "  warnings.warn(f\"enable_nested_tensor is True, but self.use_nested_tensor is False because {why_not_sparsity_fast_path}\")\n",
      "Hyperparameter combinations:  54%|█████▎    | 193/360 [8:49:32<5:30:38, 118.79s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Early stopping with best val loss: 0.12224684190005064!\n",
      "Running configuration: timesteps=6000, layers=4, heads=16, image_tokens=4, user_tokens=4, learning_rate=0.0001, optimizer=adamw, scheduler=reduce_on_plateau, batch_size=128, noise_schedule=linear, samples_per_user=50, objective=noise-pred, use_ue=False\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Gabriel\\anaconda3\\envs\\recgensys-env\\lib\\site-packages\\torch\\nn\\modules\\transformer.py:306: UserWarning: enable_nested_tensor is True, but self.use_nested_tensor is False because encoder_layer.norm_first was True\n",
      "  warnings.warn(f\"enable_nested_tensor is True, but self.use_nested_tensor is False because {why_not_sparsity_fast_path}\")\n",
      "Hyperparameter combinations:  54%|█████▍    | 194/360 [8:51:06<5:07:48, 111.25s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Early stopping with best val loss: 0.12101587234064937!\n",
      "Running configuration: timesteps=6000, layers=4, heads=16, image_tokens=4, user_tokens=4, learning_rate=0.0001, optimizer=adamw, scheduler=reduce_on_plateau, batch_size=128, noise_schedule=linear, samples_per_user=80, objective=noise-pred, use_ue=True\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Gabriel\\anaconda3\\envs\\recgensys-env\\lib\\site-packages\\torch\\nn\\modules\\transformer.py:306: UserWarning: enable_nested_tensor is True, but self.use_nested_tensor is False because encoder_layer.norm_first was True\n",
      "  warnings.warn(f\"enable_nested_tensor is True, but self.use_nested_tensor is False because {why_not_sparsity_fast_path}\")\n",
      "Hyperparameter combinations:  54%|█████▍    | 195/360 [8:53:43<5:44:07, 125.14s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Early stopping with best val loss: 0.09538750536739826!\n",
      "Running configuration: timesteps=6000, layers=4, heads=16, image_tokens=4, user_tokens=4, learning_rate=0.0001, optimizer=adamw, scheduler=reduce_on_plateau, batch_size=128, noise_schedule=linear, samples_per_user=80, objective=noise-pred, use_ue=False\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Gabriel\\anaconda3\\envs\\recgensys-env\\lib\\site-packages\\torch\\nn\\modules\\transformer.py:306: UserWarning: enable_nested_tensor is True, but self.use_nested_tensor is False because encoder_layer.norm_first was True\n",
      "  warnings.warn(f\"enable_nested_tensor is True, but self.use_nested_tensor is False because {why_not_sparsity_fast_path}\")\n",
      "Hyperparameter combinations:  54%|█████▍    | 196/360 [8:55:50<5:43:18, 125.60s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Early stopping with best val loss: 0.1086165620945394!\n",
      "Running configuration: timesteps=6000, layers=4, heads=16, image_tokens=4, user_tokens=4, learning_rate=0.0001, optimizer=adamw, scheduler=reduce_on_plateau, batch_size=128, noise_schedule=linear, samples_per_user=110, objective=noise-pred, use_ue=True\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Gabriel\\anaconda3\\envs\\recgensys-env\\lib\\site-packages\\torch\\nn\\modules\\transformer.py:306: UserWarning: enable_nested_tensor is True, but self.use_nested_tensor is False because encoder_layer.norm_first was True\n",
      "  warnings.warn(f\"enable_nested_tensor is True, but self.use_nested_tensor is False because {why_not_sparsity_fast_path}\")\n",
      "Hyperparameter combinations:  55%|█████▍    | 197/360 [8:58:35<6:13:00, 137.30s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Early stopping with best val loss: 0.10005053458735347!\n",
      "Running configuration: timesteps=6000, layers=4, heads=16, image_tokens=4, user_tokens=4, learning_rate=0.0001, optimizer=adamw, scheduler=reduce_on_plateau, batch_size=128, noise_schedule=linear, samples_per_user=110, objective=noise-pred, use_ue=False\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Gabriel\\anaconda3\\envs\\recgensys-env\\lib\\site-packages\\torch\\nn\\modules\\transformer.py:306: UserWarning: enable_nested_tensor is True, but self.use_nested_tensor is False because encoder_layer.norm_first was True\n",
      "  warnings.warn(f\"enable_nested_tensor is True, but self.use_nested_tensor is False because {why_not_sparsity_fast_path}\")\n",
      "Hyperparameter combinations:  55%|█████▌    | 198/360 [9:01:21<6:33:57, 145.91s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Early stopping with best val loss: 0.09571020118892193!\n",
      "Running configuration: timesteps=6000, layers=4, heads=16, image_tokens=4, user_tokens=4, learning_rate=0.0001, optimizer=adamw, scheduler=reduce_on_plateau, batch_size=128, noise_schedule=linear, samples_per_user=140, objective=noise-pred, use_ue=True\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Gabriel\\anaconda3\\envs\\recgensys-env\\lib\\site-packages\\torch\\nn\\modules\\transformer.py:306: UserWarning: enable_nested_tensor is True, but self.use_nested_tensor is False because encoder_layer.norm_first was True\n",
      "  warnings.warn(f\"enable_nested_tensor is True, but self.use_nested_tensor is False because {why_not_sparsity_fast_path}\")\n",
      "Hyperparameter combinations:  55%|█████▌    | 199/360 [9:04:03<6:44:40, 150.81s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Early stopping with best val loss: 0.09707025345414877!\n",
      "Running configuration: timesteps=6000, layers=4, heads=16, image_tokens=4, user_tokens=4, learning_rate=0.0001, optimizer=adamw, scheduler=reduce_on_plateau, batch_size=128, noise_schedule=linear, samples_per_user=140, objective=noise-pred, use_ue=False\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Gabriel\\anaconda3\\envs\\recgensys-env\\lib\\site-packages\\torch\\nn\\modules\\transformer.py:306: UserWarning: enable_nested_tensor is True, but self.use_nested_tensor is False because encoder_layer.norm_first was True\n",
      "  warnings.warn(f\"enable_nested_tensor is True, but self.use_nested_tensor is False because {why_not_sparsity_fast_path}\")\n",
      "Hyperparameter combinations:  56%|█████▌    | 200/360 [9:08:14<8:02:18, 180.86s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Early stopping with best val loss: 0.09248178196139634!\n",
      "Running configuration: timesteps=6000, layers=4, heads=32, image_tokens=1, user_tokens=1, learning_rate=0.0001, optimizer=adamw, scheduler=reduce_on_plateau, batch_size=128, noise_schedule=linear, samples_per_user=30, objective=noise-pred, use_ue=True\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Gabriel\\anaconda3\\envs\\recgensys-env\\lib\\site-packages\\torch\\nn\\modules\\transformer.py:306: UserWarning: enable_nested_tensor is True, but self.use_nested_tensor is False because encoder_layer.norm_first was True\n",
      "  warnings.warn(f\"enable_nested_tensor is True, but self.use_nested_tensor is False because {why_not_sparsity_fast_path}\")\n",
      "Hyperparameter combinations:  56%|█████▌    | 201/360 [9:11:27<8:09:13, 184.62s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Early stopping with best val loss: 0.0904923789203167!\n",
      "Running configuration: timesteps=6000, layers=4, heads=32, image_tokens=1, user_tokens=1, learning_rate=0.0001, optimizer=adamw, scheduler=reduce_on_plateau, batch_size=128, noise_schedule=linear, samples_per_user=30, objective=noise-pred, use_ue=False\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Gabriel\\anaconda3\\envs\\recgensys-env\\lib\\site-packages\\torch\\nn\\modules\\transformer.py:306: UserWarning: enable_nested_tensor is True, but self.use_nested_tensor is False because encoder_layer.norm_first was True\n",
      "  warnings.warn(f\"enable_nested_tensor is True, but self.use_nested_tensor is False because {why_not_sparsity_fast_path}\")\n",
      "Hyperparameter combinations:  56%|█████▌    | 202/360 [9:14:00<7:40:57, 175.04s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Early stopping with best val loss: 0.09325291216373444!\n",
      "Running configuration: timesteps=6000, layers=4, heads=32, image_tokens=1, user_tokens=1, learning_rate=0.0001, optimizer=adamw, scheduler=reduce_on_plateau, batch_size=128, noise_schedule=linear, samples_per_user=50, objective=noise-pred, use_ue=True\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Gabriel\\anaconda3\\envs\\recgensys-env\\lib\\site-packages\\torch\\nn\\modules\\transformer.py:306: UserWarning: enable_nested_tensor is True, but self.use_nested_tensor is False because encoder_layer.norm_first was True\n",
      "  warnings.warn(f\"enable_nested_tensor is True, but self.use_nested_tensor is False because {why_not_sparsity_fast_path}\")\n",
      "Hyperparameter combinations:  56%|█████▋    | 203/360 [9:17:46<8:17:50, 190.26s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Early stopping with best val loss: 0.08640010887756944!\n",
      "Running configuration: timesteps=6000, layers=4, heads=32, image_tokens=1, user_tokens=1, learning_rate=0.0001, optimizer=adamw, scheduler=reduce_on_plateau, batch_size=128, noise_schedule=linear, samples_per_user=50, objective=noise-pred, use_ue=False\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Gabriel\\anaconda3\\envs\\recgensys-env\\lib\\site-packages\\torch\\nn\\modules\\transformer.py:306: UserWarning: enable_nested_tensor is True, but self.use_nested_tensor is False because encoder_layer.norm_first was True\n",
      "  warnings.warn(f\"enable_nested_tensor is True, but self.use_nested_tensor is False because {why_not_sparsity_fast_path}\")\n",
      "Hyperparameter combinations:  57%|█████▋    | 204/360 [9:21:50<8:56:30, 206.35s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Early stopping with best val loss: 0.08145700208842754!\n",
      "Running configuration: timesteps=6000, layers=4, heads=32, image_tokens=1, user_tokens=1, learning_rate=0.0001, optimizer=adamw, scheduler=reduce_on_plateau, batch_size=128, noise_schedule=linear, samples_per_user=80, objective=noise-pred, use_ue=True\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Gabriel\\anaconda3\\envs\\recgensys-env\\lib\\site-packages\\torch\\nn\\modules\\transformer.py:306: UserWarning: enable_nested_tensor is True, but self.use_nested_tensor is False because encoder_layer.norm_first was True\n",
      "  warnings.warn(f\"enable_nested_tensor is True, but self.use_nested_tensor is False because {why_not_sparsity_fast_path}\")\n",
      "Hyperparameter combinations:  57%|█████▋    | 205/360 [9:27:23<10:31:28, 244.44s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Early stopping with best val loss: 0.07981156604364514!\n",
      "Running configuration: timesteps=6000, layers=4, heads=32, image_tokens=1, user_tokens=1, learning_rate=0.0001, optimizer=adamw, scheduler=reduce_on_plateau, batch_size=128, noise_schedule=linear, samples_per_user=80, objective=noise-pred, use_ue=False\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Gabriel\\anaconda3\\envs\\recgensys-env\\lib\\site-packages\\torch\\nn\\modules\\transformer.py:306: UserWarning: enable_nested_tensor is True, but self.use_nested_tensor is False because encoder_layer.norm_first was True\n",
      "  warnings.warn(f\"enable_nested_tensor is True, but self.use_nested_tensor is False because {why_not_sparsity_fast_path}\")\n",
      "Hyperparameter combinations:  57%|█████▋    | 206/360 [9:32:04<10:55:54, 255.55s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Early stopping with best val loss: 0.07963695307262242!\n",
      "Running configuration: timesteps=6000, layers=4, heads=32, image_tokens=1, user_tokens=1, learning_rate=0.0001, optimizer=adamw, scheduler=reduce_on_plateau, batch_size=128, noise_schedule=linear, samples_per_user=110, objective=noise-pred, use_ue=True\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Gabriel\\anaconda3\\envs\\recgensys-env\\lib\\site-packages\\torch\\nn\\modules\\transformer.py:306: UserWarning: enable_nested_tensor is True, but self.use_nested_tensor is False because encoder_layer.norm_first was True\n",
      "  warnings.warn(f\"enable_nested_tensor is True, but self.use_nested_tensor is False because {why_not_sparsity_fast_path}\")\n",
      "Hyperparameter combinations:  57%|█████▊    | 207/360 [9:38:26<12:28:12, 293.41s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Early stopping with best val loss: 0.07478677155449986!\n",
      "Running configuration: timesteps=6000, layers=4, heads=32, image_tokens=1, user_tokens=1, learning_rate=0.0001, optimizer=adamw, scheduler=reduce_on_plateau, batch_size=128, noise_schedule=linear, samples_per_user=110, objective=noise-pred, use_ue=False\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Gabriel\\anaconda3\\envs\\recgensys-env\\lib\\site-packages\\torch\\nn\\modules\\transformer.py:306: UserWarning: enable_nested_tensor is True, but self.use_nested_tensor is False because encoder_layer.norm_first was True\n",
      "  warnings.warn(f\"enable_nested_tensor is True, but self.use_nested_tensor is False because {why_not_sparsity_fast_path}\")\n",
      "Hyperparameter combinations:  58%|█████▊    | 208/360 [9:43:49<12:45:57, 302.35s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Early stopping with best val loss: 0.07970021804794669!\n",
      "Running configuration: timesteps=6000, layers=4, heads=32, image_tokens=1, user_tokens=1, learning_rate=0.0001, optimizer=adamw, scheduler=reduce_on_plateau, batch_size=128, noise_schedule=linear, samples_per_user=140, objective=noise-pred, use_ue=True\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Gabriel\\anaconda3\\envs\\recgensys-env\\lib\\site-packages\\torch\\nn\\modules\\transformer.py:306: UserWarning: enable_nested_tensor is True, but self.use_nested_tensor is False because encoder_layer.norm_first was True\n",
      "  warnings.warn(f\"enable_nested_tensor is True, but self.use_nested_tensor is False because {why_not_sparsity_fast_path}\")\n",
      "Hyperparameter combinations:  58%|█████▊    | 209/360 [9:50:08<13:38:17, 325.15s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Early stopping with best val loss: 0.07287801499478519!\n",
      "Running configuration: timesteps=6000, layers=4, heads=32, image_tokens=1, user_tokens=1, learning_rate=0.0001, optimizer=adamw, scheduler=reduce_on_plateau, batch_size=128, noise_schedule=linear, samples_per_user=140, objective=noise-pred, use_ue=False\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Gabriel\\anaconda3\\envs\\recgensys-env\\lib\\site-packages\\torch\\nn\\modules\\transformer.py:306: UserWarning: enable_nested_tensor is True, but self.use_nested_tensor is False because encoder_layer.norm_first was True\n",
      "  warnings.warn(f\"enable_nested_tensor is True, but self.use_nested_tensor is False because {why_not_sparsity_fast_path}\")\n",
      "Hyperparameter combinations:  58%|█████▊    | 210/360 [9:56:05<13:56:56, 334.78s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Early stopping with best val loss: 0.06966196559369564!\n",
      "Running configuration: timesteps=6000, layers=4, heads=32, image_tokens=1, user_tokens=4, learning_rate=0.0001, optimizer=adamw, scheduler=reduce_on_plateau, batch_size=128, noise_schedule=linear, samples_per_user=30, objective=noise-pred, use_ue=True\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Gabriel\\anaconda3\\envs\\recgensys-env\\lib\\site-packages\\torch\\nn\\modules\\transformer.py:306: UserWarning: enable_nested_tensor is True, but self.use_nested_tensor is False because encoder_layer.norm_first was True\n",
      "  warnings.warn(f\"enable_nested_tensor is True, but self.use_nested_tensor is False because {why_not_sparsity_fast_path}\")\n",
      "Hyperparameter combinations:  59%|█████▊    | 211/360 [9:59:54<12:32:18, 302.95s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Early stopping with best val loss: 0.09024446364492178!\n",
      "Running configuration: timesteps=6000, layers=4, heads=32, image_tokens=1, user_tokens=4, learning_rate=0.0001, optimizer=adamw, scheduler=reduce_on_plateau, batch_size=128, noise_schedule=linear, samples_per_user=30, objective=noise-pred, use_ue=False\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Gabriel\\anaconda3\\envs\\recgensys-env\\lib\\site-packages\\torch\\nn\\modules\\transformer.py:306: UserWarning: enable_nested_tensor is True, but self.use_nested_tensor is False because encoder_layer.norm_first was True\n",
      "  warnings.warn(f\"enable_nested_tensor is True, but self.use_nested_tensor is False because {why_not_sparsity_fast_path}\")\n",
      "Hyperparameter combinations:  59%|█████▉    | 212/360 [10:02:34<10:41:58, 260.26s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Early stopping with best val loss: 0.09552345634438097!\n",
      "Running configuration: timesteps=6000, layers=4, heads=32, image_tokens=1, user_tokens=4, learning_rate=0.0001, optimizer=adamw, scheduler=reduce_on_plateau, batch_size=128, noise_schedule=linear, samples_per_user=50, objective=noise-pred, use_ue=True\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Gabriel\\anaconda3\\envs\\recgensys-env\\lib\\site-packages\\torch\\nn\\modules\\transformer.py:306: UserWarning: enable_nested_tensor is True, but self.use_nested_tensor is False because encoder_layer.norm_first was True\n",
      "  warnings.warn(f\"enable_nested_tensor is True, but self.use_nested_tensor is False because {why_not_sparsity_fast_path}\")\n",
      "Hyperparameter combinations:  59%|█████▉    | 213/360 [10:07:57<11:23:55, 279.15s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Early stopping with best val loss: 0.08596531394869089!\n",
      "Running configuration: timesteps=6000, layers=4, heads=32, image_tokens=1, user_tokens=4, learning_rate=0.0001, optimizer=adamw, scheduler=reduce_on_plateau, batch_size=128, noise_schedule=linear, samples_per_user=50, objective=noise-pred, use_ue=False\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Gabriel\\anaconda3\\envs\\recgensys-env\\lib\\site-packages\\torch\\nn\\modules\\transformer.py:306: UserWarning: enable_nested_tensor is True, but self.use_nested_tensor is False because encoder_layer.norm_first was True\n",
      "  warnings.warn(f\"enable_nested_tensor is True, but self.use_nested_tensor is False because {why_not_sparsity_fast_path}\")\n",
      "Hyperparameter combinations:  59%|█████▉    | 214/360 [10:12:20<11:07:23, 274.27s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Early stopping with best val loss: 0.07998763513751328!\n",
      "Running configuration: timesteps=6000, layers=4, heads=32, image_tokens=1, user_tokens=4, learning_rate=0.0001, optimizer=adamw, scheduler=reduce_on_plateau, batch_size=128, noise_schedule=linear, samples_per_user=80, objective=noise-pred, use_ue=True\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Gabriel\\anaconda3\\envs\\recgensys-env\\lib\\site-packages\\torch\\nn\\modules\\transformer.py:306: UserWarning: enable_nested_tensor is True, but self.use_nested_tensor is False because encoder_layer.norm_first was True\n",
      "  warnings.warn(f\"enable_nested_tensor is True, but self.use_nested_tensor is False because {why_not_sparsity_fast_path}\")\n",
      "Hyperparameter combinations:  60%|█████▉    | 215/360 [10:19:01<12:34:08, 312.06s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Early stopping with best val loss: 0.07540783286094666!\n",
      "Running configuration: timesteps=6000, layers=4, heads=32, image_tokens=1, user_tokens=4, learning_rate=0.0001, optimizer=adamw, scheduler=reduce_on_plateau, batch_size=128, noise_schedule=linear, samples_per_user=80, objective=noise-pred, use_ue=False\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Gabriel\\anaconda3\\envs\\recgensys-env\\lib\\site-packages\\torch\\nn\\modules\\transformer.py:306: UserWarning: enable_nested_tensor is True, but self.use_nested_tensor is False because encoder_layer.norm_first was True\n",
      "  warnings.warn(f\"enable_nested_tensor is True, but self.use_nested_tensor is False because {why_not_sparsity_fast_path}\")\n",
      "Hyperparameter combinations:  60%|██████    | 216/360 [10:24:05<12:23:28, 309.78s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Early stopping with best val loss: 0.08553877077065408!\n",
      "Running configuration: timesteps=6000, layers=4, heads=32, image_tokens=1, user_tokens=4, learning_rate=0.0001, optimizer=adamw, scheduler=reduce_on_plateau, batch_size=128, noise_schedule=linear, samples_per_user=110, objective=noise-pred, use_ue=True\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Gabriel\\anaconda3\\envs\\recgensys-env\\lib\\site-packages\\torch\\nn\\modules\\transformer.py:306: UserWarning: enable_nested_tensor is True, but self.use_nested_tensor is False because encoder_layer.norm_first was True\n",
      "  warnings.warn(f\"enable_nested_tensor is True, but self.use_nested_tensor is False because {why_not_sparsity_fast_path}\")\n",
      "Hyperparameter combinations:  60%|██████    | 217/360 [10:30:59<13:32:38, 340.97s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Early stopping with best val loss: 0.0738482375163585!\n",
      "Running configuration: timesteps=6000, layers=4, heads=32, image_tokens=1, user_tokens=4, learning_rate=0.0001, optimizer=adamw, scheduler=reduce_on_plateau, batch_size=128, noise_schedule=linear, samples_per_user=110, objective=noise-pred, use_ue=False\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Gabriel\\anaconda3\\envs\\recgensys-env\\lib\\site-packages\\torch\\nn\\modules\\transformer.py:306: UserWarning: enable_nested_tensor is True, but self.use_nested_tensor is False because encoder_layer.norm_first was True\n",
      "  warnings.warn(f\"enable_nested_tensor is True, but self.use_nested_tensor is False because {why_not_sparsity_fast_path}\")\n",
      "Hyperparameter combinations:  61%|██████    | 218/360 [10:35:36<12:41:28, 321.75s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Early stopping with best val loss: 0.08534594252705574!\n",
      "Running configuration: timesteps=6000, layers=4, heads=32, image_tokens=1, user_tokens=4, learning_rate=0.0001, optimizer=adamw, scheduler=reduce_on_plateau, batch_size=128, noise_schedule=linear, samples_per_user=140, objective=noise-pred, use_ue=True\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Gabriel\\anaconda3\\envs\\recgensys-env\\lib\\site-packages\\torch\\nn\\modules\\transformer.py:306: UserWarning: enable_nested_tensor is True, but self.use_nested_tensor is False because encoder_layer.norm_first was True\n",
      "  warnings.warn(f\"enable_nested_tensor is True, but self.use_nested_tensor is False because {why_not_sparsity_fast_path}\")\n",
      "Hyperparameter combinations:  61%|██████    | 219/360 [10:43:51<14:38:26, 373.80s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Early stopping with best val loss: 0.07344788196496665!\n",
      "Running configuration: timesteps=6000, layers=4, heads=32, image_tokens=1, user_tokens=4, learning_rate=0.0001, optimizer=adamw, scheduler=reduce_on_plateau, batch_size=128, noise_schedule=linear, samples_per_user=140, objective=noise-pred, use_ue=False\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Gabriel\\anaconda3\\envs\\recgensys-env\\lib\\site-packages\\torch\\nn\\modules\\transformer.py:306: UserWarning: enable_nested_tensor is True, but self.use_nested_tensor is False because encoder_layer.norm_first was True\n",
      "  warnings.warn(f\"enable_nested_tensor is True, but self.use_nested_tensor is False because {why_not_sparsity_fast_path}\")\n",
      "Hyperparameter combinations:  61%|██████    | 220/360 [10:50:57<15:08:53, 389.52s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Early stopping with best val loss: 0.06573947914876044!\n",
      "Running configuration: timesteps=6000, layers=4, heads=32, image_tokens=4, user_tokens=1, learning_rate=0.0001, optimizer=adamw, scheduler=reduce_on_plateau, batch_size=128, noise_schedule=linear, samples_per_user=30, objective=noise-pred, use_ue=True\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Gabriel\\anaconda3\\envs\\recgensys-env\\lib\\site-packages\\torch\\nn\\modules\\transformer.py:306: UserWarning: enable_nested_tensor is True, but self.use_nested_tensor is False because encoder_layer.norm_first was True\n",
      "  warnings.warn(f\"enable_nested_tensor is True, but self.use_nested_tensor is False because {why_not_sparsity_fast_path}\")\n",
      "Hyperparameter combinations:  61%|██████▏   | 221/360 [10:52:26<11:33:30, 299.36s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Early stopping with best val loss: 0.13852725783362985!\n",
      "Running configuration: timesteps=6000, layers=4, heads=32, image_tokens=4, user_tokens=1, learning_rate=0.0001, optimizer=adamw, scheduler=reduce_on_plateau, batch_size=128, noise_schedule=linear, samples_per_user=30, objective=noise-pred, use_ue=False\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Gabriel\\anaconda3\\envs\\recgensys-env\\lib\\site-packages\\torch\\nn\\modules\\transformer.py:306: UserWarning: enable_nested_tensor is True, but self.use_nested_tensor is False because encoder_layer.norm_first was True\n",
      "  warnings.warn(f\"enable_nested_tensor is True, but self.use_nested_tensor is False because {why_not_sparsity_fast_path}\")\n",
      "Hyperparameter combinations:  62%|██████▏   | 222/360 [10:53:58<9:05:32, 237.20s/it] "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Early stopping with best val loss: 0.13049184856936336!\n",
      "Running configuration: timesteps=6000, layers=4, heads=32, image_tokens=4, user_tokens=1, learning_rate=0.0001, optimizer=adamw, scheduler=reduce_on_plateau, batch_size=128, noise_schedule=linear, samples_per_user=50, objective=noise-pred, use_ue=True\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Gabriel\\anaconda3\\envs\\recgensys-env\\lib\\site-packages\\torch\\nn\\modules\\transformer.py:306: UserWarning: enable_nested_tensor is True, but self.use_nested_tensor is False because encoder_layer.norm_first was True\n",
      "  warnings.warn(f\"enable_nested_tensor is True, but self.use_nested_tensor is False because {why_not_sparsity_fast_path}\")\n",
      "Hyperparameter combinations:  62%|██████▏   | 223/360 [10:55:39<7:27:59, 196.20s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Early stopping with best val loss: 0.12234220514073968!\n",
      "Running configuration: timesteps=6000, layers=4, heads=32, image_tokens=4, user_tokens=1, learning_rate=0.0001, optimizer=adamw, scheduler=reduce_on_plateau, batch_size=128, noise_schedule=linear, samples_per_user=50, objective=noise-pred, use_ue=False\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Gabriel\\anaconda3\\envs\\recgensys-env\\lib\\site-packages\\torch\\nn\\modules\\transformer.py:306: UserWarning: enable_nested_tensor is True, but self.use_nested_tensor is False because encoder_layer.norm_first was True\n",
      "  warnings.warn(f\"enable_nested_tensor is True, but self.use_nested_tensor is False because {why_not_sparsity_fast_path}\")\n",
      "Hyperparameter combinations:  62%|██████▏   | 224/360 [10:57:19<6:19:18, 167.35s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Early stopping with best val loss: 0.11442131083458662!\n",
      "Running configuration: timesteps=6000, layers=4, heads=32, image_tokens=4, user_tokens=1, learning_rate=0.0001, optimizer=adamw, scheduler=reduce_on_plateau, batch_size=128, noise_schedule=linear, samples_per_user=80, objective=noise-pred, use_ue=True\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Gabriel\\anaconda3\\envs\\recgensys-env\\lib\\site-packages\\torch\\nn\\modules\\transformer.py:306: UserWarning: enable_nested_tensor is True, but self.use_nested_tensor is False because encoder_layer.norm_first was True\n",
      "  warnings.warn(f\"enable_nested_tensor is True, but self.use_nested_tensor is False because {why_not_sparsity_fast_path}\")\n",
      "Hyperparameter combinations:  62%|██████▎   | 225/360 [10:59:34<5:55:03, 157.80s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Early stopping with best val loss: 0.0946257640607655!\n",
      "Running configuration: timesteps=6000, layers=4, heads=32, image_tokens=4, user_tokens=1, learning_rate=0.0001, optimizer=adamw, scheduler=reduce_on_plateau, batch_size=128, noise_schedule=linear, samples_per_user=80, objective=noise-pred, use_ue=False\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Gabriel\\anaconda3\\envs\\recgensys-env\\lib\\site-packages\\torch\\nn\\modules\\transformer.py:306: UserWarning: enable_nested_tensor is True, but self.use_nested_tensor is False because encoder_layer.norm_first was True\n",
      "  warnings.warn(f\"enable_nested_tensor is True, but self.use_nested_tensor is False because {why_not_sparsity_fast_path}\")\n",
      "Hyperparameter combinations:  63%|██████▎   | 226/360 [11:01:36<5:28:29, 147.08s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Early stopping with best val loss: 0.11041951039806008!\n",
      "Running configuration: timesteps=6000, layers=4, heads=32, image_tokens=4, user_tokens=1, learning_rate=0.0001, optimizer=adamw, scheduler=reduce_on_plateau, batch_size=128, noise_schedule=linear, samples_per_user=110, objective=noise-pred, use_ue=True\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Gabriel\\anaconda3\\envs\\recgensys-env\\lib\\site-packages\\torch\\nn\\modules\\transformer.py:306: UserWarning: enable_nested_tensor is True, but self.use_nested_tensor is False because encoder_layer.norm_first was True\n",
      "  warnings.warn(f\"enable_nested_tensor is True, but self.use_nested_tensor is False because {why_not_sparsity_fast_path}\")\n",
      "Hyperparameter combinations:  63%|██████▎   | 227/360 [11:04:19<5:36:07, 151.64s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Early stopping with best val loss: 0.10057042678818107!\n",
      "Running configuration: timesteps=6000, layers=4, heads=32, image_tokens=4, user_tokens=1, learning_rate=0.0001, optimizer=adamw, scheduler=reduce_on_plateau, batch_size=128, noise_schedule=linear, samples_per_user=110, objective=noise-pred, use_ue=False\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Gabriel\\anaconda3\\envs\\recgensys-env\\lib\\site-packages\\torch\\nn\\modules\\transformer.py:306: UserWarning: enable_nested_tensor is True, but self.use_nested_tensor is False because encoder_layer.norm_first was True\n",
      "  warnings.warn(f\"enable_nested_tensor is True, but self.use_nested_tensor is False because {why_not_sparsity_fast_path}\")\n",
      "Hyperparameter combinations:  63%|██████▎   | 228/360 [11:07:41<6:07:22, 166.99s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Early stopping with best val loss: 0.09285198641009629!\n",
      "Running configuration: timesteps=6000, layers=4, heads=32, image_tokens=4, user_tokens=1, learning_rate=0.0001, optimizer=adamw, scheduler=reduce_on_plateau, batch_size=128, noise_schedule=linear, samples_per_user=140, objective=noise-pred, use_ue=True\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Gabriel\\anaconda3\\envs\\recgensys-env\\lib\\site-packages\\torch\\nn\\modules\\transformer.py:306: UserWarning: enable_nested_tensor is True, but self.use_nested_tensor is False because encoder_layer.norm_first was True\n",
      "  warnings.warn(f\"enable_nested_tensor is True, but self.use_nested_tensor is False because {why_not_sparsity_fast_path}\")\n",
      "Hyperparameter combinations:  64%|██████▎   | 229/360 [11:10:18<5:57:36, 163.79s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Early stopping with best val loss: 0.10173213761299849!\n",
      "Running configuration: timesteps=6000, layers=4, heads=32, image_tokens=4, user_tokens=1, learning_rate=0.0001, optimizer=adamw, scheduler=reduce_on_plateau, batch_size=128, noise_schedule=linear, samples_per_user=140, objective=noise-pred, use_ue=False\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Gabriel\\anaconda3\\envs\\recgensys-env\\lib\\site-packages\\torch\\nn\\modules\\transformer.py:306: UserWarning: enable_nested_tensor is True, but self.use_nested_tensor is False because encoder_layer.norm_first was True\n",
      "  warnings.warn(f\"enable_nested_tensor is True, but self.use_nested_tensor is False because {why_not_sparsity_fast_path}\")\n",
      "Hyperparameter combinations:  64%|██████▍   | 230/360 [11:14:29<6:51:32, 189.95s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Early stopping with best val loss: 0.09684480866417289!\n",
      "Running configuration: timesteps=6000, layers=4, heads=32, image_tokens=4, user_tokens=4, learning_rate=0.0001, optimizer=adamw, scheduler=reduce_on_plateau, batch_size=128, noise_schedule=linear, samples_per_user=30, objective=noise-pred, use_ue=True\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Gabriel\\anaconda3\\envs\\recgensys-env\\lib\\site-packages\\torch\\nn\\modules\\transformer.py:306: UserWarning: enable_nested_tensor is True, but self.use_nested_tensor is False because encoder_layer.norm_first was True\n",
      "  warnings.warn(f\"enable_nested_tensor is True, but self.use_nested_tensor is False because {why_not_sparsity_fast_path}\")\n",
      "Hyperparameter combinations:  64%|██████▍   | 231/360 [11:15:34<5:28:05, 152.60s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Early stopping with best val loss: 0.16956084687262774!\n",
      "Running configuration: timesteps=6000, layers=4, heads=32, image_tokens=4, user_tokens=4, learning_rate=0.0001, optimizer=adamw, scheduler=reduce_on_plateau, batch_size=128, noise_schedule=linear, samples_per_user=30, objective=noise-pred, use_ue=False\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Gabriel\\anaconda3\\envs\\recgensys-env\\lib\\site-packages\\torch\\nn\\modules\\transformer.py:306: UserWarning: enable_nested_tensor is True, but self.use_nested_tensor is False because encoder_layer.norm_first was True\n",
      "  warnings.warn(f\"enable_nested_tensor is True, but self.use_nested_tensor is False because {why_not_sparsity_fast_path}\")\n",
      "Hyperparameter combinations:  64%|██████▍   | 232/360 [11:17:03<4:44:56, 133.56s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Early stopping with best val loss: 0.12860851036384702!\n",
      "Running configuration: timesteps=6000, layers=4, heads=32, image_tokens=4, user_tokens=4, learning_rate=0.0001, optimizer=adamw, scheduler=reduce_on_plateau, batch_size=128, noise_schedule=linear, samples_per_user=50, objective=noise-pred, use_ue=True\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Gabriel\\anaconda3\\envs\\recgensys-env\\lib\\site-packages\\torch\\nn\\modules\\transformer.py:306: UserWarning: enable_nested_tensor is True, but self.use_nested_tensor is False because encoder_layer.norm_first was True\n",
      "  warnings.warn(f\"enable_nested_tensor is True, but self.use_nested_tensor is False because {why_not_sparsity_fast_path}\")\n",
      "Hyperparameter combinations:  65%|██████▍   | 233/360 [11:19:10<4:38:27, 131.55s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Early stopping with best val loss: 0.13614747300744057!\n",
      "Running configuration: timesteps=6000, layers=4, heads=32, image_tokens=4, user_tokens=4, learning_rate=0.0001, optimizer=adamw, scheduler=reduce_on_plateau, batch_size=128, noise_schedule=linear, samples_per_user=50, objective=noise-pred, use_ue=False\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Gabriel\\anaconda3\\envs\\recgensys-env\\lib\\site-packages\\torch\\nn\\modules\\transformer.py:306: UserWarning: enable_nested_tensor is True, but self.use_nested_tensor is False because encoder_layer.norm_first was True\n",
      "  warnings.warn(f\"enable_nested_tensor is True, but self.use_nested_tensor is False because {why_not_sparsity_fast_path}\")\n",
      "Hyperparameter combinations:  65%|██████▌   | 234/360 [11:21:00<4:22:13, 124.87s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Early stopping with best val loss: 0.1309955040924251!\n",
      "Running configuration: timesteps=6000, layers=4, heads=32, image_tokens=4, user_tokens=4, learning_rate=0.0001, optimizer=adamw, scheduler=reduce_on_plateau, batch_size=128, noise_schedule=linear, samples_per_user=80, objective=noise-pred, use_ue=True\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Gabriel\\anaconda3\\envs\\recgensys-env\\lib\\site-packages\\torch\\nn\\modules\\transformer.py:306: UserWarning: enable_nested_tensor is True, but self.use_nested_tensor is False because encoder_layer.norm_first was True\n",
      "  warnings.warn(f\"enable_nested_tensor is True, but self.use_nested_tensor is False because {why_not_sparsity_fast_path}\")\n",
      "Hyperparameter combinations:  65%|██████▌   | 235/360 [11:23:13<4:25:36, 127.49s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Early stopping with best val loss: 0.10692499857395887!\n",
      "Running configuration: timesteps=6000, layers=4, heads=32, image_tokens=4, user_tokens=4, learning_rate=0.0001, optimizer=adamw, scheduler=reduce_on_plateau, batch_size=128, noise_schedule=linear, samples_per_user=80, objective=noise-pred, use_ue=False\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Gabriel\\anaconda3\\envs\\recgensys-env\\lib\\site-packages\\torch\\nn\\modules\\transformer.py:306: UserWarning: enable_nested_tensor is True, but self.use_nested_tensor is False because encoder_layer.norm_first was True\n",
      "  warnings.warn(f\"enable_nested_tensor is True, but self.use_nested_tensor is False because {why_not_sparsity_fast_path}\")\n",
      "Hyperparameter combinations:  66%|██████▌   | 236/360 [11:26:22<5:01:20, 145.81s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Early stopping with best val loss: 0.1035128477960825!\n",
      "Running configuration: timesteps=6000, layers=4, heads=32, image_tokens=4, user_tokens=4, learning_rate=0.0001, optimizer=adamw, scheduler=reduce_on_plateau, batch_size=128, noise_schedule=linear, samples_per_user=110, objective=noise-pred, use_ue=True\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Gabriel\\anaconda3\\envs\\recgensys-env\\lib\\site-packages\\torch\\nn\\modules\\transformer.py:306: UserWarning: enable_nested_tensor is True, but self.use_nested_tensor is False because encoder_layer.norm_first was True\n",
      "  warnings.warn(f\"enable_nested_tensor is True, but self.use_nested_tensor is False because {why_not_sparsity_fast_path}\")\n",
      "Hyperparameter combinations:  66%|██████▌   | 237/360 [11:29:09<5:12:14, 152.31s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Early stopping with best val loss: 0.10752690001390874!\n",
      "Running configuration: timesteps=6000, layers=4, heads=32, image_tokens=4, user_tokens=4, learning_rate=0.0001, optimizer=adamw, scheduler=reduce_on_plateau, batch_size=128, noise_schedule=linear, samples_per_user=110, objective=noise-pred, use_ue=False\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Gabriel\\anaconda3\\envs\\recgensys-env\\lib\\site-packages\\torch\\nn\\modules\\transformer.py:306: UserWarning: enable_nested_tensor is True, but self.use_nested_tensor is False because encoder_layer.norm_first was True\n",
      "  warnings.warn(f\"enable_nested_tensor is True, but self.use_nested_tensor is False because {why_not_sparsity_fast_path}\")\n",
      "Hyperparameter combinations:  66%|██████▌   | 238/360 [11:32:02<5:22:21, 158.54s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Early stopping with best val loss: 0.10028693662025034!\n",
      "Running configuration: timesteps=6000, layers=4, heads=32, image_tokens=4, user_tokens=4, learning_rate=0.0001, optimizer=adamw, scheduler=reduce_on_plateau, batch_size=128, noise_schedule=linear, samples_per_user=140, objective=noise-pred, use_ue=True\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Gabriel\\anaconda3\\envs\\recgensys-env\\lib\\site-packages\\torch\\nn\\modules\\transformer.py:306: UserWarning: enable_nested_tensor is True, but self.use_nested_tensor is False because encoder_layer.norm_first was True\n",
      "  warnings.warn(f\"enable_nested_tensor is True, but self.use_nested_tensor is False because {why_not_sparsity_fast_path}\")\n",
      "Hyperparameter combinations:  66%|██████▋   | 239/360 [11:34:45<5:22:27, 159.90s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Early stopping with best val loss: 0.10715243872255087!\n",
      "Running configuration: timesteps=6000, layers=4, heads=32, image_tokens=4, user_tokens=4, learning_rate=0.0001, optimizer=adamw, scheduler=reduce_on_plateau, batch_size=128, noise_schedule=linear, samples_per_user=140, objective=noise-pred, use_ue=False\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Gabriel\\anaconda3\\envs\\recgensys-env\\lib\\site-packages\\torch\\nn\\modules\\transformer.py:306: UserWarning: enable_nested_tensor is True, but self.use_nested_tensor is False because encoder_layer.norm_first was True\n",
      "  warnings.warn(f\"enable_nested_tensor is True, but self.use_nested_tensor is False because {why_not_sparsity_fast_path}\")\n",
      "Hyperparameter combinations:  67%|██████▋   | 240/360 [11:37:02<5:05:52, 152.94s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Early stopping with best val loss: 0.1060917405411601!\n",
      "Running configuration: timesteps=6000, layers=8, heads=8, image_tokens=1, user_tokens=1, learning_rate=0.0001, optimizer=adamw, scheduler=reduce_on_plateau, batch_size=128, noise_schedule=linear, samples_per_user=30, objective=noise-pred, use_ue=True\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Gabriel\\anaconda3\\envs\\recgensys-env\\lib\\site-packages\\torch\\nn\\modules\\transformer.py:306: UserWarning: enable_nested_tensor is True, but self.use_nested_tensor is False because encoder_layer.norm_first was True\n",
      "  warnings.warn(f\"enable_nested_tensor is True, but self.use_nested_tensor is False because {why_not_sparsity_fast_path}\")\n",
      "Hyperparameter combinations:  67%|██████▋   | 241/360 [11:43:27<7:21:28, 222.59s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Early stopping with best val loss: 0.09422217728570104!\n",
      "Running configuration: timesteps=6000, layers=8, heads=8, image_tokens=1, user_tokens=1, learning_rate=0.0001, optimizer=adamw, scheduler=reduce_on_plateau, batch_size=128, noise_schedule=linear, samples_per_user=30, objective=noise-pred, use_ue=False\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Gabriel\\anaconda3\\envs\\recgensys-env\\lib\\site-packages\\torch\\nn\\modules\\transformer.py:306: UserWarning: enable_nested_tensor is True, but self.use_nested_tensor is False because encoder_layer.norm_first was True\n",
      "  warnings.warn(f\"enable_nested_tensor is True, but self.use_nested_tensor is False because {why_not_sparsity_fast_path}\")\n",
      "Hyperparameter combinations:  67%|██████▋   | 242/360 [11:49:05<8:26:00, 257.29s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Early stopping with best val loss: 0.1010564872995019!\n",
      "Running configuration: timesteps=6000, layers=8, heads=8, image_tokens=1, user_tokens=1, learning_rate=0.0001, optimizer=adamw, scheduler=reduce_on_plateau, batch_size=128, noise_schedule=linear, samples_per_user=50, objective=noise-pred, use_ue=True\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Gabriel\\anaconda3\\envs\\recgensys-env\\lib\\site-packages\\torch\\nn\\modules\\transformer.py:306: UserWarning: enable_nested_tensor is True, but self.use_nested_tensor is False because encoder_layer.norm_first was True\n",
      "  warnings.warn(f\"enable_nested_tensor is True, but self.use_nested_tensor is False because {why_not_sparsity_fast_path}\")\n",
      "Hyperparameter combinations:  68%|██████▊   | 243/360 [11:56:44<10:19:43, 317.81s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Early stopping with best val loss: 0.08571864059194922!\n",
      "Running configuration: timesteps=6000, layers=8, heads=8, image_tokens=1, user_tokens=1, learning_rate=0.0001, optimizer=adamw, scheduler=reduce_on_plateau, batch_size=128, noise_schedule=linear, samples_per_user=50, objective=noise-pred, use_ue=False\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Gabriel\\anaconda3\\envs\\recgensys-env\\lib\\site-packages\\torch\\nn\\modules\\transformer.py:306: UserWarning: enable_nested_tensor is True, but self.use_nested_tensor is False because encoder_layer.norm_first was True\n",
      "  warnings.warn(f\"enable_nested_tensor is True, but self.use_nested_tensor is False because {why_not_sparsity_fast_path}\")\n",
      "Hyperparameter combinations:  68%|██████▊   | 244/360 [12:04:18<11:33:21, 358.63s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Early stopping with best val loss: 0.09264970221556723!\n",
      "Running configuration: timesteps=6000, layers=8, heads=8, image_tokens=1, user_tokens=1, learning_rate=0.0001, optimizer=adamw, scheduler=reduce_on_plateau, batch_size=128, noise_schedule=linear, samples_per_user=80, objective=noise-pred, use_ue=True\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Gabriel\\anaconda3\\envs\\recgensys-env\\lib\\site-packages\\torch\\nn\\modules\\transformer.py:306: UserWarning: enable_nested_tensor is True, but self.use_nested_tensor is False because encoder_layer.norm_first was True\n",
      "  warnings.warn(f\"enable_nested_tensor is True, but self.use_nested_tensor is False because {why_not_sparsity_fast_path}\")\n",
      "Hyperparameter combinations:  68%|██████▊   | 245/360 [12:10:55<11:49:08, 369.99s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Early stopping with best val loss: 0.08530710055492818!\n",
      "Running configuration: timesteps=6000, layers=8, heads=8, image_tokens=1, user_tokens=1, learning_rate=0.0001, optimizer=adamw, scheduler=reduce_on_plateau, batch_size=128, noise_schedule=linear, samples_per_user=80, objective=noise-pred, use_ue=False\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Gabriel\\anaconda3\\envs\\recgensys-env\\lib\\site-packages\\torch\\nn\\modules\\transformer.py:306: UserWarning: enable_nested_tensor is True, but self.use_nested_tensor is False because encoder_layer.norm_first was True\n",
      "  warnings.warn(f\"enable_nested_tensor is True, but self.use_nested_tensor is False because {why_not_sparsity_fast_path}\")\n",
      "Hyperparameter combinations:  68%|██████▊   | 246/360 [12:18:23<12:27:19, 393.33s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Early stopping with best val loss: 0.07874282426200807!\n",
      "Running configuration: timesteps=6000, layers=8, heads=8, image_tokens=1, user_tokens=1, learning_rate=0.0001, optimizer=adamw, scheduler=reduce_on_plateau, batch_size=128, noise_schedule=linear, samples_per_user=110, objective=noise-pred, use_ue=True\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Gabriel\\anaconda3\\envs\\recgensys-env\\lib\\site-packages\\torch\\nn\\modules\\transformer.py:306: UserWarning: enable_nested_tensor is True, but self.use_nested_tensor is False because encoder_layer.norm_first was True\n",
      "  warnings.warn(f\"enable_nested_tensor is True, but self.use_nested_tensor is False because {why_not_sparsity_fast_path}\")\n",
      "Hyperparameter combinations:  69%|██████▊   | 247/360 [12:32:59<16:53:44, 538.27s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Early stopping with best val loss: 0.06430289149284363!\n",
      "Running configuration: timesteps=6000, layers=8, heads=8, image_tokens=1, user_tokens=1, learning_rate=0.0001, optimizer=adamw, scheduler=reduce_on_plateau, batch_size=128, noise_schedule=linear, samples_per_user=110, objective=noise-pred, use_ue=False\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Gabriel\\anaconda3\\envs\\recgensys-env\\lib\\site-packages\\torch\\nn\\modules\\transformer.py:306: UserWarning: enable_nested_tensor is True, but self.use_nested_tensor is False because encoder_layer.norm_first was True\n",
      "  warnings.warn(f\"enable_nested_tensor is True, but self.use_nested_tensor is False because {why_not_sparsity_fast_path}\")\n",
      "Hyperparameter combinations:  69%|██████▉   | 248/360 [12:45:25<18:41:08, 600.61s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Early stopping with best val loss: 0.07000455749221146!\n",
      "Running configuration: timesteps=6000, layers=8, heads=8, image_tokens=1, user_tokens=1, learning_rate=0.0001, optimizer=adamw, scheduler=reduce_on_plateau, batch_size=128, noise_schedule=linear, samples_per_user=140, objective=noise-pred, use_ue=True\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Gabriel\\anaconda3\\envs\\recgensys-env\\lib\\site-packages\\torch\\nn\\modules\\transformer.py:306: UserWarning: enable_nested_tensor is True, but self.use_nested_tensor is False because encoder_layer.norm_first was True\n",
      "  warnings.warn(f\"enable_nested_tensor is True, but self.use_nested_tensor is False because {why_not_sparsity_fast_path}\")\n",
      "Hyperparameter combinations:  69%|██████▉   | 249/360 [12:54:07<17:47:10, 576.86s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Early stopping with best val loss: 0.07582976995036006!\n",
      "Running configuration: timesteps=6000, layers=8, heads=8, image_tokens=1, user_tokens=1, learning_rate=0.0001, optimizer=adamw, scheduler=reduce_on_plateau, batch_size=128, noise_schedule=linear, samples_per_user=140, objective=noise-pred, use_ue=False\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Gabriel\\anaconda3\\envs\\recgensys-env\\lib\\site-packages\\torch\\nn\\modules\\transformer.py:306: UserWarning: enable_nested_tensor is True, but self.use_nested_tensor is False because encoder_layer.norm_first was True\n",
      "  warnings.warn(f\"enable_nested_tensor is True, but self.use_nested_tensor is False because {why_not_sparsity_fast_path}\")\n",
      "Hyperparameter combinations:  69%|██████▉   | 250/360 [13:07:21<19:37:07, 642.07s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Early stopping with best val loss: 0.06711287470534444!\n",
      "Running configuration: timesteps=6000, layers=8, heads=8, image_tokens=1, user_tokens=4, learning_rate=0.0001, optimizer=adamw, scheduler=reduce_on_plateau, batch_size=128, noise_schedule=linear, samples_per_user=30, objective=noise-pred, use_ue=True\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Gabriel\\anaconda3\\envs\\recgensys-env\\lib\\site-packages\\torch\\nn\\modules\\transformer.py:306: UserWarning: enable_nested_tensor is True, but self.use_nested_tensor is False because encoder_layer.norm_first was True\n",
      "  warnings.warn(f\"enable_nested_tensor is True, but self.use_nested_tensor is False because {why_not_sparsity_fast_path}\")\n",
      "Hyperparameter combinations:  70%|██████▉   | 251/360 [13:15:37<18:07:07, 598.42s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Early stopping with best val loss: 0.088515360141173!\n",
      "Running configuration: timesteps=6000, layers=8, heads=8, image_tokens=1, user_tokens=4, learning_rate=0.0001, optimizer=adamw, scheduler=reduce_on_plateau, batch_size=128, noise_schedule=linear, samples_per_user=30, objective=noise-pred, use_ue=False\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Gabriel\\anaconda3\\envs\\recgensys-env\\lib\\site-packages\\torch\\nn\\modules\\transformer.py:306: UserWarning: enable_nested_tensor is True, but self.use_nested_tensor is False because encoder_layer.norm_first was True\n",
      "  warnings.warn(f\"enable_nested_tensor is True, but self.use_nested_tensor is False because {why_not_sparsity_fast_path}\")\n",
      "Hyperparameter combinations:  70%|███████   | 252/360 [13:20:47<15:21:17, 511.83s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Early stopping with best val loss: 0.09442261746153235!\n",
      "Running configuration: timesteps=6000, layers=8, heads=8, image_tokens=1, user_tokens=4, learning_rate=0.0001, optimizer=adamw, scheduler=reduce_on_plateau, batch_size=128, noise_schedule=linear, samples_per_user=50, objective=noise-pred, use_ue=True\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Gabriel\\anaconda3\\envs\\recgensys-env\\lib\\site-packages\\torch\\nn\\modules\\transformer.py:306: UserWarning: enable_nested_tensor is True, but self.use_nested_tensor is False because encoder_layer.norm_first was True\n",
      "  warnings.warn(f\"enable_nested_tensor is True, but self.use_nested_tensor is False because {why_not_sparsity_fast_path}\")\n",
      "Hyperparameter combinations:  70%|███████   | 253/360 [13:30:50<16:01:21, 539.08s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Early stopping with best val loss: 0.07475262088701129!\n",
      "Running configuration: timesteps=6000, layers=8, heads=8, image_tokens=1, user_tokens=4, learning_rate=0.0001, optimizer=adamw, scheduler=reduce_on_plateau, batch_size=128, noise_schedule=linear, samples_per_user=50, objective=noise-pred, use_ue=False\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Gabriel\\anaconda3\\envs\\recgensys-env\\lib\\site-packages\\torch\\nn\\modules\\transformer.py:306: UserWarning: enable_nested_tensor is True, but self.use_nested_tensor is False because encoder_layer.norm_first was True\n",
      "  warnings.warn(f\"enable_nested_tensor is True, but self.use_nested_tensor is False because {why_not_sparsity_fast_path}\")\n",
      "Hyperparameter combinations:  71%|███████   | 254/360 [13:40:25<16:11:18, 549.80s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Early stopping with best val loss: 0.07371258176863194!\n",
      "Running configuration: timesteps=6000, layers=8, heads=8, image_tokens=1, user_tokens=4, learning_rate=0.0001, optimizer=adamw, scheduler=reduce_on_plateau, batch_size=128, noise_schedule=linear, samples_per_user=80, objective=noise-pred, use_ue=True\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Gabriel\\anaconda3\\envs\\recgensys-env\\lib\\site-packages\\torch\\nn\\modules\\transformer.py:306: UserWarning: enable_nested_tensor is True, but self.use_nested_tensor is False because encoder_layer.norm_first was True\n",
      "  warnings.warn(f\"enable_nested_tensor is True, but self.use_nested_tensor is False because {why_not_sparsity_fast_path}\")\n",
      "Hyperparameter combinations:  71%|███████   | 255/360 [13:53:12<17:56:19, 615.04s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Early stopping with best val loss: 0.07377427793107927!\n",
      "Running configuration: timesteps=6000, layers=8, heads=8, image_tokens=1, user_tokens=4, learning_rate=0.0001, optimizer=adamw, scheduler=reduce_on_plateau, batch_size=128, noise_schedule=linear, samples_per_user=80, objective=noise-pred, use_ue=False\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Gabriel\\anaconda3\\envs\\recgensys-env\\lib\\site-packages\\torch\\nn\\modules\\transformer.py:306: UserWarning: enable_nested_tensor is True, but self.use_nested_tensor is False because encoder_layer.norm_first was True\n",
      "  warnings.warn(f\"enable_nested_tensor is True, but self.use_nested_tensor is False because {why_not_sparsity_fast_path}\")\n",
      "Hyperparameter combinations:  71%|███████   | 256/360 [14:02:05<17:03:26, 590.44s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Early stopping with best val loss: 0.07646169466897845!\n",
      "Running configuration: timesteps=6000, layers=8, heads=8, image_tokens=1, user_tokens=4, learning_rate=0.0001, optimizer=adamw, scheduler=reduce_on_plateau, batch_size=128, noise_schedule=linear, samples_per_user=110, objective=noise-pred, use_ue=True\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Gabriel\\anaconda3\\envs\\recgensys-env\\lib\\site-packages\\torch\\nn\\modules\\transformer.py:306: UserWarning: enable_nested_tensor is True, but self.use_nested_tensor is False because encoder_layer.norm_first was True\n",
      "  warnings.warn(f\"enable_nested_tensor is True, but self.use_nested_tensor is False because {why_not_sparsity_fast_path}\")\n",
      "Hyperparameter combinations:  71%|███████▏  | 257/360 [14:14:10<18:02:49, 630.77s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Early stopping with best val loss: 0.07516078231856227!\n",
      "Running configuration: timesteps=6000, layers=8, heads=8, image_tokens=1, user_tokens=4, learning_rate=0.0001, optimizer=adamw, scheduler=reduce_on_plateau, batch_size=128, noise_schedule=linear, samples_per_user=110, objective=noise-pred, use_ue=False\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Gabriel\\anaconda3\\envs\\recgensys-env\\lib\\site-packages\\torch\\nn\\modules\\transformer.py:306: UserWarning: enable_nested_tensor is True, but self.use_nested_tensor is False because encoder_layer.norm_first was True\n",
      "  warnings.warn(f\"enable_nested_tensor is True, but self.use_nested_tensor is False because {why_not_sparsity_fast_path}\")\n",
      "Hyperparameter combinations:  72%|███████▏  | 258/360 [14:24:06<17:34:34, 620.34s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Early stopping with best val loss: 0.07549991807900369!\n",
      "Running configuration: timesteps=6000, layers=8, heads=8, image_tokens=1, user_tokens=4, learning_rate=0.0001, optimizer=adamw, scheduler=reduce_on_plateau, batch_size=128, noise_schedule=linear, samples_per_user=140, objective=noise-pred, use_ue=True\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Gabriel\\anaconda3\\envs\\recgensys-env\\lib\\site-packages\\torch\\nn\\modules\\transformer.py:306: UserWarning: enable_nested_tensor is True, but self.use_nested_tensor is False because encoder_layer.norm_first was True\n",
      "  warnings.warn(f\"enable_nested_tensor is True, but self.use_nested_tensor is False because {why_not_sparsity_fast_path}\")\n",
      "Hyperparameter combinations:  72%|███████▏  | 259/360 [14:38:24<19:24:33, 691.82s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Early stopping with best val loss: 0.07026818534359336!\n",
      "Running configuration: timesteps=6000, layers=8, heads=8, image_tokens=1, user_tokens=4, learning_rate=0.0001, optimizer=adamw, scheduler=reduce_on_plateau, batch_size=128, noise_schedule=linear, samples_per_user=140, objective=noise-pred, use_ue=False\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Gabriel\\anaconda3\\envs\\recgensys-env\\lib\\site-packages\\torch\\nn\\modules\\transformer.py:306: UserWarning: enable_nested_tensor is True, but self.use_nested_tensor is False because encoder_layer.norm_first was True\n",
      "  warnings.warn(f\"enable_nested_tensor is True, but self.use_nested_tensor is False because {why_not_sparsity_fast_path}\")\n",
      "Hyperparameter combinations:  72%|███████▏  | 260/360 [14:54:19<21:24:38, 770.79s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Early stopping with best val loss: 0.06447548419237137!\n",
      "Running configuration: timesteps=6000, layers=8, heads=8, image_tokens=4, user_tokens=1, learning_rate=0.0001, optimizer=adamw, scheduler=reduce_on_plateau, batch_size=128, noise_schedule=linear, samples_per_user=30, objective=noise-pred, use_ue=True\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Gabriel\\anaconda3\\envs\\recgensys-env\\lib\\site-packages\\torch\\nn\\modules\\transformer.py:306: UserWarning: enable_nested_tensor is True, but self.use_nested_tensor is False because encoder_layer.norm_first was True\n",
      "  warnings.warn(f\"enable_nested_tensor is True, but self.use_nested_tensor is False because {why_not_sparsity_fast_path}\")\n",
      "Hyperparameter combinations:  72%|███████▎  | 261/360 [14:56:20<15:49:47, 575.63s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Early stopping with best val loss: 0.14015654986724257!\n",
      "Running configuration: timesteps=6000, layers=8, heads=8, image_tokens=4, user_tokens=1, learning_rate=0.0001, optimizer=adamw, scheduler=reduce_on_plateau, batch_size=128, noise_schedule=linear, samples_per_user=30, objective=noise-pred, use_ue=False\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Gabriel\\anaconda3\\envs\\recgensys-env\\lib\\site-packages\\torch\\nn\\modules\\transformer.py:306: UserWarning: enable_nested_tensor is True, but self.use_nested_tensor is False because encoder_layer.norm_first was True\n",
      "  warnings.warn(f\"enable_nested_tensor is True, but self.use_nested_tensor is False because {why_not_sparsity_fast_path}\")\n",
      "Hyperparameter combinations:  73%|███████▎  | 262/360 [14:58:37<12:05:31, 444.20s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Early stopping with best val loss: 0.12283235602080822!\n",
      "Running configuration: timesteps=6000, layers=8, heads=8, image_tokens=4, user_tokens=1, learning_rate=0.0001, optimizer=adamw, scheduler=reduce_on_plateau, batch_size=128, noise_schedule=linear, samples_per_user=50, objective=noise-pred, use_ue=True\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Gabriel\\anaconda3\\envs\\recgensys-env\\lib\\site-packages\\torch\\nn\\modules\\transformer.py:306: UserWarning: enable_nested_tensor is True, but self.use_nested_tensor is False because encoder_layer.norm_first was True\n",
      "  warnings.warn(f\"enable_nested_tensor is True, but self.use_nested_tensor is False because {why_not_sparsity_fast_path}\")\n",
      "Hyperparameter combinations:  73%|███████▎  | 263/360 [15:01:59<10:00:34, 371.49s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Early stopping with best val loss: 0.10430924943648279!\n",
      "Running configuration: timesteps=6000, layers=8, heads=8, image_tokens=4, user_tokens=1, learning_rate=0.0001, optimizer=adamw, scheduler=reduce_on_plateau, batch_size=128, noise_schedule=linear, samples_per_user=50, objective=noise-pred, use_ue=False\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Gabriel\\anaconda3\\envs\\recgensys-env\\lib\\site-packages\\torch\\nn\\modules\\transformer.py:306: UserWarning: enable_nested_tensor is True, but self.use_nested_tensor is False because encoder_layer.norm_first was True\n",
      "  warnings.warn(f\"enable_nested_tensor is True, but self.use_nested_tensor is False because {why_not_sparsity_fast_path}\")\n",
      "Hyperparameter combinations:  73%|███████▎  | 264/360 [15:05:50<8:46:41, 329.18s/it] "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Early stopping with best val loss: 0.11293251113966107!\n",
      "Running configuration: timesteps=6000, layers=8, heads=8, image_tokens=4, user_tokens=1, learning_rate=0.0001, optimizer=adamw, scheduler=reduce_on_plateau, batch_size=128, noise_schedule=linear, samples_per_user=80, objective=noise-pred, use_ue=True\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Gabriel\\anaconda3\\envs\\recgensys-env\\lib\\site-packages\\torch\\nn\\modules\\transformer.py:306: UserWarning: enable_nested_tensor is True, but self.use_nested_tensor is False because encoder_layer.norm_first was True\n",
      "  warnings.warn(f\"enable_nested_tensor is True, but self.use_nested_tensor is False because {why_not_sparsity_fast_path}\")\n",
      "Hyperparameter combinations:  74%|███████▎  | 265/360 [15:10:11<8:09:16, 309.02s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Early stopping with best val loss: 0.10611005406826735!\n",
      "Running configuration: timesteps=6000, layers=8, heads=8, image_tokens=4, user_tokens=1, learning_rate=0.0001, optimizer=adamw, scheduler=reduce_on_plateau, batch_size=128, noise_schedule=linear, samples_per_user=80, objective=noise-pred, use_ue=False\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Gabriel\\anaconda3\\envs\\recgensys-env\\lib\\site-packages\\torch\\nn\\modules\\transformer.py:306: UserWarning: enable_nested_tensor is True, but self.use_nested_tensor is False because encoder_layer.norm_first was True\n",
      "  warnings.warn(f\"enable_nested_tensor is True, but self.use_nested_tensor is False because {why_not_sparsity_fast_path}\")\n",
      "Hyperparameter combinations:  74%|███████▍  | 266/360 [15:16:09<8:26:43, 323.44s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Early stopping with best val loss: 0.09553527366369963!\n",
      "Running configuration: timesteps=6000, layers=8, heads=8, image_tokens=4, user_tokens=1, learning_rate=0.0001, optimizer=adamw, scheduler=reduce_on_plateau, batch_size=128, noise_schedule=linear, samples_per_user=110, objective=noise-pred, use_ue=True\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Gabriel\\anaconda3\\envs\\recgensys-env\\lib\\site-packages\\torch\\nn\\modules\\transformer.py:306: UserWarning: enable_nested_tensor is True, but self.use_nested_tensor is False because encoder_layer.norm_first was True\n",
      "  warnings.warn(f\"enable_nested_tensor is True, but self.use_nested_tensor is False because {why_not_sparsity_fast_path}\")\n",
      "Hyperparameter combinations:  74%|███████▍  | 267/360 [15:22:41<8:53:20, 344.09s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Early stopping with best val loss: 0.10646706214174628!\n",
      "Running configuration: timesteps=6000, layers=8, heads=8, image_tokens=4, user_tokens=1, learning_rate=0.0001, optimizer=adamw, scheduler=reduce_on_plateau, batch_size=128, noise_schedule=linear, samples_per_user=110, objective=noise-pred, use_ue=False\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Gabriel\\anaconda3\\envs\\recgensys-env\\lib\\site-packages\\torch\\nn\\modules\\transformer.py:306: UserWarning: enable_nested_tensor is True, but self.use_nested_tensor is False because encoder_layer.norm_first was True\n",
      "  warnings.warn(f\"enable_nested_tensor is True, but self.use_nested_tensor is False because {why_not_sparsity_fast_path}\")\n",
      "Hyperparameter combinations:  74%|███████▍  | 268/360 [15:26:17<7:48:44, 305.70s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Early stopping with best val loss: 0.10501181008294225!\n",
      "Running configuration: timesteps=6000, layers=8, heads=8, image_tokens=4, user_tokens=1, learning_rate=0.0001, optimizer=adamw, scheduler=reduce_on_plateau, batch_size=128, noise_schedule=linear, samples_per_user=140, objective=noise-pred, use_ue=True\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Gabriel\\anaconda3\\envs\\recgensys-env\\lib\\site-packages\\torch\\nn\\modules\\transformer.py:306: UserWarning: enable_nested_tensor is True, but self.use_nested_tensor is False because encoder_layer.norm_first was True\n",
      "  warnings.warn(f\"enable_nested_tensor is True, but self.use_nested_tensor is False because {why_not_sparsity_fast_path}\")\n",
      "Hyperparameter combinations:  75%|███████▍  | 269/360 [15:31:34<7:48:56, 309.20s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Early stopping with best val loss: 0.09431103290989995!\n",
      "Running configuration: timesteps=6000, layers=8, heads=8, image_tokens=4, user_tokens=1, learning_rate=0.0001, optimizer=adamw, scheduler=reduce_on_plateau, batch_size=128, noise_schedule=linear, samples_per_user=140, objective=noise-pred, use_ue=False\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Gabriel\\anaconda3\\envs\\recgensys-env\\lib\\site-packages\\torch\\nn\\modules\\transformer.py:306: UserWarning: enable_nested_tensor is True, but self.use_nested_tensor is False because encoder_layer.norm_first was True\n",
      "  warnings.warn(f\"enable_nested_tensor is True, but self.use_nested_tensor is False because {why_not_sparsity_fast_path}\")\n",
      "Hyperparameter combinations:  75%|███████▌  | 270/360 [15:37:11<7:56:20, 317.56s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Early stopping with best val loss: 0.0985731310211122!\n",
      "Running configuration: timesteps=6000, layers=8, heads=8, image_tokens=4, user_tokens=4, learning_rate=0.0001, optimizer=adamw, scheduler=reduce_on_plateau, batch_size=128, noise_schedule=linear, samples_per_user=30, objective=noise-pred, use_ue=True\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Gabriel\\anaconda3\\envs\\recgensys-env\\lib\\site-packages\\torch\\nn\\modules\\transformer.py:306: UserWarning: enable_nested_tensor is True, but self.use_nested_tensor is False because encoder_layer.norm_first was True\n",
      "  warnings.warn(f\"enable_nested_tensor is True, but self.use_nested_tensor is False because {why_not_sparsity_fast_path}\")\n",
      "Hyperparameter combinations:  75%|███████▌  | 271/360 [15:39:23<6:28:18, 261.78s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Early stopping with best val loss: 0.14295661402866244!\n",
      "Running configuration: timesteps=6000, layers=8, heads=8, image_tokens=4, user_tokens=4, learning_rate=0.0001, optimizer=adamw, scheduler=reduce_on_plateau, batch_size=128, noise_schedule=linear, samples_per_user=30, objective=noise-pred, use_ue=False\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Gabriel\\anaconda3\\envs\\recgensys-env\\lib\\site-packages\\torch\\nn\\modules\\transformer.py:306: UserWarning: enable_nested_tensor is True, but self.use_nested_tensor is False because encoder_layer.norm_first was True\n",
      "  warnings.warn(f\"enable_nested_tensor is True, but self.use_nested_tensor is False because {why_not_sparsity_fast_path}\")\n",
      "Hyperparameter combinations:  76%|███████▌  | 272/360 [15:41:54<5:35:18, 228.62s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Early stopping with best val loss: 0.12056317366659641!\n",
      "Running configuration: timesteps=6000, layers=8, heads=8, image_tokens=4, user_tokens=4, learning_rate=0.0001, optimizer=adamw, scheduler=reduce_on_plateau, batch_size=128, noise_schedule=linear, samples_per_user=50, objective=noise-pred, use_ue=True\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Gabriel\\anaconda3\\envs\\recgensys-env\\lib\\site-packages\\torch\\nn\\modules\\transformer.py:306: UserWarning: enable_nested_tensor is True, but self.use_nested_tensor is False because encoder_layer.norm_first was True\n",
      "  warnings.warn(f\"enable_nested_tensor is True, but self.use_nested_tensor is False because {why_not_sparsity_fast_path}\")\n",
      "Hyperparameter combinations:  76%|███████▌  | 273/360 [15:44:45<5:06:21, 211.28s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Early stopping with best val loss: 0.1139246872626245!\n",
      "Running configuration: timesteps=6000, layers=8, heads=8, image_tokens=4, user_tokens=4, learning_rate=0.0001, optimizer=adamw, scheduler=reduce_on_plateau, batch_size=128, noise_schedule=linear, samples_per_user=50, objective=noise-pred, use_ue=False\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Gabriel\\anaconda3\\envs\\recgensys-env\\lib\\site-packages\\torch\\nn\\modules\\transformer.py:306: UserWarning: enable_nested_tensor is True, but self.use_nested_tensor is False because encoder_layer.norm_first was True\n",
      "  warnings.warn(f\"enable_nested_tensor is True, but self.use_nested_tensor is False because {why_not_sparsity_fast_path}\")\n",
      "Hyperparameter combinations:  76%|███████▌  | 274/360 [15:47:54<4:53:06, 204.50s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Early stopping with best val loss: 0.1095494800247252!\n",
      "Running configuration: timesteps=6000, layers=8, heads=8, image_tokens=4, user_tokens=4, learning_rate=0.0001, optimizer=adamw, scheduler=reduce_on_plateau, batch_size=128, noise_schedule=linear, samples_per_user=80, objective=noise-pred, use_ue=True\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Gabriel\\anaconda3\\envs\\recgensys-env\\lib\\site-packages\\torch\\nn\\modules\\transformer.py:306: UserWarning: enable_nested_tensor is True, but self.use_nested_tensor is False because encoder_layer.norm_first was True\n",
      "  warnings.warn(f\"enable_nested_tensor is True, but self.use_nested_tensor is False because {why_not_sparsity_fast_path}\")\n",
      "Hyperparameter combinations:  76%|███████▋  | 275/360 [15:53:04<5:34:32, 236.14s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Early stopping with best val loss: 0.09790034778416157!\n",
      "Running configuration: timesteps=6000, layers=8, heads=8, image_tokens=4, user_tokens=4, learning_rate=0.0001, optimizer=adamw, scheduler=reduce_on_plateau, batch_size=128, noise_schedule=linear, samples_per_user=80, objective=noise-pred, use_ue=False\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Gabriel\\anaconda3\\envs\\recgensys-env\\lib\\site-packages\\torch\\nn\\modules\\transformer.py:306: UserWarning: enable_nested_tensor is True, but self.use_nested_tensor is False because encoder_layer.norm_first was True\n",
      "  warnings.warn(f\"enable_nested_tensor is True, but self.use_nested_tensor is False because {why_not_sparsity_fast_path}\")\n",
      "Hyperparameter combinations:  77%|███████▋  | 276/360 [15:56:45<5:24:28, 231.77s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Early stopping with best val loss: 0.10726702818647027!\n",
      "Running configuration: timesteps=6000, layers=8, heads=8, image_tokens=4, user_tokens=4, learning_rate=0.0001, optimizer=adamw, scheduler=reduce_on_plateau, batch_size=128, noise_schedule=linear, samples_per_user=110, objective=noise-pred, use_ue=True\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Gabriel\\anaconda3\\envs\\recgensys-env\\lib\\site-packages\\torch\\nn\\modules\\transformer.py:306: UserWarning: enable_nested_tensor is True, but self.use_nested_tensor is False because encoder_layer.norm_first was True\n",
      "  warnings.warn(f\"enable_nested_tensor is True, but self.use_nested_tensor is False because {why_not_sparsity_fast_path}\")\n",
      "Hyperparameter combinations:  77%|███████▋  | 277/360 [16:01:47<5:49:29, 252.64s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Early stopping with best val loss: 0.09402724425308406!\n",
      "Running configuration: timesteps=6000, layers=8, heads=8, image_tokens=4, user_tokens=4, learning_rate=0.0001, optimizer=adamw, scheduler=reduce_on_plateau, batch_size=128, noise_schedule=linear, samples_per_user=110, objective=noise-pred, use_ue=False\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Gabriel\\anaconda3\\envs\\recgensys-env\\lib\\site-packages\\torch\\nn\\modules\\transformer.py:306: UserWarning: enable_nested_tensor is True, but self.use_nested_tensor is False because encoder_layer.norm_first was True\n",
      "  warnings.warn(f\"enable_nested_tensor is True, but self.use_nested_tensor is False because {why_not_sparsity_fast_path}\")\n",
      "Hyperparameter combinations:  77%|███████▋  | 278/360 [16:06:26<5:56:05, 260.55s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Early stopping with best val loss: 0.10236456943675876!\n",
      "Running configuration: timesteps=6000, layers=8, heads=8, image_tokens=4, user_tokens=4, learning_rate=0.0001, optimizer=adamw, scheduler=reduce_on_plateau, batch_size=128, noise_schedule=linear, samples_per_user=140, objective=noise-pred, use_ue=True\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Gabriel\\anaconda3\\envs\\recgensys-env\\lib\\site-packages\\torch\\nn\\modules\\transformer.py:306: UserWarning: enable_nested_tensor is True, but self.use_nested_tensor is False because encoder_layer.norm_first was True\n",
      "  warnings.warn(f\"enable_nested_tensor is True, but self.use_nested_tensor is False because {why_not_sparsity_fast_path}\")\n",
      "Hyperparameter combinations:  78%|███████▊  | 279/360 [16:18:56<9:10:04, 407.46s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Early stopping with best val loss: 0.09577467618510127!\n",
      "Running configuration: timesteps=6000, layers=8, heads=8, image_tokens=4, user_tokens=4, learning_rate=0.0001, optimizer=adamw, scheduler=reduce_on_plateau, batch_size=128, noise_schedule=linear, samples_per_user=140, objective=noise-pred, use_ue=False\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Gabriel\\anaconda3\\envs\\recgensys-env\\lib\\site-packages\\torch\\nn\\modules\\transformer.py:306: UserWarning: enable_nested_tensor is True, but self.use_nested_tensor is False because encoder_layer.norm_first was True\n",
      "  warnings.warn(f\"enable_nested_tensor is True, but self.use_nested_tensor is False because {why_not_sparsity_fast_path}\")\n",
      "Hyperparameter combinations:  78%|███████▊  | 280/360 [16:28:48<10:17:18, 462.98s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Early stopping with best val loss: 0.09555441117845476!\n",
      "Running configuration: timesteps=6000, layers=8, heads=16, image_tokens=1, user_tokens=1, learning_rate=0.0001, optimizer=adamw, scheduler=reduce_on_plateau, batch_size=128, noise_schedule=linear, samples_per_user=30, objective=noise-pred, use_ue=True\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Gabriel\\anaconda3\\envs\\recgensys-env\\lib\\site-packages\\torch\\nn\\modules\\transformer.py:306: UserWarning: enable_nested_tensor is True, but self.use_nested_tensor is False because encoder_layer.norm_first was True\n",
      "  warnings.warn(f\"enable_nested_tensor is True, but self.use_nested_tensor is False because {why_not_sparsity_fast_path}\")\n",
      "Hyperparameter combinations:  78%|███████▊  | 281/360 [16:36:57<10:19:38, 470.61s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Early stopping with best val loss: 0.09569295914843678!\n",
      "Running configuration: timesteps=6000, layers=8, heads=16, image_tokens=1, user_tokens=1, learning_rate=0.0001, optimizer=adamw, scheduler=reduce_on_plateau, batch_size=128, noise_schedule=linear, samples_per_user=30, objective=noise-pred, use_ue=False\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Gabriel\\anaconda3\\envs\\recgensys-env\\lib\\site-packages\\torch\\nn\\modules\\transformer.py:306: UserWarning: enable_nested_tensor is True, but self.use_nested_tensor is False because encoder_layer.norm_first was True\n",
      "  warnings.warn(f\"enable_nested_tensor is True, but self.use_nested_tensor is False because {why_not_sparsity_fast_path}\")\n",
      "Hyperparameter combinations:  78%|███████▊  | 282/360 [16:45:14<10:21:57, 478.44s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Early stopping with best val loss: 0.0861187509726733!\n",
      "Running configuration: timesteps=6000, layers=8, heads=16, image_tokens=1, user_tokens=1, learning_rate=0.0001, optimizer=adamw, scheduler=reduce_on_plateau, batch_size=128, noise_schedule=linear, samples_per_user=50, objective=noise-pred, use_ue=True\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Gabriel\\anaconda3\\envs\\recgensys-env\\lib\\site-packages\\torch\\nn\\modules\\transformer.py:306: UserWarning: enable_nested_tensor is True, but self.use_nested_tensor is False because encoder_layer.norm_first was True\n",
      "  warnings.warn(f\"enable_nested_tensor is True, but self.use_nested_tensor is False because {why_not_sparsity_fast_path}\")\n",
      "Hyperparameter combinations:  79%|███████▊  | 283/360 [16:53:56<10:30:47, 491.53s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Early stopping with best val loss: 0.0795731064863503!\n",
      "Running configuration: timesteps=6000, layers=8, heads=16, image_tokens=1, user_tokens=1, learning_rate=0.0001, optimizer=adamw, scheduler=reduce_on_plateau, batch_size=128, noise_schedule=linear, samples_per_user=50, objective=noise-pred, use_ue=False\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Gabriel\\anaconda3\\envs\\recgensys-env\\lib\\site-packages\\torch\\nn\\modules\\transformer.py:306: UserWarning: enable_nested_tensor is True, but self.use_nested_tensor is False because encoder_layer.norm_first was True\n",
      "  warnings.warn(f\"enable_nested_tensor is True, but self.use_nested_tensor is False because {why_not_sparsity_fast_path}\")\n",
      "Hyperparameter combinations:  79%|███████▉  | 284/360 [17:04:35<11:18:43, 535.84s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Early stopping with best val loss: 0.07467379583977163!\n",
      "Running configuration: timesteps=6000, layers=8, heads=16, image_tokens=1, user_tokens=1, learning_rate=0.0001, optimizer=adamw, scheduler=reduce_on_plateau, batch_size=128, noise_schedule=linear, samples_per_user=80, objective=noise-pred, use_ue=True\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Gabriel\\anaconda3\\envs\\recgensys-env\\lib\\site-packages\\torch\\nn\\modules\\transformer.py:306: UserWarning: enable_nested_tensor is True, but self.use_nested_tensor is False because encoder_layer.norm_first was True\n",
      "  warnings.warn(f\"enable_nested_tensor is True, but self.use_nested_tensor is False because {why_not_sparsity_fast_path}\")\n",
      "Hyperparameter combinations:  79%|███████▉  | 285/360 [17:13:12<11:02:44, 530.19s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Early stopping with best val loss: 0.07403185218572617!\n",
      "Running configuration: timesteps=6000, layers=8, heads=16, image_tokens=1, user_tokens=1, learning_rate=0.0001, optimizer=adamw, scheduler=reduce_on_plateau, batch_size=128, noise_schedule=linear, samples_per_user=80, objective=noise-pred, use_ue=False\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Gabriel\\anaconda3\\envs\\recgensys-env\\lib\\site-packages\\torch\\nn\\modules\\transformer.py:306: UserWarning: enable_nested_tensor is True, but self.use_nested_tensor is False because encoder_layer.norm_first was True\n",
      "  warnings.warn(f\"enable_nested_tensor is True, but self.use_nested_tensor is False because {why_not_sparsity_fast_path}\")\n",
      "Hyperparameter combinations:  79%|███████▉  | 286/360 [17:24:11<11:41:41, 568.93s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Early stopping with best val loss: 0.0721840241458267!\n",
      "Running configuration: timesteps=6000, layers=8, heads=16, image_tokens=1, user_tokens=1, learning_rate=0.0001, optimizer=adamw, scheduler=reduce_on_plateau, batch_size=128, noise_schedule=linear, samples_per_user=110, objective=noise-pred, use_ue=True\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Gabriel\\anaconda3\\envs\\recgensys-env\\lib\\site-packages\\torch\\nn\\modules\\transformer.py:306: UserWarning: enable_nested_tensor is True, but self.use_nested_tensor is False because encoder_layer.norm_first was True\n",
      "  warnings.warn(f\"enable_nested_tensor is True, but self.use_nested_tensor is False because {why_not_sparsity_fast_path}\")\n",
      "Hyperparameter combinations:  80%|███████▉  | 287/360 [17:36:05<12:25:02, 612.36s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Early stopping with best val loss: 0.07340769050642848!\n",
      "Running configuration: timesteps=6000, layers=8, heads=16, image_tokens=1, user_tokens=1, learning_rate=0.0001, optimizer=adamw, scheduler=reduce_on_plateau, batch_size=128, noise_schedule=linear, samples_per_user=110, objective=noise-pred, use_ue=False\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Gabriel\\anaconda3\\envs\\recgensys-env\\lib\\site-packages\\torch\\nn\\modules\\transformer.py:306: UserWarning: enable_nested_tensor is True, but self.use_nested_tensor is False because encoder_layer.norm_first was True\n",
      "  warnings.warn(f\"enable_nested_tensor is True, but self.use_nested_tensor is False because {why_not_sparsity_fast_path}\")\n",
      "Hyperparameter combinations:  80%|████████  | 288/360 [17:50:32<13:46:28, 688.73s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Early stopping with best val loss: 0.0693460030015558!\n",
      "Running configuration: timesteps=6000, layers=8, heads=16, image_tokens=1, user_tokens=1, learning_rate=0.0001, optimizer=adamw, scheduler=reduce_on_plateau, batch_size=128, noise_schedule=linear, samples_per_user=140, objective=noise-pred, use_ue=True\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Gabriel\\anaconda3\\envs\\recgensys-env\\lib\\site-packages\\torch\\nn\\modules\\transformer.py:306: UserWarning: enable_nested_tensor is True, but self.use_nested_tensor is False because encoder_layer.norm_first was True\n",
      "  warnings.warn(f\"enable_nested_tensor is True, but self.use_nested_tensor is False because {why_not_sparsity_fast_path}\")\n",
      "Hyperparameter combinations:  80%|████████  | 289/360 [18:06:50<15:17:49, 775.62s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Early stopping with best val loss: 0.06313292100094259!\n",
      "Running configuration: timesteps=6000, layers=8, heads=16, image_tokens=1, user_tokens=1, learning_rate=0.0001, optimizer=adamw, scheduler=reduce_on_plateau, batch_size=128, noise_schedule=linear, samples_per_user=140, objective=noise-pred, use_ue=False\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Gabriel\\anaconda3\\envs\\recgensys-env\\lib\\site-packages\\torch\\nn\\modules\\transformer.py:306: UserWarning: enable_nested_tensor is True, but self.use_nested_tensor is False because encoder_layer.norm_first was True\n",
      "  warnings.warn(f\"enable_nested_tensor is True, but self.use_nested_tensor is False because {why_not_sparsity_fast_path}\")\n",
      "Hyperparameter combinations:  81%|████████  | 290/360 [18:21:05<15:32:41, 799.45s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Early stopping with best val loss: 0.06384181941393763!\n",
      "Running configuration: timesteps=6000, layers=8, heads=16, image_tokens=1, user_tokens=4, learning_rate=0.0001, optimizer=adamw, scheduler=reduce_on_plateau, batch_size=128, noise_schedule=linear, samples_per_user=30, objective=noise-pred, use_ue=True\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Gabriel\\anaconda3\\envs\\recgensys-env\\lib\\site-packages\\torch\\nn\\modules\\transformer.py:306: UserWarning: enable_nested_tensor is True, but self.use_nested_tensor is False because encoder_layer.norm_first was True\n",
      "  warnings.warn(f\"enable_nested_tensor is True, but self.use_nested_tensor is False because {why_not_sparsity_fast_path}\")\n",
      "Hyperparameter combinations:  81%|████████  | 291/360 [18:29:17<13:33:17, 707.21s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Early stopping with best val loss: 0.09154535038396716!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Gabriel\\anaconda3\\envs\\recgensys-env\\lib\\site-packages\\torch\\nn\\modules\\transformer.py:306: UserWarning: enable_nested_tensor is True, but self.use_nested_tensor is False because encoder_layer.norm_first was True\n",
      "  warnings.warn(f\"enable_nested_tensor is True, but self.use_nested_tensor is False because {why_not_sparsity_fast_path}\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running configuration: timesteps=6000, layers=8, heads=16, image_tokens=1, user_tokens=4, learning_rate=0.0001, optimizer=adamw, scheduler=reduce_on_plateau, batch_size=128, noise_schedule=linear, samples_per_user=30, objective=noise-pred, use_ue=False\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Hyperparameter combinations:  81%|████████  | 292/360 [18:36:55<11:56:40, 632.36s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Early stopping with best val loss: 0.101822713855654!\n",
      "Running configuration: timesteps=6000, layers=8, heads=16, image_tokens=1, user_tokens=4, learning_rate=0.0001, optimizer=adamw, scheduler=reduce_on_plateau, batch_size=128, noise_schedule=linear, samples_per_user=50, objective=noise-pred, use_ue=True\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Gabriel\\anaconda3\\envs\\recgensys-env\\lib\\site-packages\\torch\\nn\\modules\\transformer.py:306: UserWarning: enable_nested_tensor is True, but self.use_nested_tensor is False because encoder_layer.norm_first was True\n",
      "  warnings.warn(f\"enable_nested_tensor is True, but self.use_nested_tensor is False because {why_not_sparsity_fast_path}\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Early stopping with best val loss: 0.09039866365492344!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Hyperparameter combinations:  81%|████████▏ | 293/360 [18:45:59<11:16:34, 605.89s/it]c:\\Users\\Gabriel\\anaconda3\\envs\\recgensys-env\\lib\\site-packages\\torch\\nn\\modules\\transformer.py:306: UserWarning: enable_nested_tensor is True, but self.use_nested_tensor is False because encoder_layer.norm_first was True\n",
      "  warnings.warn(f\"enable_nested_tensor is True, but self.use_nested_tensor is False because {why_not_sparsity_fast_path}\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running configuration: timesteps=6000, layers=8, heads=16, image_tokens=1, user_tokens=4, learning_rate=0.0001, optimizer=adamw, scheduler=reduce_on_plateau, batch_size=128, noise_schedule=linear, samples_per_user=50, objective=noise-pred, use_ue=False\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Hyperparameter combinations:  82%|████████▏ | 294/360 [18:55:17<10:50:31, 591.39s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Early stopping with best val loss: 0.08429046371020377!\n",
      "Running configuration: timesteps=6000, layers=8, heads=16, image_tokens=1, user_tokens=4, learning_rate=0.0001, optimizer=adamw, scheduler=reduce_on_plateau, batch_size=128, noise_schedule=linear, samples_per_user=80, objective=noise-pred, use_ue=True\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Gabriel\\anaconda3\\envs\\recgensys-env\\lib\\site-packages\\torch\\nn\\modules\\transformer.py:306: UserWarning: enable_nested_tensor is True, but self.use_nested_tensor is False because encoder_layer.norm_first was True\n",
      "  warnings.warn(f\"enable_nested_tensor is True, but self.use_nested_tensor is False because {why_not_sparsity_fast_path}\")\n",
      "Hyperparameter combinations:  82%|████████▏ | 295/360 [19:10:57<12:34:10, 696.17s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Early stopping with best val loss: 0.0698013782966882!\n",
      "Running configuration: timesteps=6000, layers=8, heads=16, image_tokens=1, user_tokens=4, learning_rate=0.0001, optimizer=adamw, scheduler=reduce_on_plateau, batch_size=128, noise_schedule=linear, samples_per_user=80, objective=noise-pred, use_ue=False\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Gabriel\\anaconda3\\envs\\recgensys-env\\lib\\site-packages\\torch\\nn\\modules\\transformer.py:306: UserWarning: enable_nested_tensor is True, but self.use_nested_tensor is False because encoder_layer.norm_first was True\n",
      "  warnings.warn(f\"enable_nested_tensor is True, but self.use_nested_tensor is False because {why_not_sparsity_fast_path}\")\n",
      "Hyperparameter combinations:  82%|████████▏ | 296/360 [19:20:46<11:48:09, 663.90s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Early stopping with best val loss: 0.06979372468777001!\n",
      "Running configuration: timesteps=6000, layers=8, heads=16, image_tokens=1, user_tokens=4, learning_rate=0.0001, optimizer=adamw, scheduler=reduce_on_plateau, batch_size=128, noise_schedule=linear, samples_per_user=110, objective=noise-pred, use_ue=True\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Gabriel\\anaconda3\\envs\\recgensys-env\\lib\\site-packages\\torch\\nn\\modules\\transformer.py:306: UserWarning: enable_nested_tensor is True, but self.use_nested_tensor is False because encoder_layer.norm_first was True\n",
      "  warnings.warn(f\"enable_nested_tensor is True, but self.use_nested_tensor is False because {why_not_sparsity_fast_path}\")\n",
      "Hyperparameter combinations:  82%|████████▎ | 297/360 [19:34:55<12:35:27, 719.49s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Early stopping with best val loss: 0.0733984331600368!\n",
      "Running configuration: timesteps=6000, layers=8, heads=16, image_tokens=1, user_tokens=4, learning_rate=0.0001, optimizer=adamw, scheduler=reduce_on_plateau, batch_size=128, noise_schedule=linear, samples_per_user=110, objective=noise-pred, use_ue=False\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Gabriel\\anaconda3\\envs\\recgensys-env\\lib\\site-packages\\torch\\nn\\modules\\transformer.py:306: UserWarning: enable_nested_tensor is True, but self.use_nested_tensor is False because encoder_layer.norm_first was True\n",
      "  warnings.warn(f\"enable_nested_tensor is True, but self.use_nested_tensor is False because {why_not_sparsity_fast_path}\")\n",
      "Hyperparameter combinations:  83%|████████▎ | 298/360 [19:48:16<12:48:35, 743.80s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Early stopping with best val loss: 0.07034272467717528!\n",
      "Running configuration: timesteps=6000, layers=8, heads=16, image_tokens=1, user_tokens=4, learning_rate=0.0001, optimizer=adamw, scheduler=reduce_on_plateau, batch_size=128, noise_schedule=linear, samples_per_user=140, objective=noise-pred, use_ue=True\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Gabriel\\anaconda3\\envs\\recgensys-env\\lib\\site-packages\\torch\\nn\\modules\\transformer.py:306: UserWarning: enable_nested_tensor is True, but self.use_nested_tensor is False because encoder_layer.norm_first was True\n",
      "  warnings.warn(f\"enable_nested_tensor is True, but self.use_nested_tensor is False because {why_not_sparsity_fast_path}\")\n",
      "Hyperparameter combinations:  83%|████████▎ | 299/360 [20:06:54<14:30:20, 856.07s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Early stopping with best val loss: 0.06749725108966231!\n",
      "Running configuration: timesteps=6000, layers=8, heads=16, image_tokens=1, user_tokens=4, learning_rate=0.0001, optimizer=adamw, scheduler=reduce_on_plateau, batch_size=128, noise_schedule=linear, samples_per_user=140, objective=noise-pred, use_ue=False\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Gabriel\\anaconda3\\envs\\recgensys-env\\lib\\site-packages\\torch\\nn\\modules\\transformer.py:306: UserWarning: enable_nested_tensor is True, but self.use_nested_tensor is False because encoder_layer.norm_first was True\n",
      "  warnings.warn(f\"enable_nested_tensor is True, but self.use_nested_tensor is False because {why_not_sparsity_fast_path}\")\n",
      "Hyperparameter combinations:  83%|████████▎ | 300/360 [20:19:05<13:38:40, 818.68s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Early stopping with best val loss: 0.06887100101448596!\n",
      "Running configuration: timesteps=6000, layers=8, heads=16, image_tokens=4, user_tokens=1, learning_rate=0.0001, optimizer=adamw, scheduler=reduce_on_plateau, batch_size=128, noise_schedule=linear, samples_per_user=30, objective=noise-pred, use_ue=True\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Gabriel\\anaconda3\\envs\\recgensys-env\\lib\\site-packages\\torch\\nn\\modules\\transformer.py:306: UserWarning: enable_nested_tensor is True, but self.use_nested_tensor is False because encoder_layer.norm_first was True\n",
      "  warnings.warn(f\"enable_nested_tensor is True, but self.use_nested_tensor is False because {why_not_sparsity_fast_path}\")\n",
      "Hyperparameter combinations:  84%|████████▎ | 301/360 [20:21:37<10:08:25, 618.74s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Early stopping with best val loss: 0.12956707831472158!\n",
      "Running configuration: timesteps=6000, layers=8, heads=16, image_tokens=4, user_tokens=1, learning_rate=0.0001, optimizer=adamw, scheduler=reduce_on_plateau, batch_size=128, noise_schedule=linear, samples_per_user=30, objective=noise-pred, use_ue=False\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Gabriel\\anaconda3\\envs\\recgensys-env\\lib\\site-packages\\torch\\nn\\modules\\transformer.py:306: UserWarning: enable_nested_tensor is True, but self.use_nested_tensor is False because encoder_layer.norm_first was True\n",
      "  warnings.warn(f\"enable_nested_tensor is True, but self.use_nested_tensor is False because {why_not_sparsity_fast_path}\")\n",
      "Hyperparameter combinations:  84%|████████▍ | 302/360 [20:24:24<7:46:53, 483.00s/it] "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Early stopping with best val loss: 0.13296759454533458!\n",
      "Running configuration: timesteps=6000, layers=8, heads=16, image_tokens=4, user_tokens=1, learning_rate=0.0001, optimizer=adamw, scheduler=reduce_on_plateau, batch_size=128, noise_schedule=linear, samples_per_user=50, objective=noise-pred, use_ue=True\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Gabriel\\anaconda3\\envs\\recgensys-env\\lib\\site-packages\\torch\\nn\\modules\\transformer.py:306: UserWarning: enable_nested_tensor is True, but self.use_nested_tensor is False because encoder_layer.norm_first was True\n",
      "  warnings.warn(f\"enable_nested_tensor is True, but self.use_nested_tensor is False because {why_not_sparsity_fast_path}\")\n",
      "Hyperparameter combinations:  84%|████████▍ | 303/360 [20:27:50<6:19:58, 399.97s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Early stopping with best val loss: 0.1140987821854651!\n",
      "Running configuration: timesteps=6000, layers=8, heads=16, image_tokens=4, user_tokens=1, learning_rate=0.0001, optimizer=adamw, scheduler=reduce_on_plateau, batch_size=128, noise_schedule=linear, samples_per_user=50, objective=noise-pred, use_ue=False\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Gabriel\\anaconda3\\envs\\recgensys-env\\lib\\site-packages\\torch\\nn\\modules\\transformer.py:306: UserWarning: enable_nested_tensor is True, but self.use_nested_tensor is False because encoder_layer.norm_first was True\n",
      "  warnings.warn(f\"enable_nested_tensor is True, but self.use_nested_tensor is False because {why_not_sparsity_fast_path}\")\n",
      "Hyperparameter combinations:  84%|████████▍ | 304/360 [20:30:42<5:09:39, 331.78s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Early stopping with best val loss: 0.1094103236682713!\n",
      "Running configuration: timesteps=6000, layers=8, heads=16, image_tokens=4, user_tokens=1, learning_rate=0.0001, optimizer=adamw, scheduler=reduce_on_plateau, batch_size=128, noise_schedule=linear, samples_per_user=80, objective=noise-pred, use_ue=True\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Gabriel\\anaconda3\\envs\\recgensys-env\\lib\\site-packages\\torch\\nn\\modules\\transformer.py:306: UserWarning: enable_nested_tensor is True, but self.use_nested_tensor is False because encoder_layer.norm_first was True\n",
      "  warnings.warn(f\"enable_nested_tensor is True, but self.use_nested_tensor is False because {why_not_sparsity_fast_path}\")\n",
      "Hyperparameter combinations:  85%|████████▍ | 305/360 [20:34:39<4:37:55, 303.19s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Early stopping with best val loss: 0.10648352419957519!\n",
      "Running configuration: timesteps=6000, layers=8, heads=16, image_tokens=4, user_tokens=1, learning_rate=0.0001, optimizer=adamw, scheduler=reduce_on_plateau, batch_size=128, noise_schedule=linear, samples_per_user=80, objective=noise-pred, use_ue=False\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Gabriel\\anaconda3\\envs\\recgensys-env\\lib\\site-packages\\torch\\nn\\modules\\transformer.py:306: UserWarning: enable_nested_tensor is True, but self.use_nested_tensor is False because encoder_layer.norm_first was True\n",
      "  warnings.warn(f\"enable_nested_tensor is True, but self.use_nested_tensor is False because {why_not_sparsity_fast_path}\")\n",
      "Hyperparameter combinations:  85%|████████▌ | 306/360 [20:40:21<4:43:30, 315.00s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Early stopping with best val loss: 0.10094176698476076!\n",
      "Running configuration: timesteps=6000, layers=8, heads=16, image_tokens=4, user_tokens=1, learning_rate=0.0001, optimizer=adamw, scheduler=reduce_on_plateau, batch_size=128, noise_schedule=linear, samples_per_user=110, objective=noise-pred, use_ue=True\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Gabriel\\anaconda3\\envs\\recgensys-env\\lib\\site-packages\\torch\\nn\\modules\\transformer.py:306: UserWarning: enable_nested_tensor is True, but self.use_nested_tensor is False because encoder_layer.norm_first was True\n",
      "  warnings.warn(f\"enable_nested_tensor is True, but self.use_nested_tensor is False because {why_not_sparsity_fast_path}\")\n",
      "Hyperparameter combinations:  85%|████████▌ | 307/360 [20:45:32<4:37:11, 313.80s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Early stopping with best val loss: 0.0902256858535111!\n",
      "Running configuration: timesteps=6000, layers=8, heads=16, image_tokens=4, user_tokens=1, learning_rate=0.0001, optimizer=adamw, scheduler=reduce_on_plateau, batch_size=128, noise_schedule=linear, samples_per_user=110, objective=noise-pred, use_ue=False\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Gabriel\\anaconda3\\envs\\recgensys-env\\lib\\site-packages\\torch\\nn\\modules\\transformer.py:306: UserWarning: enable_nested_tensor is True, but self.use_nested_tensor is False because encoder_layer.norm_first was True\n",
      "  warnings.warn(f\"enable_nested_tensor is True, but self.use_nested_tensor is False because {why_not_sparsity_fast_path}\")\n",
      "Hyperparameter combinations:  86%|████████▌ | 308/360 [20:49:47<4:16:27, 295.92s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Early stopping with best val loss: 0.10558962263166904!\n",
      "Running configuration: timesteps=6000, layers=8, heads=16, image_tokens=4, user_tokens=1, learning_rate=0.0001, optimizer=adamw, scheduler=reduce_on_plateau, batch_size=128, noise_schedule=linear, samples_per_user=140, objective=noise-pred, use_ue=True\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Gabriel\\anaconda3\\envs\\recgensys-env\\lib\\site-packages\\torch\\nn\\modules\\transformer.py:306: UserWarning: enable_nested_tensor is True, but self.use_nested_tensor is False because encoder_layer.norm_first was True\n",
      "  warnings.warn(f\"enable_nested_tensor is True, but self.use_nested_tensor is False because {why_not_sparsity_fast_path}\")\n",
      "Hyperparameter combinations:  86%|████████▌ | 309/360 [20:54:26<4:07:17, 290.93s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Early stopping with best val loss: 0.10214409185573459!\n",
      "Running configuration: timesteps=6000, layers=8, heads=16, image_tokens=4, user_tokens=1, learning_rate=0.0001, optimizer=adamw, scheduler=reduce_on_plateau, batch_size=128, noise_schedule=linear, samples_per_user=140, objective=noise-pred, use_ue=False\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Gabriel\\anaconda3\\envs\\recgensys-env\\lib\\site-packages\\torch\\nn\\modules\\transformer.py:306: UserWarning: enable_nested_tensor is True, but self.use_nested_tensor is False because encoder_layer.norm_first was True\n",
      "  warnings.warn(f\"enable_nested_tensor is True, but self.use_nested_tensor is False because {why_not_sparsity_fast_path}\")\n",
      "Hyperparameter combinations:  86%|████████▌ | 310/360 [20:59:06<3:59:37, 287.55s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Early stopping with best val loss: 0.0975338751450181!\n",
      "Running configuration: timesteps=6000, layers=8, heads=16, image_tokens=4, user_tokens=4, learning_rate=0.0001, optimizer=adamw, scheduler=reduce_on_plateau, batch_size=128, noise_schedule=linear, samples_per_user=30, objective=noise-pred, use_ue=True\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Gabriel\\anaconda3\\envs\\recgensys-env\\lib\\site-packages\\torch\\nn\\modules\\transformer.py:306: UserWarning: enable_nested_tensor is True, but self.use_nested_tensor is False because encoder_layer.norm_first was True\n",
      "  warnings.warn(f\"enable_nested_tensor is True, but self.use_nested_tensor is False because {why_not_sparsity_fast_path}\")\n",
      "Hyperparameter combinations:  86%|████████▋ | 311/360 [21:02:07<3:28:51, 255.74s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Early stopping with best val loss: 0.12145401211455464!\n",
      "Running configuration: timesteps=6000, layers=8, heads=16, image_tokens=4, user_tokens=4, learning_rate=0.0001, optimizer=adamw, scheduler=reduce_on_plateau, batch_size=128, noise_schedule=linear, samples_per_user=30, objective=noise-pred, use_ue=False\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Gabriel\\anaconda3\\envs\\recgensys-env\\lib\\site-packages\\torch\\nn\\modules\\transformer.py:306: UserWarning: enable_nested_tensor is True, but self.use_nested_tensor is False because encoder_layer.norm_first was True\n",
      "  warnings.warn(f\"enable_nested_tensor is True, but self.use_nested_tensor is False because {why_not_sparsity_fast_path}\")\n",
      "Hyperparameter combinations:  87%|████████▋ | 312/360 [21:04:07<2:52:03, 215.08s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Early stopping with best val loss: 0.13920217426493764!\n",
      "Running configuration: timesteps=6000, layers=8, heads=16, image_tokens=4, user_tokens=4, learning_rate=0.0001, optimizer=adamw, scheduler=reduce_on_plateau, batch_size=128, noise_schedule=linear, samples_per_user=50, objective=noise-pred, use_ue=True\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Gabriel\\anaconda3\\envs\\recgensys-env\\lib\\site-packages\\torch\\nn\\modules\\transformer.py:306: UserWarning: enable_nested_tensor is True, but self.use_nested_tensor is False because encoder_layer.norm_first was True\n",
      "  warnings.warn(f\"enable_nested_tensor is True, but self.use_nested_tensor is False because {why_not_sparsity_fast_path}\")\n",
      "Hyperparameter combinations:  87%|████████▋ | 313/360 [21:07:36<2:47:01, 213.22s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Early stopping with best val loss: 0.12022958183661103!\n",
      "Running configuration: timesteps=6000, layers=8, heads=16, image_tokens=4, user_tokens=4, learning_rate=0.0001, optimizer=adamw, scheduler=reduce_on_plateau, batch_size=128, noise_schedule=linear, samples_per_user=50, objective=noise-pred, use_ue=False\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Gabriel\\anaconda3\\envs\\recgensys-env\\lib\\site-packages\\torch\\nn\\modules\\transformer.py:306: UserWarning: enable_nested_tensor is True, but self.use_nested_tensor is False because encoder_layer.norm_first was True\n",
      "  warnings.warn(f\"enable_nested_tensor is True, but self.use_nested_tensor is False because {why_not_sparsity_fast_path}\")\n",
      "Hyperparameter combinations:  87%|████████▋ | 314/360 [21:11:22<2:46:21, 216.98s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Early stopping with best val loss: 0.1072403583675623!\n",
      "Running configuration: timesteps=6000, layers=8, heads=16, image_tokens=4, user_tokens=4, learning_rate=0.0001, optimizer=adamw, scheduler=reduce_on_plateau, batch_size=128, noise_schedule=linear, samples_per_user=80, objective=noise-pred, use_ue=True\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Gabriel\\anaconda3\\envs\\recgensys-env\\lib\\site-packages\\torch\\nn\\modules\\transformer.py:306: UserWarning: enable_nested_tensor is True, but self.use_nested_tensor is False because encoder_layer.norm_first was True\n",
      "  warnings.warn(f\"enable_nested_tensor is True, but self.use_nested_tensor is False because {why_not_sparsity_fast_path}\")\n",
      "Hyperparameter combinations:  88%|████████▊ | 315/360 [21:15:25<2:48:38, 224.85s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Early stopping with best val loss: 0.10308876354247332!\n",
      "Running configuration: timesteps=6000, layers=8, heads=16, image_tokens=4, user_tokens=4, learning_rate=0.0001, optimizer=adamw, scheduler=reduce_on_plateau, batch_size=128, noise_schedule=linear, samples_per_user=80, objective=noise-pred, use_ue=False\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Gabriel\\anaconda3\\envs\\recgensys-env\\lib\\site-packages\\torch\\nn\\modules\\transformer.py:306: UserWarning: enable_nested_tensor is True, but self.use_nested_tensor is False because encoder_layer.norm_first was True\n",
      "  warnings.warn(f\"enable_nested_tensor is True, but self.use_nested_tensor is False because {why_not_sparsity_fast_path}\")\n",
      "Hyperparameter combinations:  88%|████████▊ | 316/360 [21:21:17<3:12:42, 262.80s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Early stopping with best val loss: 0.10132801393046975!\n",
      "Running configuration: timesteps=6000, layers=8, heads=16, image_tokens=4, user_tokens=4, learning_rate=0.0001, optimizer=adamw, scheduler=reduce_on_plateau, batch_size=128, noise_schedule=linear, samples_per_user=110, objective=noise-pred, use_ue=True\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Gabriel\\anaconda3\\envs\\recgensys-env\\lib\\site-packages\\torch\\nn\\modules\\transformer.py:306: UserWarning: enable_nested_tensor is True, but self.use_nested_tensor is False because encoder_layer.norm_first was True\n",
      "  warnings.warn(f\"enable_nested_tensor is True, but self.use_nested_tensor is False because {why_not_sparsity_fast_path}\")\n",
      "Hyperparameter combinations:  88%|████████▊ | 317/360 [21:28:54<3:50:06, 321.09s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Early stopping with best val loss: 0.09473290969617665!\n",
      "Running configuration: timesteps=6000, layers=8, heads=16, image_tokens=4, user_tokens=4, learning_rate=0.0001, optimizer=adamw, scheduler=reduce_on_plateau, batch_size=128, noise_schedule=linear, samples_per_user=110, objective=noise-pred, use_ue=False\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Gabriel\\anaconda3\\envs\\recgensys-env\\lib\\site-packages\\torch\\nn\\modules\\transformer.py:306: UserWarning: enable_nested_tensor is True, but self.use_nested_tensor is False because encoder_layer.norm_first was True\n",
      "  warnings.warn(f\"enable_nested_tensor is True, but self.use_nested_tensor is False because {why_not_sparsity_fast_path}\")\n",
      "Hyperparameter combinations:  88%|████████▊ | 318/360 [21:35:56<4:06:02, 351.48s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Early stopping with best val loss: 0.09158434299752116!\n",
      "Running configuration: timesteps=6000, layers=8, heads=16, image_tokens=4, user_tokens=4, learning_rate=0.0001, optimizer=adamw, scheduler=reduce_on_plateau, batch_size=128, noise_schedule=linear, samples_per_user=140, objective=noise-pred, use_ue=True\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Gabriel\\anaconda3\\envs\\recgensys-env\\lib\\site-packages\\torch\\nn\\modules\\transformer.py:306: UserWarning: enable_nested_tensor is True, but self.use_nested_tensor is False because encoder_layer.norm_first was True\n",
      "  warnings.warn(f\"enable_nested_tensor is True, but self.use_nested_tensor is False because {why_not_sparsity_fast_path}\")\n",
      "Hyperparameter combinations:  89%|████████▊ | 319/360 [21:42:46<4:12:15, 369.16s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Early stopping with best val loss: 0.0954937837086618!\n",
      "Running configuration: timesteps=6000, layers=8, heads=16, image_tokens=4, user_tokens=4, learning_rate=0.0001, optimizer=adamw, scheduler=reduce_on_plateau, batch_size=128, noise_schedule=linear, samples_per_user=140, objective=noise-pred, use_ue=False\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Gabriel\\anaconda3\\envs\\recgensys-env\\lib\\site-packages\\torch\\nn\\modules\\transformer.py:306: UserWarning: enable_nested_tensor is True, but self.use_nested_tensor is False because encoder_layer.norm_first was True\n",
      "  warnings.warn(f\"enable_nested_tensor is True, but self.use_nested_tensor is False because {why_not_sparsity_fast_path}\")\n",
      "Hyperparameter combinations:  89%|████████▉ | 320/360 [21:48:17<3:58:28, 357.70s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Early stopping with best val loss: 0.09283564798533916!\n",
      "Running configuration: timesteps=6000, layers=8, heads=32, image_tokens=1, user_tokens=1, learning_rate=0.0001, optimizer=adamw, scheduler=reduce_on_plateau, batch_size=128, noise_schedule=linear, samples_per_user=30, objective=noise-pred, use_ue=True\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Gabriel\\anaconda3\\envs\\recgensys-env\\lib\\site-packages\\torch\\nn\\modules\\transformer.py:306: UserWarning: enable_nested_tensor is True, but self.use_nested_tensor is False because encoder_layer.norm_first was True\n",
      "  warnings.warn(f\"enable_nested_tensor is True, but self.use_nested_tensor is False because {why_not_sparsity_fast_path}\")\n",
      "Hyperparameter combinations:  89%|████████▉ | 321/360 [21:55:27<4:06:27, 379.17s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Early stopping with best val loss: 0.0952140181325376!\n",
      "Running configuration: timesteps=6000, layers=8, heads=32, image_tokens=1, user_tokens=1, learning_rate=0.0001, optimizer=adamw, scheduler=reduce_on_plateau, batch_size=128, noise_schedule=linear, samples_per_user=30, objective=noise-pred, use_ue=False\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Gabriel\\anaconda3\\envs\\recgensys-env\\lib\\site-packages\\torch\\nn\\modules\\transformer.py:306: UserWarning: enable_nested_tensor is True, but self.use_nested_tensor is False because encoder_layer.norm_first was True\n",
      "  warnings.warn(f\"enable_nested_tensor is True, but self.use_nested_tensor is False because {why_not_sparsity_fast_path}\")\n",
      "Hyperparameter combinations:  89%|████████▉ | 322/360 [22:03:46<4:23:01, 415.31s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Early stopping with best val loss: 0.0985169024206698!\n",
      "Running configuration: timesteps=6000, layers=8, heads=32, image_tokens=1, user_tokens=1, learning_rate=0.0001, optimizer=adamw, scheduler=reduce_on_plateau, batch_size=128, noise_schedule=linear, samples_per_user=50, objective=noise-pred, use_ue=True\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Gabriel\\anaconda3\\envs\\recgensys-env\\lib\\site-packages\\torch\\nn\\modules\\transformer.py:306: UserWarning: enable_nested_tensor is True, but self.use_nested_tensor is False because encoder_layer.norm_first was True\n",
      "  warnings.warn(f\"enable_nested_tensor is True, but self.use_nested_tensor is False because {why_not_sparsity_fast_path}\")\n",
      "Hyperparameter combinations:  90%|████████▉ | 323/360 [22:15:13<5:06:24, 496.87s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Early stopping with best val loss: 0.08086562808603048!\n",
      "Running configuration: timesteps=6000, layers=8, heads=32, image_tokens=1, user_tokens=1, learning_rate=0.0001, optimizer=adamw, scheduler=reduce_on_plateau, batch_size=128, noise_schedule=linear, samples_per_user=50, objective=noise-pred, use_ue=False\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Gabriel\\anaconda3\\envs\\recgensys-env\\lib\\site-packages\\torch\\nn\\modules\\transformer.py:306: UserWarning: enable_nested_tensor is True, but self.use_nested_tensor is False because encoder_layer.norm_first was True\n",
      "  warnings.warn(f\"enable_nested_tensor is True, but self.use_nested_tensor is False because {why_not_sparsity_fast_path}\")\n",
      "Hyperparameter combinations:  90%|█████████ | 324/360 [22:26:14<5:27:37, 546.05s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Early stopping with best val loss: 0.07520027155987918!\n",
      "Running configuration: timesteps=6000, layers=8, heads=32, image_tokens=1, user_tokens=1, learning_rate=0.0001, optimizer=adamw, scheduler=reduce_on_plateau, batch_size=128, noise_schedule=linear, samples_per_user=80, objective=noise-pred, use_ue=True\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Gabriel\\anaconda3\\envs\\recgensys-env\\lib\\site-packages\\torch\\nn\\modules\\transformer.py:306: UserWarning: enable_nested_tensor is True, but self.use_nested_tensor is False because encoder_layer.norm_first was True\n",
      "  warnings.warn(f\"enable_nested_tensor is True, but self.use_nested_tensor is False because {why_not_sparsity_fast_path}\")\n",
      "Hyperparameter combinations:  90%|█████████ | 325/360 [22:40:02<6:07:46, 630.48s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Early stopping with best val loss: 0.07210882380604744!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Gabriel\\anaconda3\\envs\\recgensys-env\\lib\\site-packages\\torch\\nn\\modules\\transformer.py:306: UserWarning: enable_nested_tensor is True, but self.use_nested_tensor is False because encoder_layer.norm_first was True\n",
      "  warnings.warn(f\"enable_nested_tensor is True, but self.use_nested_tensor is False because {why_not_sparsity_fast_path}\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running configuration: timesteps=6000, layers=8, heads=32, image_tokens=1, user_tokens=1, learning_rate=0.0001, optimizer=adamw, scheduler=reduce_on_plateau, batch_size=128, noise_schedule=linear, samples_per_user=80, objective=noise-pred, use_ue=False\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Hyperparameter combinations:  91%|█████████ | 326/360 [22:51:50<6:10:34, 653.96s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Early stopping with best val loss: 0.07172591122798622!\n",
      "Running configuration: timesteps=6000, layers=8, heads=32, image_tokens=1, user_tokens=1, learning_rate=0.0001, optimizer=adamw, scheduler=reduce_on_plateau, batch_size=128, noise_schedule=linear, samples_per_user=110, objective=noise-pred, use_ue=True\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Gabriel\\anaconda3\\envs\\recgensys-env\\lib\\site-packages\\torch\\nn\\modules\\transformer.py:306: UserWarning: enable_nested_tensor is True, but self.use_nested_tensor is False because encoder_layer.norm_first was True\n",
      "  warnings.warn(f\"enable_nested_tensor is True, but self.use_nested_tensor is False because {why_not_sparsity_fast_path}\")\n",
      "Hyperparameter combinations:  91%|█████████ | 327/360 [23:07:25<6:45:54, 738.03s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Early stopping with best val loss: 0.07116837450303137!\n",
      "Running configuration: timesteps=6000, layers=8, heads=32, image_tokens=1, user_tokens=1, learning_rate=0.0001, optimizer=adamw, scheduler=reduce_on_plateau, batch_size=128, noise_schedule=linear, samples_per_user=110, objective=noise-pred, use_ue=False\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Gabriel\\anaconda3\\envs\\recgensys-env\\lib\\site-packages\\torch\\nn\\modules\\transformer.py:306: UserWarning: enable_nested_tensor is True, but self.use_nested_tensor is False because encoder_layer.norm_first was True\n",
      "  warnings.warn(f\"enable_nested_tensor is True, but self.use_nested_tensor is False because {why_not_sparsity_fast_path}\")\n",
      "Hyperparameter combinations:  91%|█████████ | 328/360 [23:22:57<7:04:41, 796.31s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Early stopping with best val loss: 0.06820812751539052!\n",
      "Running configuration: timesteps=6000, layers=8, heads=32, image_tokens=1, user_tokens=1, learning_rate=0.0001, optimizer=adamw, scheduler=reduce_on_plateau, batch_size=128, noise_schedule=linear, samples_per_user=140, objective=noise-pred, use_ue=True\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Gabriel\\anaconda3\\envs\\recgensys-env\\lib\\site-packages\\torch\\nn\\modules\\transformer.py:306: UserWarning: enable_nested_tensor is True, but self.use_nested_tensor is False because encoder_layer.norm_first was True\n",
      "  warnings.warn(f\"enable_nested_tensor is True, but self.use_nested_tensor is False because {why_not_sparsity_fast_path}\")\n",
      "Hyperparameter combinations:  91%|█████████▏| 329/360 [23:42:14<7:47:22, 904.61s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Early stopping with best val loss: 0.06139950454235077!\n",
      "Running configuration: timesteps=6000, layers=8, heads=32, image_tokens=1, user_tokens=1, learning_rate=0.0001, optimizer=adamw, scheduler=reduce_on_plateau, batch_size=128, noise_schedule=linear, samples_per_user=140, objective=noise-pred, use_ue=False\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Gabriel\\anaconda3\\envs\\recgensys-env\\lib\\site-packages\\torch\\nn\\modules\\transformer.py:306: UserWarning: enable_nested_tensor is True, but self.use_nested_tensor is False because encoder_layer.norm_first was True\n",
      "  warnings.warn(f\"enable_nested_tensor is True, but self.use_nested_tensor is False because {why_not_sparsity_fast_path}\")\n",
      "Hyperparameter combinations:  92%|█████████▏| 330/360 [23:55:32<7:16:15, 872.50s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Early stopping with best val loss: 0.0628618779592216!\n",
      "Running configuration: timesteps=6000, layers=8, heads=32, image_tokens=1, user_tokens=4, learning_rate=0.0001, optimizer=adamw, scheduler=reduce_on_plateau, batch_size=128, noise_schedule=linear, samples_per_user=30, objective=noise-pred, use_ue=True\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Gabriel\\anaconda3\\envs\\recgensys-env\\lib\\site-packages\\torch\\nn\\modules\\transformer.py:306: UserWarning: enable_nested_tensor is True, but self.use_nested_tensor is False because encoder_layer.norm_first was True\n",
      "  warnings.warn(f\"enable_nested_tensor is True, but self.use_nested_tensor is False because {why_not_sparsity_fast_path}\")\n",
      "Hyperparameter combinations:  92%|█████████▏| 331/360 [24:04:39<6:14:27, 774.75s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Early stopping with best val loss: 0.07764164544641972!\n",
      "Running configuration: timesteps=6000, layers=8, heads=32, image_tokens=1, user_tokens=4, learning_rate=0.0001, optimizer=adamw, scheduler=reduce_on_plateau, batch_size=128, noise_schedule=linear, samples_per_user=30, objective=noise-pred, use_ue=False\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Gabriel\\anaconda3\\envs\\recgensys-env\\lib\\site-packages\\torch\\nn\\modules\\transformer.py:306: UserWarning: enable_nested_tensor is True, but self.use_nested_tensor is False because encoder_layer.norm_first was True\n",
      "  warnings.warn(f\"enable_nested_tensor is True, but self.use_nested_tensor is False because {why_not_sparsity_fast_path}\")\n",
      "Hyperparameter combinations:  92%|█████████▏| 332/360 [24:09:45<4:55:56, 634.16s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Early stopping with best val loss: 0.10299931885674596!\n",
      "Running configuration: timesteps=6000, layers=8, heads=32, image_tokens=1, user_tokens=4, learning_rate=0.0001, optimizer=adamw, scheduler=reduce_on_plateau, batch_size=128, noise_schedule=linear, samples_per_user=50, objective=noise-pred, use_ue=True\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Gabriel\\anaconda3\\envs\\recgensys-env\\lib\\site-packages\\torch\\nn\\modules\\transformer.py:306: UserWarning: enable_nested_tensor is True, but self.use_nested_tensor is False because encoder_layer.norm_first was True\n",
      "  warnings.warn(f\"enable_nested_tensor is True, but self.use_nested_tensor is False because {why_not_sparsity_fast_path}\")\n",
      "Hyperparameter combinations:  92%|█████████▎| 333/360 [24:19:38<4:39:47, 621.78s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Early stopping with best val loss: 0.07301067723892629!\n",
      "Running configuration: timesteps=6000, layers=8, heads=32, image_tokens=1, user_tokens=4, learning_rate=0.0001, optimizer=adamw, scheduler=reduce_on_plateau, batch_size=128, noise_schedule=linear, samples_per_user=50, objective=noise-pred, use_ue=False\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Gabriel\\anaconda3\\envs\\recgensys-env\\lib\\site-packages\\torch\\nn\\modules\\transformer.py:306: UserWarning: enable_nested_tensor is True, but self.use_nested_tensor is False because encoder_layer.norm_first was True\n",
      "  warnings.warn(f\"enable_nested_tensor is True, but self.use_nested_tensor is False because {why_not_sparsity_fast_path}\")\n",
      "Hyperparameter combinations:  93%|█████████▎| 334/360 [24:27:12<4:07:40, 571.55s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Early stopping with best val loss: 0.08502371329814196!\n",
      "Running configuration: timesteps=6000, layers=8, heads=32, image_tokens=1, user_tokens=4, learning_rate=0.0001, optimizer=adamw, scheduler=reduce_on_plateau, batch_size=128, noise_schedule=linear, samples_per_user=80, objective=noise-pred, use_ue=True\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Gabriel\\anaconda3\\envs\\recgensys-env\\lib\\site-packages\\torch\\nn\\modules\\transformer.py:306: UserWarning: enable_nested_tensor is True, but self.use_nested_tensor is False because encoder_layer.norm_first was True\n",
      "  warnings.warn(f\"enable_nested_tensor is True, but self.use_nested_tensor is False because {why_not_sparsity_fast_path}\")\n",
      "Hyperparameter combinations:  93%|█████████▎| 335/360 [24:39:59<4:22:34, 630.17s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Early stopping with best val loss: 0.07859119772911072!\n",
      "Running configuration: timesteps=6000, layers=8, heads=32, image_tokens=1, user_tokens=4, learning_rate=0.0001, optimizer=adamw, scheduler=reduce_on_plateau, batch_size=128, noise_schedule=linear, samples_per_user=80, objective=noise-pred, use_ue=False\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Gabriel\\anaconda3\\envs\\recgensys-env\\lib\\site-packages\\torch\\nn\\modules\\transformer.py:306: UserWarning: enable_nested_tensor is True, but self.use_nested_tensor is False because encoder_layer.norm_first was True\n",
      "  warnings.warn(f\"enable_nested_tensor is True, but self.use_nested_tensor is False because {why_not_sparsity_fast_path}\")\n",
      "Hyperparameter combinations:  93%|█████████▎| 336/360 [24:49:29<4:04:50, 612.09s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Early stopping with best val loss: 0.07303141616284847!\n",
      "Running configuration: timesteps=6000, layers=8, heads=32, image_tokens=1, user_tokens=4, learning_rate=0.0001, optimizer=adamw, scheduler=reduce_on_plateau, batch_size=128, noise_schedule=linear, samples_per_user=110, objective=noise-pred, use_ue=True\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Gabriel\\anaconda3\\envs\\recgensys-env\\lib\\site-packages\\torch\\nn\\modules\\transformer.py:306: UserWarning: enable_nested_tensor is True, but self.use_nested_tensor is False because encoder_layer.norm_first was True\n",
      "  warnings.warn(f\"enable_nested_tensor is True, but self.use_nested_tensor is False because {why_not_sparsity_fast_path}\")\n",
      "Hyperparameter combinations:  94%|█████████▎| 337/360 [25:01:16<4:05:31, 640.50s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Early stopping with best val loss: 0.07267614873126149!\n",
      "Running configuration: timesteps=6000, layers=8, heads=32, image_tokens=1, user_tokens=4, learning_rate=0.0001, optimizer=adamw, scheduler=reduce_on_plateau, batch_size=128, noise_schedule=linear, samples_per_user=110, objective=noise-pred, use_ue=False\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Gabriel\\anaconda3\\envs\\recgensys-env\\lib\\site-packages\\torch\\nn\\modules\\transformer.py:306: UserWarning: enable_nested_tensor is True, but self.use_nested_tensor is False because encoder_layer.norm_first was True\n",
      "  warnings.warn(f\"enable_nested_tensor is True, but self.use_nested_tensor is False because {why_not_sparsity_fast_path}\")\n",
      "Hyperparameter combinations:  94%|█████████▍| 338/360 [25:11:20<3:50:50, 629.57s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Early stopping with best val loss: 0.07317857956513762!\n",
      "Running configuration: timesteps=6000, layers=8, heads=32, image_tokens=1, user_tokens=4, learning_rate=0.0001, optimizer=adamw, scheduler=reduce_on_plateau, batch_size=128, noise_schedule=linear, samples_per_user=140, objective=noise-pred, use_ue=True\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Gabriel\\anaconda3\\envs\\recgensys-env\\lib\\site-packages\\torch\\nn\\modules\\transformer.py:306: UserWarning: enable_nested_tensor is True, but self.use_nested_tensor is False because encoder_layer.norm_first was True\n",
      "  warnings.warn(f\"enable_nested_tensor is True, but self.use_nested_tensor is False because {why_not_sparsity_fast_path}\")\n",
      "Hyperparameter combinations:  94%|█████████▍| 339/360 [25:26:10<4:07:46, 707.92s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Early stopping with best val loss: 0.07011406403034925!\n",
      "Running configuration: timesteps=6000, layers=8, heads=32, image_tokens=1, user_tokens=4, learning_rate=0.0001, optimizer=adamw, scheduler=reduce_on_plateau, batch_size=128, noise_schedule=linear, samples_per_user=140, objective=noise-pred, use_ue=False\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Gabriel\\anaconda3\\envs\\recgensys-env\\lib\\site-packages\\torch\\nn\\modules\\transformer.py:306: UserWarning: enable_nested_tensor is True, but self.use_nested_tensor is False because encoder_layer.norm_first was True\n",
      "  warnings.warn(f\"enable_nested_tensor is True, but self.use_nested_tensor is False because {why_not_sparsity_fast_path}\")\n",
      "Hyperparameter combinations:  94%|█████████▍| 340/360 [25:40:35<4:11:35, 754.79s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Early stopping with best val loss: 0.05938523472286761!\n",
      "Running configuration: timesteps=6000, layers=8, heads=32, image_tokens=4, user_tokens=1, learning_rate=0.0001, optimizer=adamw, scheduler=reduce_on_plateau, batch_size=128, noise_schedule=linear, samples_per_user=30, objective=noise-pred, use_ue=True\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Gabriel\\anaconda3\\envs\\recgensys-env\\lib\\site-packages\\torch\\nn\\modules\\transformer.py:306: UserWarning: enable_nested_tensor is True, but self.use_nested_tensor is False because encoder_layer.norm_first was True\n",
      "  warnings.warn(f\"enable_nested_tensor is True, but self.use_nested_tensor is False because {why_not_sparsity_fast_path}\")\n",
      "Hyperparameter combinations:  95%|█████████▍| 341/360 [25:43:04<3:01:29, 573.15s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Early stopping with best val loss: 0.14943858701735735!\n",
      "Running configuration: timesteps=6000, layers=8, heads=32, image_tokens=4, user_tokens=1, learning_rate=0.0001, optimizer=adamw, scheduler=reduce_on_plateau, batch_size=128, noise_schedule=linear, samples_per_user=30, objective=noise-pred, use_ue=False\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Gabriel\\anaconda3\\envs\\recgensys-env\\lib\\site-packages\\torch\\nn\\modules\\transformer.py:306: UserWarning: enable_nested_tensor is True, but self.use_nested_tensor is False because encoder_layer.norm_first was True\n",
      "  warnings.warn(f\"enable_nested_tensor is True, but self.use_nested_tensor is False because {why_not_sparsity_fast_path}\")\n",
      "Hyperparameter combinations:  95%|█████████▌| 342/360 [25:45:11<2:11:49, 439.43s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Early stopping with best val loss: 0.13370042899623513!\n",
      "Running configuration: timesteps=6000, layers=8, heads=32, image_tokens=4, user_tokens=1, learning_rate=0.0001, optimizer=adamw, scheduler=reduce_on_plateau, batch_size=128, noise_schedule=linear, samples_per_user=50, objective=noise-pred, use_ue=True\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Gabriel\\anaconda3\\envs\\recgensys-env\\lib\\site-packages\\torch\\nn\\modules\\transformer.py:306: UserWarning: enable_nested_tensor is True, but self.use_nested_tensor is False because encoder_layer.norm_first was True\n",
      "  warnings.warn(f\"enable_nested_tensor is True, but self.use_nested_tensor is False because {why_not_sparsity_fast_path}\")\n",
      "Hyperparameter combinations:  95%|█████████▌| 343/360 [25:48:18<1:43:00, 363.53s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Early stopping with best val loss: 0.11244417261332273!\n",
      "Running configuration: timesteps=6000, layers=8, heads=32, image_tokens=4, user_tokens=1, learning_rate=0.0001, optimizer=adamw, scheduler=reduce_on_plateau, batch_size=128, noise_schedule=linear, samples_per_user=50, objective=noise-pred, use_ue=False\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Gabriel\\anaconda3\\envs\\recgensys-env\\lib\\site-packages\\torch\\nn\\modules\\transformer.py:306: UserWarning: enable_nested_tensor is True, but self.use_nested_tensor is False because encoder_layer.norm_first was True\n",
      "  warnings.warn(f\"enable_nested_tensor is True, but self.use_nested_tensor is False because {why_not_sparsity_fast_path}\")\n",
      "Hyperparameter combinations:  96%|█████████▌| 344/360 [25:51:08<1:21:29, 305.59s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Early stopping with best val loss: 0.11928879376500845!\n",
      "Running configuration: timesteps=6000, layers=8, heads=32, image_tokens=4, user_tokens=1, learning_rate=0.0001, optimizer=adamw, scheduler=reduce_on_plateau, batch_size=128, noise_schedule=linear, samples_per_user=80, objective=noise-pred, use_ue=True\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Gabriel\\anaconda3\\envs\\recgensys-env\\lib\\site-packages\\torch\\nn\\modules\\transformer.py:306: UserWarning: enable_nested_tensor is True, but self.use_nested_tensor is False because encoder_layer.norm_first was True\n",
      "  warnings.warn(f\"enable_nested_tensor is True, but self.use_nested_tensor is False because {why_not_sparsity_fast_path}\")\n",
      "Hyperparameter combinations:  96%|█████████▌| 345/360 [25:55:35<1:13:31, 294.10s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Early stopping with best val loss: 0.10402748361229897!\n",
      "Running configuration: timesteps=6000, layers=8, heads=32, image_tokens=4, user_tokens=1, learning_rate=0.0001, optimizer=adamw, scheduler=reduce_on_plateau, batch_size=128, noise_schedule=linear, samples_per_user=80, objective=noise-pred, use_ue=False\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Gabriel\\anaconda3\\envs\\recgensys-env\\lib\\site-packages\\torch\\nn\\modules\\transformer.py:306: UserWarning: enable_nested_tensor is True, but self.use_nested_tensor is False because encoder_layer.norm_first was True\n",
      "  warnings.warn(f\"enable_nested_tensor is True, but self.use_nested_tensor is False because {why_not_sparsity_fast_path}\")\n",
      "Hyperparameter combinations:  96%|█████████▌| 346/360 [25:58:48<1:01:32, 263.78s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Early stopping with best val loss: 0.10135393915697932!\n",
      "Running configuration: timesteps=6000, layers=8, heads=32, image_tokens=4, user_tokens=1, learning_rate=0.0001, optimizer=adamw, scheduler=reduce_on_plateau, batch_size=128, noise_schedule=linear, samples_per_user=110, objective=noise-pred, use_ue=True\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Gabriel\\anaconda3\\envs\\recgensys-env\\lib\\site-packages\\torch\\nn\\modules\\transformer.py:306: UserWarning: enable_nested_tensor is True, but self.use_nested_tensor is False because encoder_layer.norm_first was True\n",
      "  warnings.warn(f\"enable_nested_tensor is True, but self.use_nested_tensor is False because {why_not_sparsity_fast_path}\")\n",
      "Hyperparameter combinations:  96%|█████████▋| 347/360 [26:05:13<1:05:01, 300.11s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Early stopping with best val loss: 0.09272995358332992!\n",
      "Running configuration: timesteps=6000, layers=8, heads=32, image_tokens=4, user_tokens=1, learning_rate=0.0001, optimizer=adamw, scheduler=reduce_on_plateau, batch_size=128, noise_schedule=linear, samples_per_user=110, objective=noise-pred, use_ue=False\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Gabriel\\anaconda3\\envs\\recgensys-env\\lib\\site-packages\\torch\\nn\\modules\\transformer.py:306: UserWarning: enable_nested_tensor is True, but self.use_nested_tensor is False because encoder_layer.norm_first was True\n",
      "  warnings.warn(f\"enable_nested_tensor is True, but self.use_nested_tensor is False because {why_not_sparsity_fast_path}\")\n",
      "Hyperparameter combinations:  97%|█████████▋| 348/360 [26:10:12<59:56, 299.74s/it]  "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Early stopping with best val loss: 0.08960814331658185!\n",
      "Running configuration: timesteps=6000, layers=8, heads=32, image_tokens=4, user_tokens=1, learning_rate=0.0001, optimizer=adamw, scheduler=reduce_on_plateau, batch_size=128, noise_schedule=linear, samples_per_user=140, objective=noise-pred, use_ue=True\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Gabriel\\anaconda3\\envs\\recgensys-env\\lib\\site-packages\\torch\\nn\\modules\\transformer.py:306: UserWarning: enable_nested_tensor is True, but self.use_nested_tensor is False because encoder_layer.norm_first was True\n",
      "  warnings.warn(f\"enable_nested_tensor is True, but self.use_nested_tensor is False because {why_not_sparsity_fast_path}\")\n",
      "Hyperparameter combinations:  97%|█████████▋| 349/360 [26:14:38<53:05, 289.64s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Early stopping with best val loss: 0.0985339698381722!\n",
      "Running configuration: timesteps=6000, layers=8, heads=32, image_tokens=4, user_tokens=1, learning_rate=0.0001, optimizer=adamw, scheduler=reduce_on_plateau, batch_size=128, noise_schedule=linear, samples_per_user=140, objective=noise-pred, use_ue=False\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Gabriel\\anaconda3\\envs\\recgensys-env\\lib\\site-packages\\torch\\nn\\modules\\transformer.py:306: UserWarning: enable_nested_tensor is True, but self.use_nested_tensor is False because encoder_layer.norm_first was True\n",
      "  warnings.warn(f\"enable_nested_tensor is True, but self.use_nested_tensor is False because {why_not_sparsity_fast_path}\")\n",
      "Hyperparameter combinations:  97%|█████████▋| 350/360 [26:21:10<53:24, 320.42s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Early stopping with best val loss: 0.0945756291039288!\n",
      "Running configuration: timesteps=6000, layers=8, heads=32, image_tokens=4, user_tokens=4, learning_rate=0.0001, optimizer=adamw, scheduler=reduce_on_plateau, batch_size=128, noise_schedule=linear, samples_per_user=30, objective=noise-pred, use_ue=True\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Gabriel\\anaconda3\\envs\\recgensys-env\\lib\\site-packages\\torch\\nn\\modules\\transformer.py:306: UserWarning: enable_nested_tensor is True, but self.use_nested_tensor is False because encoder_layer.norm_first was True\n",
      "  warnings.warn(f\"enable_nested_tensor is True, but self.use_nested_tensor is False because {why_not_sparsity_fast_path}\")\n",
      "Hyperparameter combinations:  98%|█████████▊| 351/360 [26:23:22<39:34, 263.87s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Early stopping with best val loss: 0.13735701004043221!\n",
      "Running configuration: timesteps=6000, layers=8, heads=32, image_tokens=4, user_tokens=4, learning_rate=0.0001, optimizer=adamw, scheduler=reduce_on_plateau, batch_size=128, noise_schedule=linear, samples_per_user=30, objective=noise-pred, use_ue=False\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Gabriel\\anaconda3\\envs\\recgensys-env\\lib\\site-packages\\torch\\nn\\modules\\transformer.py:306: UserWarning: enable_nested_tensor is True, but self.use_nested_tensor is False because encoder_layer.norm_first was True\n",
      "  warnings.warn(f\"enable_nested_tensor is True, but self.use_nested_tensor is False because {why_not_sparsity_fast_path}\")\n",
      "Hyperparameter combinations:  98%|█████████▊| 352/360 [26:25:42<30:13, 226.73s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Early stopping with best val loss: 0.12165156938135624!\n",
      "Running configuration: timesteps=6000, layers=8, heads=32, image_tokens=4, user_tokens=4, learning_rate=0.0001, optimizer=adamw, scheduler=reduce_on_plateau, batch_size=128, noise_schedule=linear, samples_per_user=50, objective=noise-pred, use_ue=True\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Gabriel\\anaconda3\\envs\\recgensys-env\\lib\\site-packages\\torch\\nn\\modules\\transformer.py:306: UserWarning: enable_nested_tensor is True, but self.use_nested_tensor is False because encoder_layer.norm_first was True\n",
      "  warnings.warn(f\"enable_nested_tensor is True, but self.use_nested_tensor is False because {why_not_sparsity_fast_path}\")\n",
      "Hyperparameter combinations:  98%|█████████▊| 353/360 [26:28:39<24:42, 211.80s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Early stopping with best val loss: 0.11228023516014218!\n",
      "Running configuration: timesteps=6000, layers=8, heads=32, image_tokens=4, user_tokens=4, learning_rate=0.0001, optimizer=adamw, scheduler=reduce_on_plateau, batch_size=128, noise_schedule=linear, samples_per_user=50, objective=noise-pred, use_ue=False\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Gabriel\\anaconda3\\envs\\recgensys-env\\lib\\site-packages\\torch\\nn\\modules\\transformer.py:306: UserWarning: enable_nested_tensor is True, but self.use_nested_tensor is False because encoder_layer.norm_first was True\n",
      "  warnings.warn(f\"enable_nested_tensor is True, but self.use_nested_tensor is False because {why_not_sparsity_fast_path}\")\n",
      "Hyperparameter combinations:  98%|█████████▊| 354/360 [26:31:28<19:53, 198.85s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Early stopping with best val loss: 0.11479498725384474!\n",
      "Running configuration: timesteps=6000, layers=8, heads=32, image_tokens=4, user_tokens=4, learning_rate=0.0001, optimizer=adamw, scheduler=reduce_on_plateau, batch_size=128, noise_schedule=linear, samples_per_user=80, objective=noise-pred, use_ue=True\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Gabriel\\anaconda3\\envs\\recgensys-env\\lib\\site-packages\\torch\\nn\\modules\\transformer.py:306: UserWarning: enable_nested_tensor is True, but self.use_nested_tensor is False because encoder_layer.norm_first was True\n",
      "  warnings.warn(f\"enable_nested_tensor is True, but self.use_nested_tensor is False because {why_not_sparsity_fast_path}\")\n",
      "Hyperparameter combinations:  99%|█████████▊| 355/360 [26:36:43<19:28, 233.71s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Early stopping with best val loss: 0.09583884524181485!\n",
      "Running configuration: timesteps=6000, layers=8, heads=32, image_tokens=4, user_tokens=4, learning_rate=0.0001, optimizer=adamw, scheduler=reduce_on_plateau, batch_size=128, noise_schedule=linear, samples_per_user=80, objective=noise-pred, use_ue=False\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Gabriel\\anaconda3\\envs\\recgensys-env\\lib\\site-packages\\torch\\nn\\modules\\transformer.py:306: UserWarning: enable_nested_tensor is True, but self.use_nested_tensor is False because encoder_layer.norm_first was True\n",
      "  warnings.warn(f\"enable_nested_tensor is True, but self.use_nested_tensor is False because {why_not_sparsity_fast_path}\")\n",
      "Hyperparameter combinations:  99%|█████████▉| 356/360 [26:41:40<16:50, 252.75s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Early stopping with best val loss: 0.09847093117423356!\n",
      "Running configuration: timesteps=6000, layers=8, heads=32, image_tokens=4, user_tokens=4, learning_rate=0.0001, optimizer=adamw, scheduler=reduce_on_plateau, batch_size=128, noise_schedule=linear, samples_per_user=110, objective=noise-pred, use_ue=True\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Gabriel\\anaconda3\\envs\\recgensys-env\\lib\\site-packages\\torch\\nn\\modules\\transformer.py:306: UserWarning: enable_nested_tensor is True, but self.use_nested_tensor is False because encoder_layer.norm_first was True\n",
      "  warnings.warn(f\"enable_nested_tensor is True, but self.use_nested_tensor is False because {why_not_sparsity_fast_path}\")\n",
      "Hyperparameter combinations:  99%|█████████▉| 357/360 [26:46:36<13:16, 265.56s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Early stopping with best val loss: 0.10199351469054818!\n",
      "Running configuration: timesteps=6000, layers=8, heads=32, image_tokens=4, user_tokens=4, learning_rate=0.0001, optimizer=adamw, scheduler=reduce_on_plateau, batch_size=128, noise_schedule=linear, samples_per_user=110, objective=noise-pred, use_ue=False\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Gabriel\\anaconda3\\envs\\recgensys-env\\lib\\site-packages\\torch\\nn\\modules\\transformer.py:306: UserWarning: enable_nested_tensor is True, but self.use_nested_tensor is False because encoder_layer.norm_first was True\n",
      "  warnings.warn(f\"enable_nested_tensor is True, but self.use_nested_tensor is False because {why_not_sparsity_fast_path}\")\n",
      "Hyperparameter combinations:  99%|█████████▉| 358/360 [26:50:21<08:27, 253.53s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Early stopping with best val loss: 0.10329900775104761!\n",
      "Running configuration: timesteps=6000, layers=8, heads=32, image_tokens=4, user_tokens=4, learning_rate=0.0001, optimizer=adamw, scheduler=reduce_on_plateau, batch_size=128, noise_schedule=linear, samples_per_user=140, objective=noise-pred, use_ue=True\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Gabriel\\anaconda3\\envs\\recgensys-env\\lib\\site-packages\\torch\\nn\\modules\\transformer.py:306: UserWarning: enable_nested_tensor is True, but self.use_nested_tensor is False because encoder_layer.norm_first was True\n",
      "  warnings.warn(f\"enable_nested_tensor is True, but self.use_nested_tensor is False because {why_not_sparsity_fast_path}\")\n",
      "Hyperparameter combinations: 100%|█████████▉| 359/360 [26:55:36<04:31, 271.84s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Early stopping with best val loss: 0.09518501651473343!\n",
      "Running configuration: timesteps=6000, layers=8, heads=32, image_tokens=4, user_tokens=4, learning_rate=0.0001, optimizer=adamw, scheduler=reduce_on_plateau, batch_size=128, noise_schedule=linear, samples_per_user=140, objective=noise-pred, use_ue=False\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Gabriel\\anaconda3\\envs\\recgensys-env\\lib\\site-packages\\torch\\nn\\modules\\transformer.py:306: UserWarning: enable_nested_tensor is True, but self.use_nested_tensor is False because encoder_layer.norm_first was True\n",
      "  warnings.warn(f\"enable_nested_tensor is True, but self.use_nested_tensor is False because {why_not_sparsity_fast_path}\")\n",
      "Hyperparameter combinations: 100%|██████████| 360/360 [27:04:40<00:00, 270.78s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Early stopping with best val loss: 0.09450408862903714!\n",
      "Experimentation complete. Results saved to results.csv at ../weights/sdxl_experiments\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "run_experiments(\n",
    "    train_df=train_df,\n",
    "    train_dataset=train_dataset,\n",
    "    val_dataset=val_dataset,\n",
    "    param_grid=param_grid,\n",
    "    savedir=savedir\n",
    "                )"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "rebeca-env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
