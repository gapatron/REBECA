{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Train Custom Diffusion Priors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "\n",
    "import sys\n",
    "sys.path.append('../')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from diffusers import DDPMScheduler\n",
    "import pandas as pd\n",
    "import torch\n",
    "from torch.utils.data import DataLoader\n",
    "\n",
    "from Datasets import RecommenderUserSampler, EmbeddingsDataset\n",
    "from grid_search import run_grid_search\n",
    "from prior_models import TransformerEmbeddingDiffusionModelv2\n",
    "from train_priors import train_diffusion_prior\n",
    "from utils import map_embeddings_to_ratings, split_recommender_data, set_seeds"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load Data\n",
    "\n",
    "Load the data in its corresponding (sub)directory and map image embeddings to observations.\n",
    "The data in ratings.csv will constitute our observations, and for our purposes, it will \n",
    "consist of the triplets $(U_i, S_j, I_k)$, where $U_i$ corresponds user $i$, $S_j$ encodes wheter user likes $(\\text{ score}\\geq 4)$ or dislikes the image $(\\text{ score}< 4)$ and $I_k$ is the $k$-th image."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "image_features = torch.load(\"../data/flickr/processed/ip-adapters/SD15/sd15_image_embeddings.pt\", weights_only=True)\n",
    "ratings_df = pd.read_csv(\"../data/flickr/processed/ratings.csv\")\n",
    "expanded_features = map_embeddings_to_ratings(image_features, ratings_df)\n",
    "device = \"cuda\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "User loss: 116\n",
      "Data loss: 7.281789573930686%\n"
     ]
    }
   ],
   "source": [
    "usr_threshold = 100\n",
    "\n",
    "liked_counts = (\n",
    "    ratings_df[ratings_df[\"score\"] >= 4]\n",
    "    .groupby(\"worker_id\")[\"score\"]\n",
    "    .count()\n",
    "    .reset_index(name=\"liked_count\")\n",
    ")\n",
    "valid_users = liked_counts[liked_counts[\"liked_count\"] >= usr_threshold][\"worker_id\"].unique()\n",
    "valid_worker_id = liked_counts[liked_counts[\"liked_count\"] >= usr_threshold][\"worker_id\"].unique()\n",
    "filtered_ratings_df = ratings_df[ratings_df[\"worker_id\"].isin(valid_users)].copy()\n",
    "print(f\"User loss: {210-len(valid_users)}\")\n",
    "print(f\"Data loss: {100*(1 - filtered_ratings_df.shape[0]/ratings_df.shape[0])}%\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "worker_mapping = {old_id: new_id for new_id, old_id in enumerate(valid_worker_id)}\n",
    "filtered_ratings_df.rename(columns={\"worker_id\": \"old_worker_id\"}, inplace=True)\n",
    "filtered_ratings_df[\"worker_id\"] = filtered_ratings_df[\"old_worker_id\"].map(worker_mapping)\n",
    "#filtered_ratings_df = filtered_ratings_df.reset_index(drop=True)\n",
    "worker_mapping_df = pd.DataFrame(list(worker_mapping.items()), columns=[\"old_worker_id\", \"worker_id\"])\n",
    "worker_mapping_df.to_csv(\"../data/flickr/processed/worker_id_mapping_usrthr_100.csv\", index=False)\n",
    "filtered_ratings_df.to_csv(\"../data/flickr/processed/filtered_ratings_df_usrthrs_100.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train set size: 177278\n",
      "Validation set size: 928\n",
      "Evaluation set size: 933\n"
     ]
    }
   ],
   "source": [
    "train_df, val_df, test_df = split_recommender_data(\n",
    "    ratings_df=filtered_ratings_df,\n",
    "    val_spu=10,\n",
    "    test_spu=10,\n",
    "    seed=42\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "worker_id\n",
       "40      201\n",
       "52      208\n",
       "36      208\n",
       "72      210\n",
       "67      258\n",
       "      ...  \n",
       "49     8064\n",
       "20    11064\n",
       "22    11343\n",
       "87    17320\n",
       "28    17875\n",
       "Name: count, Length: 94, dtype: int64"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_df['worker_id'].value_counts(ascending=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df.to_csv(\"../data/flickr/processed/train_usrthrs_100.csv\", index=False)\n",
    "val_df.to_csv(\"../data/flickr/processed/validation_usrthrs_100.csv\", index=False)\n",
    "test_df.to_csv(\"../data/flickr/processed/test_usrthrs_100.csv\", index=False)\n",
    "\n",
    "\n",
    "\n",
    "torch.save(expanded_features[train_df.original_index], \"../data/flickr/processed/train/train_ie_usrthrs_100.pth\")\n",
    "torch.save(expanded_features[val_df.original_index], \"../data/flickr/processed/train/validation_ie_usrthrs_100.pth\")\n",
    "torch.save(expanded_features[test_df.original_index], \"../data/flickr/processed/test/test_ie_usrthrs_100.pth\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([177278, 1024])"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "expanded_features[train_df.original_index].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataset = EmbeddingsDataset(\n",
    "    train_df,\n",
    "    image_embeddings=expanded_features[train_df.original_index]\n",
    ")\n",
    "\n",
    "val_dataset = EmbeddingsDataset(\n",
    "    val_df,\n",
    "    image_embeddings=expanded_features[val_df.original_index]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Gabriel\\anaconda3\\envs\\recgensys-env\\lib\\site-packages\\torch\\nn\\modules\\transformer.py:306: UserWarning: enable_nested_tensor is True, but self.use_nested_tensor is False because encoder_layer.norm_first was True\n",
      "  warnings.warn(f\"enable_nested_tensor is True, but self.use_nested_tensor is False because {why_not_sparsity_fast_path}\")\n"
     ]
    }
   ],
   "source": [
    "diffusion_prior_model = TransformerEmbeddingDiffusionModelv2(\n",
    "    img_embed_dim=1024,\n",
    "    num_users=94,    # So user embedding covers your entire user set\n",
    "    n_heads=16,\n",
    "    num_tokens=1,\n",
    "    num_user_tokens=4,\n",
    "    num_layers=8,\n",
    "    dim_feedforward=2048,\n",
    "    whether_use_user_embeddings=True\n",
    ").to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total parameters: 68641792\n",
      "Trainable parameters: 68641792\n"
     ]
    }
   ],
   "source": [
    "set_seeds(0)\n",
    "batch_size = 64\n",
    "samples_per_user = 200\n",
    "learning_rate = 1e-4\n",
    "unique_users = filtered_ratings_df[\"worker_id\"].unique()\n",
    "train_user_sampler = RecommenderUserSampler(train_df, num_users=len(unique_users), samples_per_user=samples_per_user)\n",
    "\n",
    "train_dataloader = DataLoader(train_dataset, sampler=train_user_sampler, batch_size=batch_size)\n",
    "test_dataloader = DataLoader(val_dataset, batch_size=batch_size, shuffle=True)\n",
    "\n",
    "diffusion_optimizer = torch.optim.AdamW(diffusion_prior_model.parameters(), lr=learning_rate, weight_decay=1e-5)\n",
    "noise_scheduler = DDPMScheduler(num_train_timesteps=6000)\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "scheduler = torch.optim.lr_scheduler.ReduceLROnPlateau(diffusion_optimizer, 'min', patience=5, factor=0.5)\n",
    "\n",
    "total_params = sum(p.numel() for p in diffusion_prior_model.parameters())\n",
    "trainable_params = sum(p.numel() for p in diffusion_prior_model.parameters() if p.requires_grad)\n",
    "print(f\"Total parameters: {total_params}\")\n",
    "print(f\"Trainable parameters: {trainable_params}\")\n",
    "\n",
    "\n",
    "savepath = f\"../data/flickr/evaluation/diffusion_priors/sd15_ied1024_nu94_nh16_nit1_nut4_nl8_dff2048.pth\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/2001, Time Elapsed: 7.30s, Train Loss: 1.3213, Val Loss: 0.9947, Grad Norm: 4.3423\n",
      "Epoch 2/2001, Time Elapsed: 13.89s, Train Loss: 0.8492, Val Loss: 0.6798, Grad Norm: 2.5805\n",
      "Epoch 3/2001, Time Elapsed: 20.82s, Train Loss: 0.6410, Val Loss: 0.5304, Grad Norm: 2.2285\n",
      "Epoch 4/2001, Time Elapsed: 27.84s, Train Loss: 0.5227, Val Loss: 0.4157, Grad Norm: 2.0213\n",
      "Epoch 5/2001, Time Elapsed: 34.87s, Train Loss: 0.4362, Val Loss: 0.3372, Grad Norm: 1.8596\n",
      "Epoch 6/2001, Time Elapsed: 41.93s, Train Loss: 0.3761, Val Loss: 0.2845, Grad Norm: 1.7472\n",
      "Epoch 7/2001, Time Elapsed: 48.97s, Train Loss: 0.3249, Val Loss: 0.2391, Grad Norm: 1.6489\n",
      "Epoch 8/2001, Time Elapsed: 56.03s, Train Loss: 0.2869, Val Loss: 0.2036, Grad Norm: 1.5609\n",
      "Epoch 9/2001, Time Elapsed: 62.99s, Train Loss: 0.2580, Val Loss: 0.1760, Grad Norm: 1.4794\n",
      "Epoch 10/2001, Time Elapsed: 70.01s, Train Loss: 0.2323, Val Loss: 0.1686, Grad Norm: 1.4104\n",
      "Epoch 11/2001, Time Elapsed: 77.03s, Train Loss: 0.2112, Val Loss: 0.1604, Grad Norm: 1.3445\n",
      "Epoch 12/2001, Time Elapsed: 83.97s, Train Loss: 0.1965, Val Loss: 0.1366, Grad Norm: 1.2928\n",
      "Epoch 13/2001, Time Elapsed: 90.98s, Train Loss: 0.1800, Val Loss: 0.1248, Grad Norm: 1.2346\n",
      "Epoch 14/2001, Time Elapsed: 97.97s, Train Loss: 0.1711, Val Loss: 0.1223, Grad Norm: 1.1929\n",
      "Epoch 15/2001, Time Elapsed: 105.02s, Train Loss: 0.1616, Val Loss: 0.1047, Grad Norm: 1.1490\n",
      "Epoch 16/2001, Time Elapsed: 111.58s, Train Loss: 0.1552, Val Loss: 0.1142, Grad Norm: 1.1080\n",
      "Epoch 17/2001, Time Elapsed: 117.96s, Train Loss: 0.1459, Val Loss: 0.0962, Grad Norm: 1.0681\n",
      "Epoch 18/2001, Time Elapsed: 124.52s, Train Loss: 0.1404, Val Loss: 0.1002, Grad Norm: 1.0322\n",
      "Epoch 19/2001, Time Elapsed: 130.91s, Train Loss: 0.1367, Val Loss: 0.0954, Grad Norm: 1.0067\n",
      "Epoch 20/2001, Time Elapsed: 137.62s, Train Loss: 0.1319, Val Loss: 0.0867, Grad Norm: 0.9770\n",
      "Epoch 21/2001, Time Elapsed: 144.59s, Train Loss: 0.1258, Val Loss: 0.0924, Grad Norm: 0.9453\n",
      "Epoch 22/2001, Time Elapsed: 151.47s, Train Loss: 0.1219, Val Loss: 0.0938, Grad Norm: 0.9235\n",
      "Epoch 23/2001, Time Elapsed: 158.38s, Train Loss: 0.1223, Val Loss: 0.0837, Grad Norm: 0.9079\n",
      "Epoch 24/2001, Time Elapsed: 165.44s, Train Loss: 0.1187, Val Loss: 0.0853, Grad Norm: 0.8911\n",
      "Epoch 25/2001, Time Elapsed: 172.28s, Train Loss: 0.1160, Val Loss: 0.0809, Grad Norm: 0.8707\n",
      "Epoch 26/2001, Time Elapsed: 179.34s, Train Loss: 0.1127, Val Loss: 0.0828, Grad Norm: 0.8531\n",
      "Epoch 27/2001, Time Elapsed: 186.20s, Train Loss: 0.1093, Val Loss: 0.0829, Grad Norm: 0.8323\n",
      "Epoch 28/2001, Time Elapsed: 193.08s, Train Loss: 0.1101, Val Loss: 0.0698, Grad Norm: 0.8290\n",
      "Epoch 29/2001, Time Elapsed: 199.88s, Train Loss: 0.1078, Val Loss: 0.0798, Grad Norm: 0.8138\n",
      "Epoch 30/2001, Time Elapsed: 206.46s, Train Loss: 0.1035, Val Loss: 0.0820, Grad Norm: 0.7931\n",
      "Epoch 31/2001, Time Elapsed: 213.09s, Train Loss: 0.1027, Val Loss: 0.0821, Grad Norm: 0.7855\n",
      "Epoch 32/2001, Time Elapsed: 219.68s, Train Loss: 0.1028, Val Loss: 0.0726, Grad Norm: 0.7800\n",
      "Epoch 33/2001, Time Elapsed: 226.27s, Train Loss: 0.1011, Val Loss: 0.0689, Grad Norm: 0.7687\n",
      "Epoch 34/2001, Time Elapsed: 232.86s, Train Loss: 0.0992, Val Loss: 0.0735, Grad Norm: 0.7566\n",
      "Epoch 35/2001, Time Elapsed: 239.26s, Train Loss: 0.0958, Val Loss: 0.0741, Grad Norm: 0.7444\n",
      "Epoch 36/2001, Time Elapsed: 245.63s, Train Loss: 0.0956, Val Loss: 0.0750, Grad Norm: 0.7378\n",
      "Epoch 37/2001, Time Elapsed: 252.03s, Train Loss: 0.0930, Val Loss: 0.0807, Grad Norm: 0.7281\n",
      "Epoch 38/2001, Time Elapsed: 258.54s, Train Loss: 0.0958, Val Loss: 0.0732, Grad Norm: 0.7326\n",
      "Epoch 39/2001, Time Elapsed: 265.25s, Train Loss: 0.0890, Val Loss: 0.0679, Grad Norm: 0.7062\n",
      "Epoch 40/2001, Time Elapsed: 272.17s, Train Loss: 0.0909, Val Loss: 0.0737, Grad Norm: 0.7112\n",
      "Epoch 41/2001, Time Elapsed: 278.86s, Train Loss: 0.0886, Val Loss: 0.0664, Grad Norm: 0.7010\n",
      "Epoch 42/2001, Time Elapsed: 285.78s, Train Loss: 0.0881, Val Loss: 0.0740, Grad Norm: 0.6998\n",
      "Epoch 43/2001, Time Elapsed: 292.52s, Train Loss: 0.0891, Val Loss: 0.0636, Grad Norm: 0.7008\n",
      "Epoch 44/2001, Time Elapsed: 299.37s, Train Loss: 0.0871, Val Loss: 0.0651, Grad Norm: 0.6894\n",
      "Epoch 45/2001, Time Elapsed: 306.06s, Train Loss: 0.0875, Val Loss: 0.0683, Grad Norm: 0.6916\n",
      "Epoch 46/2001, Time Elapsed: 312.89s, Train Loss: 0.0845, Val Loss: 0.0630, Grad Norm: 0.6810\n",
      "Epoch 47/2001, Time Elapsed: 319.84s, Train Loss: 0.0840, Val Loss: 0.0664, Grad Norm: 0.6798\n",
      "Epoch 48/2001, Time Elapsed: 326.66s, Train Loss: 0.0830, Val Loss: 0.0762, Grad Norm: 0.6747\n",
      "Epoch 49/2001, Time Elapsed: 333.43s, Train Loss: 0.0817, Val Loss: 0.0694, Grad Norm: 0.6701\n",
      "Epoch 50/2001, Time Elapsed: 340.21s, Train Loss: 0.0836, Val Loss: 0.0660, Grad Norm: 0.6814\n",
      "Epoch 51/2001, Time Elapsed: 346.89s, Train Loss: 0.0806, Val Loss: 0.0704, Grad Norm: 0.6651\n",
      "Epoch 52/2001, Time Elapsed: 353.74s, Train Loss: 0.0791, Val Loss: 0.0610, Grad Norm: 0.6625\n",
      "Epoch 53/2001, Time Elapsed: 360.78s, Train Loss: 0.0792, Val Loss: 0.0699, Grad Norm: 0.6642\n",
      "Epoch 54/2001, Time Elapsed: 367.66s, Train Loss: 0.0785, Val Loss: 0.0535, Grad Norm: 0.6614\n",
      "Epoch 55/2001, Time Elapsed: 374.68s, Train Loss: 0.0777, Val Loss: 0.0648, Grad Norm: 0.6644\n",
      "Epoch 56/2001, Time Elapsed: 381.57s, Train Loss: 0.0796, Val Loss: 0.0602, Grad Norm: 0.6689\n",
      "Epoch 57/2001, Time Elapsed: 388.41s, Train Loss: 0.0747, Val Loss: 0.0660, Grad Norm: 0.6499\n",
      "Epoch 58/2001, Time Elapsed: 395.34s, Train Loss: 0.0753, Val Loss: 0.0583, Grad Norm: 0.6560\n",
      "Epoch 59/2001, Time Elapsed: 402.17s, Train Loss: 0.0774, Val Loss: 0.0664, Grad Norm: 0.6627\n",
      "Epoch 60/2001, Time Elapsed: 408.96s, Train Loss: 0.0743, Val Loss: 0.0539, Grad Norm: 0.6515\n",
      "Epoch 61/2001, Time Elapsed: 415.76s, Train Loss: 0.0725, Val Loss: 0.0626, Grad Norm: 0.6034\n",
      "Epoch 62/2001, Time Elapsed: 422.59s, Train Loss: 0.0708, Val Loss: 0.0508, Grad Norm: 0.6015\n",
      "Epoch 63/2001, Time Elapsed: 429.57s, Train Loss: 0.0700, Val Loss: 0.0620, Grad Norm: 0.6001\n",
      "Epoch 64/2001, Time Elapsed: 436.34s, Train Loss: 0.0700, Val Loss: 0.0684, Grad Norm: 0.6058\n",
      "Epoch 65/2001, Time Elapsed: 443.19s, Train Loss: 0.0702, Val Loss: 0.0528, Grad Norm: 0.6092\n",
      "Epoch 66/2001, Time Elapsed: 450.04s, Train Loss: 0.0703, Val Loss: 0.0570, Grad Norm: 0.6094\n",
      "Epoch 67/2001, Time Elapsed: 456.87s, Train Loss: 0.0690, Val Loss: 0.0589, Grad Norm: 0.6063\n",
      "Epoch 68/2001, Time Elapsed: 463.58s, Train Loss: 0.0680, Val Loss: 0.0597, Grad Norm: 0.6016\n",
      "Epoch 69/2001, Time Elapsed: 470.39s, Train Loss: 0.0670, Val Loss: 0.0541, Grad Norm: 0.5783\n",
      "Epoch 70/2001, Time Elapsed: 477.26s, Train Loss: 0.0701, Val Loss: 0.0584, Grad Norm: 0.5899\n",
      "Epoch 71/2001, Time Elapsed: 484.20s, Train Loss: 0.0660, Val Loss: 0.0625, Grad Norm: 0.5746\n",
      "Epoch 72/2001, Time Elapsed: 491.06s, Train Loss: 0.0676, Val Loss: 0.0511, Grad Norm: 0.5823\n",
      "Epoch 73/2001, Time Elapsed: 497.92s, Train Loss: 0.0686, Val Loss: 0.0520, Grad Norm: 0.5864\n",
      "Epoch 74/2001, Time Elapsed: 504.84s, Train Loss: 0.0670, Val Loss: 0.0525, Grad Norm: 0.5816\n",
      "Epoch 75/2001, Time Elapsed: 511.73s, Train Loss: 0.0652, Val Loss: 0.0553, Grad Norm: 0.5601\n",
      "Epoch 76/2001, Time Elapsed: 518.73s, Train Loss: 0.0644, Val Loss: 0.0553, Grad Norm: 0.5559\n",
      "Epoch 77/2001, Time Elapsed: 525.62s, Train Loss: 0.0655, Val Loss: 0.0572, Grad Norm: 0.5651\n",
      "Epoch 78/2001, Time Elapsed: 532.33s, Train Loss: 0.0646, Val Loss: 0.0548, Grad Norm: 0.5597\n",
      "Epoch 79/2001, Time Elapsed: 539.13s, Train Loss: 0.0641, Val Loss: 0.0596, Grad Norm: 0.5589\n",
      "Epoch 80/2001, Time Elapsed: 545.98s, Train Loss: 0.0654, Val Loss: 0.0516, Grad Norm: 0.5661\n",
      "Epoch 81/2001, Time Elapsed: 552.84s, Train Loss: 0.0642, Val Loss: 0.0589, Grad Norm: 0.5520\n",
      "Epoch 82/2001, Time Elapsed: 559.47s, Train Loss: 0.0617, Val Loss: 0.0650, Grad Norm: 0.5406\n",
      "Early stopping with best val loss: 0.05075061023235321!\n"
     ]
    }
   ],
   "source": [
    "train_loss, val_loss = train_diffusion_prior(\n",
    "                model=diffusion_prior_model,\n",
    "                noise_scheduler=noise_scheduler,\n",
    "                train_dataloader=train_dataloader,\n",
    "                val_dataloader=test_dataloader,\n",
    "                optimizer=diffusion_optimizer,\n",
    "                scheduler=scheduler,\n",
    "                num_unique_users=len(unique_users),\n",
    "                objective=\"noise-pred\",\n",
    "                device=device,\n",
    "                num_epochs=2001,      # Ensure config.num_epochs is defined\n",
    "                patience=20,\n",
    "                savepath=savepath,\n",
    "                return_losses=True,\n",
    "                verbose=True\n",
    "            )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Or we may run large-scale experiments"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "param_grid = {\n",
    "    'timesteps': [6000],\n",
    "    'layers': [8],\n",
    "    'heads': [16],\n",
    "    'dim_feedforward':[2048],\n",
    "    'num_image_tokens': [1],\n",
    "    'num_user_tokens': [4],\n",
    "    'learning_rate': [1e-4],\n",
    "    #'optimizers': ['adamw', 'sgd'],\n",
    "    'optimizers': ['adamw'],\n",
    "    #'schedulers': ['reduce_on_plateau', 'cosine'],\n",
    "    'schedulers': ['reduce_on_plateau'],\n",
    "    'batch_size': [64],\n",
    "    'noise_schedule': [ \"linear\"],\n",
    "    'samples_per_user': [200],\n",
    "    'clip_sample': [True, False],\n",
    "    'rescale_betas': [True, False],\n",
    "    'objective':[\"noise-pred\"],\n",
    "    'use_ue': [True],\n",
    "    'img_embed_dim': [1024]\n",
    "}\n",
    "\n",
    "savedir = \"../data/flickr/evaluation/diffusion_priors/models/weights/experiment_2\"\n",
    "#savedir = \"../data/flickr/evaluation/diffusion_priors/models/weights/experiment_2\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import os\n",
    "os.path.exists(\"../data/flickr/evaluation/diffusion_priors/models/weights/experiment_1\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Hyperparameter combinations:   0%|          | 0/4 [00:00<?, ?it/s]c:\\Users\\Gabriel\\anaconda3\\envs\\recgensys-env\\lib\\site-packages\\torch\\nn\\modules\\transformer.py:306: UserWarning: enable_nested_tensor is True, but self.use_nested_tensor is False because encoder_layer.norm_first was True\n",
      "  warnings.warn(f\"enable_nested_tensor is True, but self.use_nested_tensor is False because {why_not_sparsity_fast_path}\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running configuration: timesteps=6000, layers=8, heads=16, image_tokens=1, user_tokens=4, learning_rate=0.0001, clip_sample=True, rescale_betas=True, optimizer=adamw, scheduler=reduce_on_plateau, batch_size=64, noise_schedule=linear, samples_per_user=200, objective=noise-pred, use_ue=True\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Hyperparameter combinations:  25%|██▌       | 1/4 [33:33<1:40:40, 2013.42s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Early stopping with best val loss: 0.04021679734190305!\n",
      "Running configuration: timesteps=6000, layers=8, heads=16, image_tokens=1, user_tokens=4, learning_rate=0.0001, clip_sample=True, rescale_betas=False, optimizer=adamw, scheduler=reduce_on_plateau, batch_size=64, noise_schedule=linear, samples_per_user=200, objective=noise-pred, use_ue=True\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Gabriel\\anaconda3\\envs\\recgensys-env\\lib\\site-packages\\torch\\nn\\modules\\transformer.py:306: UserWarning: enable_nested_tensor is True, but self.use_nested_tensor is False because encoder_layer.norm_first was True\n",
      "  warnings.warn(f\"enable_nested_tensor is True, but self.use_nested_tensor is False because {why_not_sparsity_fast_path}\")\n",
      "Hyperparameter combinations:  50%|█████     | 2/4 [1:12:26<1:13:23, 2201.67s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Early stopping with best val loss: 0.04478246457874775!\n",
      "Running configuration: timesteps=6000, layers=8, heads=16, image_tokens=1, user_tokens=4, learning_rate=0.0001, clip_sample=False, rescale_betas=True, optimizer=adamw, scheduler=reduce_on_plateau, batch_size=64, noise_schedule=linear, samples_per_user=200, objective=noise-pred, use_ue=True\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Gabriel\\anaconda3\\envs\\recgensys-env\\lib\\site-packages\\torch\\nn\\modules\\transformer.py:306: UserWarning: enable_nested_tensor is True, but self.use_nested_tensor is False because encoder_layer.norm_first was True\n",
      "  warnings.warn(f\"enable_nested_tensor is True, but self.use_nested_tensor is False because {why_not_sparsity_fast_path}\")\n",
      "Hyperparameter combinations:  75%|███████▌  | 3/4 [1:38:36<31:52, 1912.95s/it]  "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Early stopping with best val loss: 0.0462913886954387!\n",
      "Running configuration: timesteps=6000, layers=8, heads=16, image_tokens=1, user_tokens=4, learning_rate=0.0001, clip_sample=False, rescale_betas=False, optimizer=adamw, scheduler=reduce_on_plateau, batch_size=64, noise_schedule=linear, samples_per_user=200, objective=noise-pred, use_ue=True\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Gabriel\\anaconda3\\envs\\recgensys-env\\lib\\site-packages\\torch\\nn\\modules\\transformer.py:306: UserWarning: enable_nested_tensor is True, but self.use_nested_tensor is False because encoder_layer.norm_first was True\n",
      "  warnings.warn(f\"enable_nested_tensor is True, but self.use_nested_tensor is False because {why_not_sparsity_fast_path}\")\n",
      "Hyperparameter combinations: 100%|██████████| 4/4 [1:57:17<00:00, 1759.27s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Early stopping with best val loss: 0.04166508552928765!\n",
      "Experimentation complete. Results saved to results.csv at ../data/flickr/evaluation/diffusion_priors/models/weights/experiment_2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "run_grid_search(\n",
    "    train_df=train_df,\n",
    "    train_dataset=train_dataset,\n",
    "    val_dataset=val_dataset,\n",
    "    param_grid=param_grid,\n",
    "    savedir=savedir,\n",
    "    unique_users = len(unique_users)\n",
    "                )"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "recgensys-env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
